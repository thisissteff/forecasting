{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forecasting selling price of chicken with Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.6.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from category_encoders) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (1.12.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from category_encoders) (0.14.1)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from category_encoders) (0.5.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2023.4)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (3.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.10/site-packages (from statsmodels>=0.9.0->category_encoders) (23.2)\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "!pip install category_encoders\n",
    "import category_encoders as ce\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_DATE</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>SALES PER KG</th>\n",
       "      <th>TOTAL SALES</th>\n",
       "      <th>ABW</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>LOMBOK</td>\n",
       "      <td>6237</td>\n",
       "      <td>11356.5</td>\n",
       "      <td>22000.00000</td>\n",
       "      <td>249843000</td>\n",
       "      <td>1.820827</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>NUSA TENGGARA BARAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>GARUT</td>\n",
       "      <td>2625</td>\n",
       "      <td>5446.8</td>\n",
       "      <td>17000.00000</td>\n",
       "      <td>92595600</td>\n",
       "      <td>2.074971</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>SUMEDANG</td>\n",
       "      <td>7788</td>\n",
       "      <td>14176.8</td>\n",
       "      <td>16106.05355</td>\n",
       "      <td>228332300</td>\n",
       "      <td>1.820339</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>CIREBON</td>\n",
       "      <td>7504</td>\n",
       "      <td>15958.0</td>\n",
       "      <td>17000.00000</td>\n",
       "      <td>271286000</td>\n",
       "      <td>2.126599</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>PEKALONGAN</td>\n",
       "      <td>9121</td>\n",
       "      <td>16250.0</td>\n",
       "      <td>16500.00000</td>\n",
       "      <td>268125000</td>\n",
       "      <td>1.781603</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DAY_DATE        UNIT  TAILS       KG  SALES PER KG  TOTAL SALES  \\\n",
       "0  2017-01-01      LOMBOK   6237  11356.5   22000.00000    249843000   \n",
       "1  2017-01-01       GARUT   2625   5446.8   17000.00000     92595600   \n",
       "2  2017-01-01    SUMEDANG   7788  14176.8   16106.05355    228332300   \n",
       "3  2017-01-01     CIREBON   7504  15958.0   17000.00000    271286000   \n",
       "4  2017-01-01  PEKALONGAN   9121  16250.0   16500.00000    268125000   \n",
       "\n",
       "        ABW CHICKEN SIZE             PROVINCE  \n",
       "0  1.820827       MEDIUM  NUSA TENGGARA BARAT  \n",
       "1  2.074971        LARGE           JAWA BARAT  \n",
       "2  1.820339       MEDIUM           JAWA BARAT  \n",
       "3  2.126599        LARGE           JAWA BARAT  \n",
       "4  1.781603       MEDIUM          JAWA TENGAH  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading file\n",
    "df = pd.read_csv('/workspaces/forecasting/data/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "     DAY_DATE        UNIT  TAILS       KG  SALES PER KG       ABW  \\\n",
      "0  2017-01-01      LOMBOK   6237  11356.5   22000.00000  1.820827   \n",
      "1  2017-01-01       GARUT   2625   5446.8   17000.00000  2.074971   \n",
      "2  2017-01-01    SUMEDANG   7788  14176.8   16106.05355  1.820339   \n",
      "3  2017-01-01     CIREBON   7504  15958.0   17000.00000  2.126599   \n",
      "4  2017-01-01  PEKALONGAN   9121  16250.0   16500.00000  1.781603   \n",
      "\n",
      "  CHICKEN SIZE             PROVINCE  price_bin  \n",
      "0       MEDIUM  NUSA TENGGARA BARAT         13  \n",
      "1        LARGE           JAWA BARAT         10  \n",
      "2       MEDIUM           JAWA BARAT         10  \n",
      "3        LARGE           JAWA BARAT         10  \n",
      "4       MEDIUM          JAWA TENGAH         10  \n"
     ]
    }
   ],
   "source": [
    "# removing outlier\n",
    "df = df[df['SALES PER KG'] <= 35000]\n",
    "\n",
    "# removing 'total sales' column\n",
    "df = df.drop('TOTAL SALES', axis = 1)\n",
    "\n",
    "# creating bins for prediction\n",
    "\n",
    "# using sturges to print out the number of bins\n",
    "sturges = int(np.ceil(1 + np.log2(len(df['SALES PER KG']))))\n",
    "print(sturges)\n",
    "\n",
    "max_value = 35000\n",
    "bin_width = int((max_value - 0) // sturges)\n",
    "\n",
    "# Correctly calculate 'bin_edges'\n",
    "# Ensure 'bin_width' is added to 'max_value' to include the upper edge\n",
    "bin_edges = np.arange(0, max_value + bin_width, bin_width)\n",
    "\n",
    "# Use pd.cut to bin the data\n",
    "df['price_bin'] = pd.cut(df['SALES PER KG'], bins=bin_edges, labels=False, right=False)\n",
    "\n",
    "# Add 1 to change bins from 0-19 to 1-20\n",
    "df['price_bin'] += 1\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df.head())\n",
    "\n",
    "# dropping sales per kg column as we already have price_bin\n",
    "df = df.drop('SALES PER KG', axis = 1)\n",
    "\n",
    "# dropping ABW \n",
    "df = df.drop('ABW', axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre processing\n",
    "- extracting date column\n",
    "- splitting, scaling\n",
    "- creating function to evaluate the model [call `results(y_test, predictions)`]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting year and month from date column for seasonality trends\n",
    "df['DAY_DATE'] = pd.to_datetime(df['DAY_DATE'], errors='coerce').dt.normalize()\n",
    "df['YEAR'] = df['DAY_DATE'].dt.year\n",
    "df['MONTH'] = df['DAY_DATE'].dt.month\n",
    "df['DAY'] = df['DAY_DATE'].dt.day\n",
    "df = df.drop('DAY_DATE', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split before label encoding to prevent data leakage\n",
    "\n",
    "\n",
    "X = df.drop('price_bin', axis=1)\n",
    "y = df['price_bin']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaling numerical variable\n",
    "\n",
    "scaler = StandardScaler()\n",
    "columns_to_scale = ['KG', 'TAILS']\n",
    "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to evaluate the model\n",
    "def results(y_test, predictions):\n",
    "  mae = mean_absolute_error(y_test, predictions)\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "  rmse = np.sqrt(mse)\n",
    "  r2 = r2_score(y_test, predictions)\n",
    "\n",
    "  print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "  print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "  print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "  print(f\"R-squared (R²): {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding of columns\n",
    "# label encoding for province\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "X_train['SIZE ENCODE'] = label_encoder.fit_transform(X_train['CHICKEN SIZE'])\n",
    "X_test['SIZE ENCODE'] = label_encoder.transform(X_test['CHICKEN SIZE'])\n",
    "\n",
    "# dropping chicken size column\n",
    "X_train = X_train.drop(['CHICKEN SIZE'], axis = 1)\n",
    "X_test = X_test.drop(['CHICKEN SIZE'], axis = 1)\n",
    "\n",
    "\n",
    "# one hot encoding for province\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X_train[['PROVINCE']])\n",
    "X_train_encoded = encoder.transform(X_train[['PROVINCE']])\n",
    "X_test_encoded = encoder.transform(X_test[['PROVINCE']])\n",
    "\n",
    "# Convert the encoded matrices back to dataframes for easier manipulation\n",
    "columns = encoder.get_feature_names_out(['PROVINCE'])\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded.toarray(), columns=columns, index=X_train.index)\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded.toarray(), columns=columns, index=X_test.index)\n",
    "\n",
    "# merge back the dataframe\n",
    "X_train = pd.concat([X_train.drop('PROVINCE', axis=1), X_train_encoded_df], axis=1)\n",
    "X_test = pd.concat([X_test.drop('PROVINCE', axis=1), X_test_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# one hot encoding for unit\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X_train[['UNIT']])\n",
    "X_train_encoded_unit = encoder.transform(X_train[['UNIT']])\n",
    "X_test_encoded_unit = encoder.transform(X_test[['UNIT']])\n",
    "\n",
    "# Convert the encoded matrices back to dataframes for easier manipulation\n",
    "columns = encoder.get_feature_names_out(['UNIT'])\n",
    "X_train_encoded_df_unit = pd.DataFrame(X_train_encoded_unit.toarray(), columns=columns, index=X_train.index)\n",
    "X_test_encoded_df_unit = pd.DataFrame(X_test_encoded_unit.toarray(), columns=columns, index=X_test.index)\n",
    "\n",
    "# merge back the dataframe, dropping unit column\n",
    "X_train = pd.concat([X_train.drop('UNIT', axis=1), X_train_encoded_df_unit], axis=1)\n",
    "X_test = pd.concat([X_test.drop('UNIT', axis=1), X_test_encoded_df_unit], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           TAILS        KG  YEAR  MONTH  DAY  SIZE ENCODE  PROVINCE_ACEH  \\\n",
      "276802  0.456661  0.511789  2021     10   30            2            0.0   \n",
      "126530 -0.144031 -0.129820  2019      4   12            2            0.0   \n",
      "298428  1.224147  1.070229  2022      2   15            2            0.0   \n",
      "133120  1.104237  0.617678  2019      5   23            3            0.0   \n",
      "115983  0.122580 -0.032514  2019      2    9            2            0.0   \n",
      "...          ...       ...   ...    ...  ...          ...            ...   \n",
      "259179  4.653331  6.017824  2021      7   12            1            0.0   \n",
      "365839 -0.889626 -0.816256  2023      3    6            1            0.0   \n",
      "131933  0.108858  0.166973  2019      5   16            2            0.0   \n",
      "146868  0.396052  0.445115  2019      8   16            2            0.0   \n",
      "121959 -0.440374 -0.431000  2019      3   17            2            0.0   \n",
      "\n",
      "        PROVINCE_BALI  PROVINCE_BANTEN  PROVINCE_BENGKULU  ...  \\\n",
      "276802            0.0              0.0                0.0  ...   \n",
      "126530            0.0              0.0                0.0  ...   \n",
      "298428            0.0              0.0                0.0  ...   \n",
      "133120            1.0              0.0                0.0  ...   \n",
      "115983            0.0              0.0                0.0  ...   \n",
      "...               ...              ...                ...  ...   \n",
      "259179            0.0              0.0                0.0  ...   \n",
      "365839            0.0              0.0                0.0  ...   \n",
      "131933            0.0              0.0                0.0  ...   \n",
      "146868            0.0              0.0                0.0  ...   \n",
      "121959            0.0              0.0                0.0  ...   \n",
      "\n",
      "        UNIT_TASIKMALAYA  UNIT_TEBING TINGGI  UNIT_TEGAL  UNIT_TEMANGGUNG  \\\n",
      "276802               0.0                 0.0         0.0              0.0   \n",
      "126530               0.0                 0.0         0.0              0.0   \n",
      "298428               0.0                 0.0         0.0              0.0   \n",
      "133120               0.0                 0.0         0.0              0.0   \n",
      "115983               0.0                 0.0         0.0              0.0   \n",
      "...                  ...                 ...         ...              ...   \n",
      "259179               0.0                 0.0         0.0              0.0   \n",
      "365839               0.0                 0.0         0.0              0.0   \n",
      "131933               0.0                 0.0         0.0              0.0   \n",
      "146868               0.0                 0.0         0.0              0.0   \n",
      "121959               0.0                 0.0         0.0              0.0   \n",
      "\n",
      "        UNIT_TULANG BAWANG  UNIT_TULUNGAGUNG  UNIT_UNGARAN  UNIT_WABIN  \\\n",
      "276802                 0.0               0.0           0.0         0.0   \n",
      "126530                 0.0               0.0           0.0         0.0   \n",
      "298428                 0.0               0.0           0.0         0.0   \n",
      "133120                 0.0               0.0           0.0         0.0   \n",
      "115983                 0.0               0.0           0.0         0.0   \n",
      "...                    ...               ...           ...         ...   \n",
      "259179                 0.0               0.0           0.0         0.0   \n",
      "365839                 0.0               0.0           0.0         0.0   \n",
      "131933                 0.0               0.0           0.0         0.0   \n",
      "146868                 0.0               0.0           0.0         0.0   \n",
      "121959                 0.0               0.0           0.0         0.0   \n",
      "\n",
      "        UNIT_WONOGIRI  UNIT_YOGYAKARTA  \n",
      "276802            0.0              0.0  \n",
      "126530            0.0              0.0  \n",
      "298428            0.0              0.0  \n",
      "133120            0.0              0.0  \n",
      "115983            0.0              0.0  \n",
      "...               ...              ...  \n",
      "259179            0.0              0.0  \n",
      "365839            0.0              1.0  \n",
      "131933            0.0              0.0  \n",
      "146868            0.0              0.0  \n",
      "121959            0.0              0.0  \n",
      "\n",
      "[306320 rows x 163 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying lazy predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lazypredict-nightly in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: click in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict-nightly) (8.1.7)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict-nightly) (1.4.1.post1)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from lazypredict-nightly) (2.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict-nightly) (4.66.2)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from lazypredict-nightly) (1.3.2)\n",
      "Requirement already satisfied: lightgbm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict-nightly) (4.3.0)\n",
      "Requirement already satisfied: xgboost in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict-nightly) (2.0.3)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from lightgbm->lazypredict-nightly) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from lightgbm->lazypredict-nightly) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict-nightly) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict-nightly) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict-nightly) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->lazypredict-nightly) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->lazypredict-nightly) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lazypredict-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AdaBoostRegressor', sklearn.ensemble._weight_boosting.AdaBoostRegressor),\n",
       " ('BaggingRegressor', sklearn.ensemble._bagging.BaggingRegressor),\n",
       " ('BayesianRidge', sklearn.linear_model._bayes.BayesianRidge),\n",
       " ('DecisionTreeRegressor', sklearn.tree._classes.DecisionTreeRegressor),\n",
       " ('DummyRegressor', sklearn.dummy.DummyRegressor),\n",
       " ('ElasticNet', sklearn.linear_model._coordinate_descent.ElasticNet),\n",
       " ('ElasticNetCV', sklearn.linear_model._coordinate_descent.ElasticNetCV),\n",
       " ('ExtraTreeRegressor', sklearn.tree._classes.ExtraTreeRegressor),\n",
       " ('ExtraTreesRegressor', sklearn.ensemble._forest.ExtraTreesRegressor),\n",
       " ('GammaRegressor', sklearn.linear_model._glm.glm.GammaRegressor),\n",
       " ('GaussianProcessRegressor',\n",
       "  sklearn.gaussian_process._gpr.GaussianProcessRegressor),\n",
       " ('GradientBoostingRegressor', sklearn.ensemble._gb.GradientBoostingRegressor),\n",
       " ('HistGradientBoostingRegressor',\n",
       "  sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor),\n",
       " ('HuberRegressor', sklearn.linear_model._huber.HuberRegressor),\n",
       " ('KNeighborsRegressor', sklearn.neighbors._regression.KNeighborsRegressor),\n",
       " ('KernelRidge', sklearn.kernel_ridge.KernelRidge),\n",
       " ('Lars', sklearn.linear_model._least_angle.Lars),\n",
       " ('LarsCV', sklearn.linear_model._least_angle.LarsCV),\n",
       " ('Lasso', sklearn.linear_model._coordinate_descent.Lasso),\n",
       " ('LassoCV', sklearn.linear_model._coordinate_descent.LassoCV),\n",
       " ('LassoLars', sklearn.linear_model._least_angle.LassoLars),\n",
       " ('LassoLarsCV', sklearn.linear_model._least_angle.LassoLarsCV),\n",
       " ('LassoLarsIC', sklearn.linear_model._least_angle.LassoLarsIC),\n",
       " ('LinearRegression', sklearn.linear_model._base.LinearRegression),\n",
       " ('LinearSVR', sklearn.svm._classes.LinearSVR),\n",
       " ('MLPRegressor', sklearn.neural_network._multilayer_perceptron.MLPRegressor),\n",
       " ('NuSVR', sklearn.svm._classes.NuSVR),\n",
       " ('OrthogonalMatchingPursuit',\n",
       "  sklearn.linear_model._omp.OrthogonalMatchingPursuit),\n",
       " ('OrthogonalMatchingPursuitCV',\n",
       "  sklearn.linear_model._omp.OrthogonalMatchingPursuitCV),\n",
       " ('PassiveAggressiveRegressor',\n",
       "  sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor),\n",
       " ('PoissonRegressor', sklearn.linear_model._glm.glm.PoissonRegressor),\n",
       " ('QuantileRegressor', sklearn.linear_model._quantile.QuantileRegressor),\n",
       " ('RANSACRegressor', sklearn.linear_model._ransac.RANSACRegressor),\n",
       " ('RandomForestRegressor', sklearn.ensemble._forest.RandomForestRegressor),\n",
       " ('Ridge', sklearn.linear_model._ridge.Ridge),\n",
       " ('RidgeCV', sklearn.linear_model._ridge.RidgeCV),\n",
       " ('SGDRegressor', sklearn.linear_model._stochastic_gradient.SGDRegressor),\n",
       " ('SVR', sklearn.svm._classes.SVR),\n",
       " ('TransformedTargetRegressor',\n",
       "  sklearn.compose._target.TransformedTargetRegressor),\n",
       " ('TweedieRegressor', sklearn.linear_model._glm.glm.TweedieRegressor),\n",
       " ('XGBRegressor', xgboost.sklearn.XGBRegressor),\n",
       " ('LGBMRegressor', lightgbm.sklearn.LGBMRegressor)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libraries\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "lazypredict.Supervised.REGRESSORS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# initialising regressor\n",
    "reg = LazyRegressor(verbose=10, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "# fitting and evaluate models\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'ExtraTreesRegressor', \n",
    "'BaggingRegressor', \n",
    "'svr'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
