{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forecasting selling price of chicken\n",
    "\n",
    "Things to note:\n",
    "* Changing how accuracy is being graded. As long as the model is able to predict the price within 20%, it is considered accurate. \n",
    "* Weekends are considered as a holiday as there would be many family gatherings and parties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing the relevant libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn import metrics\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "#!pip install category_encoders\n",
    "import category_encoders as ce\n",
    "from category_encoders import TargetEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>SALES PER KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "      <th>Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYAKUMBUH</td>\n",
       "      <td>1267</td>\n",
       "      <td>2856.0</td>\n",
       "      <td>18000.00000</td>\n",
       "      <td>2.254144</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3885216</td>\n",
       "      <td>5993194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINJAI</td>\n",
       "      <td>3310</td>\n",
       "      <td>7799.5</td>\n",
       "      <td>22637.89730</td>\n",
       "      <td>2.356344</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5447863</td>\n",
       "      <td>5931514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANDAR JAYA</td>\n",
       "      <td>8236</td>\n",
       "      <td>22197.0</td>\n",
       "      <td>15905.01419</td>\n",
       "      <td>2.695119</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANDAR LAMPUNG</td>\n",
       "      <td>2565</td>\n",
       "      <td>4971.0</td>\n",
       "      <td>18060.47073</td>\n",
       "      <td>1.938012</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANYUASIN</td>\n",
       "      <td>696</td>\n",
       "      <td>1464.4</td>\n",
       "      <td>16368.88828</td>\n",
       "      <td>2.104023</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5758528</td>\n",
       "      <td>7021239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             UNIT  TAILS       KG  SALES PER KG       ABW CHICKEN SIZE  \\\n",
       "0      PAYAKUMBUH   1267   2856.0   18000.00000  2.254144        LARGE   \n",
       "1          SINJAI   3310   7799.5   22637.89730  2.356344        LARGE   \n",
       "2     BANDAR JAYA   8236  22197.0   15905.01419  2.695119        LARGE   \n",
       "3  BANDAR LAMPUNG   2565   4971.0   18060.47073  1.938012       MEDIUM   \n",
       "4       BANYUASIN    696   1464.4   16368.88828  2.104023        LARGE   \n",
       "\n",
       "           PROVINCE  YEAR  MONTH  DAY  SupplyProvince  DemandProvince  Holiday  \n",
       "0    SUMATERA BARAT    19     12    1         3885216         5993194        1  \n",
       "1  SULAWESI SELATAN    19     12    1         5447863         5931514        1  \n",
       "2           LAMPUNG    19     12    1         5404511         5618463        1  \n",
       "3           LAMPUNG    19     12    1         5404511         5618463        1  \n",
       "4  SUMATERA SELATAN    19     12    1         5758528         7021239        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading file\n",
    "df = pd.read_csv('/workspaces/forecasting/data/bigDataHoliday.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>SALES PER KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "      <th>Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.0</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>1.505500e+04</td>\n",
       "      <td>1.505500e+04</td>\n",
       "      <td>15055.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8241.127532</td>\n",
       "      <td>15260.051938</td>\n",
       "      <td>19204.083254</td>\n",
       "      <td>1.829462</td>\n",
       "      <td>20.098439</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.780671</td>\n",
       "      <td>2.617008e+07</td>\n",
       "      <td>2.040207e+07</td>\n",
       "      <td>0.183726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7135.717864</td>\n",
       "      <td>13785.152507</td>\n",
       "      <td>2153.773552</td>\n",
       "      <td>0.336812</td>\n",
       "      <td>0.985753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.879310</td>\n",
       "      <td>2.328217e+07</td>\n",
       "      <td>1.675878e+07</td>\n",
       "      <td>0.387274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>6892.778929</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.322200e+04</td>\n",
       "      <td>3.913950e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3235.500000</td>\n",
       "      <td>5698.000000</td>\n",
       "      <td>17414.197155</td>\n",
       "      <td>1.596241</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.424703e+06</td>\n",
       "      <td>5.141045e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6532.000000</td>\n",
       "      <td>11683.200000</td>\n",
       "      <td>19072.570490</td>\n",
       "      <td>1.821657</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.256251e+07</td>\n",
       "      <td>1.123831e+07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11104.000000</td>\n",
       "      <td>20707.450000</td>\n",
       "      <td>20576.154140</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.994253e+07</td>\n",
       "      <td>3.453131e+07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>103280.000000</td>\n",
       "      <td>215666.400000</td>\n",
       "      <td>28621.861390</td>\n",
       "      <td>3.481132</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.499769e+07</td>\n",
       "      <td>5.193302e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TAILS             KG  SALES PER KG           ABW          YEAR  \\\n",
       "count   15055.000000   15055.000000  15055.000000  15055.000000  15055.000000   \n",
       "mean     8241.127532   15260.051938  19204.083254      1.829462     20.098439   \n",
       "std      7135.717864   13785.152507   2153.773552      0.336812      0.985753   \n",
       "min        15.000000      24.800000   6892.778929      0.547500     19.000000   \n",
       "25%      3235.500000    5698.000000  17414.197155      1.596241     19.000000   \n",
       "50%      6532.000000   11683.200000  19072.570490      1.821657     20.000000   \n",
       "75%     11104.000000   20707.450000  20576.154140      2.060000     21.000000   \n",
       "max    103280.000000  215666.400000  28621.861390      3.481132     23.000000   \n",
       "\n",
       "         MONTH           DAY  SupplyProvince  DemandProvince       Holiday  \n",
       "count  15055.0  15055.000000    1.505500e+04    1.505500e+04  15055.000000  \n",
       "mean      12.0     15.780671    2.617008e+07    2.040207e+07      0.183726  \n",
       "std        0.0      8.879310    2.328217e+07    1.675878e+07      0.387274  \n",
       "min       12.0      1.000000    8.322200e+04    3.913950e+05      0.000000  \n",
       "25%       12.0      8.000000    4.424703e+06    5.141045e+06      0.000000  \n",
       "50%       12.0     16.000000    1.256251e+07    1.123831e+07      0.000000  \n",
       "75%       12.0     23.000000    4.994253e+07    3.453131e+07      0.000000  \n",
       "max       12.0     31.000000    6.499769e+07    5.193302e+07      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIT              0\n",
      "TAILS             0\n",
      "KG                0\n",
      "ABW               0\n",
      "CHICKEN SIZE      0\n",
      "PROVINCE          0\n",
      "YEAR              0\n",
      "MONTH             0\n",
      "DAY               0\n",
      "SupplyProvince    0\n",
      "DemandProvince    0\n",
      "Holiday           0\n",
      "dtype: int64\n",
      "UNIT              0\n",
      "TAILS             0\n",
      "KG                0\n",
      "ABW               0\n",
      "CHICKEN SIZE      0\n",
      "PROVINCE          0\n",
      "YEAR              0\n",
      "MONTH             0\n",
      "DAY               0\n",
      "SupplyProvince    0\n",
      "DemandProvince    0\n",
      "Holiday           0\n",
      "dtype: int64\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# train test split before label encoding to prevent data leakage\n",
    "\n",
    "\n",
    "X = df.drop('SALES PER KG', axis=1)\n",
    "y = df['SALES PER KG']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# checking for any nan values after splitting\n",
    "print(X_train.isna().sum())\n",
    "print(X_test.isna().sum())\n",
    "print(y_train.isna().sum())\n",
    "print(y_test.isna().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling numerical variable\n",
    "\n",
    "scaler = StandardScaler()\n",
    "columns_to_scale = ['KG', 'TAILS', 'SupplyProvince', 'DemandProvince']\n",
    "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "      <th>Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12179</th>\n",
       "      <td>SANGATTA</td>\n",
       "      <td>-0.868153</td>\n",
       "      <td>-0.903847</td>\n",
       "      <td>1.385429</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>KALIMANTAN TIMUR</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.024406</td>\n",
       "      <td>-0.964375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14448</th>\n",
       "      <td>SIJUNJUNG</td>\n",
       "      <td>-0.279093</td>\n",
       "      <td>-0.318778</td>\n",
       "      <td>1.739214</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.995010</td>\n",
       "      <td>-0.935591</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13769</th>\n",
       "      <td>BOJONEGORO</td>\n",
       "      <td>-0.943107</td>\n",
       "      <td>-0.881517</td>\n",
       "      <td>2.050574</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>JAWA TIMUR</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>0.087111</td>\n",
       "      <td>0.845235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12070</th>\n",
       "      <td>BENGKULU</td>\n",
       "      <td>0.485797</td>\n",
       "      <td>0.670116</td>\n",
       "      <td>2.089701</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>BENGKULU</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>-1.104780</td>\n",
       "      <td>-1.153716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11502</th>\n",
       "      <td>PALANGKARAYA</td>\n",
       "      <td>-0.470844</td>\n",
       "      <td>-0.300075</td>\n",
       "      <td>2.272398</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>KALIMANTAN TENGAH</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.060115</td>\n",
       "      <td>-1.051460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>GIANYAR</td>\n",
       "      <td>-0.105658</td>\n",
       "      <td>-0.134086</td>\n",
       "      <td>1.791001</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>BALI</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.918898</td>\n",
       "      <td>-0.925787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13418</th>\n",
       "      <td>50 KOTA</td>\n",
       "      <td>0.028610</td>\n",
       "      <td>-0.052511</td>\n",
       "      <td>1.721377</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.995010</td>\n",
       "      <td>-0.935591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>CIREBON</td>\n",
       "      <td>0.012689</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>1.864943</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1.468594</td>\n",
       "      <td>1.720036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>SUBANG(P)</td>\n",
       "      <td>1.917237</td>\n",
       "      <td>1.183325</td>\n",
       "      <td>1.440357</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1.665132</td>\n",
       "      <td>1.884218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>GOWA</td>\n",
       "      <td>0.127937</td>\n",
       "      <td>0.174144</td>\n",
       "      <td>1.927623</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.905846</td>\n",
       "      <td>-0.881091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12044 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UNIT     TAILS        KG       ABW CHICKEN SIZE  \\\n",
       "12179      SANGATTA -0.868153 -0.903847  1.385429        SMALL   \n",
       "14448     SIJUNJUNG -0.279093 -0.318778  1.739214       MEDIUM   \n",
       "13769    BOJONEGORO -0.943107 -0.881517  2.050574        LARGE   \n",
       "12070      BENGKULU  0.485797  0.670116  2.089701        LARGE   \n",
       "11502  PALANGKARAYA -0.470844 -0.300075  2.272398        LARGE   \n",
       "...             ...       ...       ...       ...          ...   \n",
       "5191        GIANYAR -0.105658 -0.134086  1.791001       MEDIUM   \n",
       "13418       50 KOTA  0.028610 -0.052511  1.721377       MEDIUM   \n",
       "5390        CIREBON  0.012689  0.020821  1.864943       MEDIUM   \n",
       "860       SUBANG(P)  1.917237  1.183325  1.440357        SMALL   \n",
       "7270           GOWA  0.127937  0.174144  1.927623       MEDIUM   \n",
       "\n",
       "                PROVINCE  YEAR  MONTH  DAY  SupplyProvince  DemandProvince  \\\n",
       "12179   KALIMANTAN TIMUR    21     12   17       -1.024406       -0.964375   \n",
       "14448     SUMATERA BARAT    21     12   31       -0.995010       -0.935591   \n",
       "13769         JAWA TIMUR    21     12   27        0.087111        0.845235   \n",
       "12070           BENGKULU    21     12   16       -1.104780       -1.153716   \n",
       "11502  KALIMANTAN TENGAH    21     12   13       -1.060115       -1.051460   \n",
       "...                  ...   ...    ...  ...             ...             ...   \n",
       "5191                BALI    20     12    1       -0.918898       -0.925787   \n",
       "13418     SUMATERA BARAT    21     12   24       -0.995010       -0.935591   \n",
       "5390          JAWA BARAT    20     12    2        1.468594        1.720036   \n",
       "860           JAWA BARAT    19     12    5        1.665132        1.884218   \n",
       "7270    SULAWESI SELATAN    20     12   16       -0.905846       -0.881091   \n",
       "\n",
       "       Holiday  \n",
       "12179        0  \n",
       "14448        0  \n",
       "13769        1  \n",
       "12070        0  \n",
       "11502        0  \n",
       "...        ...  \n",
       "5191         0  \n",
       "13418        1  \n",
       "5390         0  \n",
       "860          0  \n",
       "7270         0  \n",
       "\n",
       "[12044 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS\n",
    "- results(y_test, predictions):\n",
    "- accuracy(y_test, predictions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining new accuracy metrics\n",
    "import math\n",
    "def accuracy(y_test, predictions):\n",
    "    cnt = 0\n",
    "    length = len(predictions)\n",
    "\n",
    "    for i in range(length):\n",
    "        above = math.ceil(predictions[i] + (predictions[i] * 0.1)) # accuracy absed on 10% above and below\n",
    "        below = math.ceil(predictions[i] - (predictions[i] * 0.1))\n",
    "\n",
    "        if (predictions[i] == y_test[i]):\n",
    "            cnt += 1\n",
    "        elif (y_test[i] >= predictions[i] and y_test[i] <= above):\n",
    "            cnt += 1\n",
    "        elif (y_test[i] <= predictions[i] and y_test[i] >= below):\n",
    "            cnt += 1\n",
    "    actual = cnt / length\n",
    "    return actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to evaluate the model\n",
    "def results(y_test, predictions):\n",
    "  mae = mean_absolute_error(y_test, predictions)\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "  rmse = np.sqrt(mse)\n",
    "  r2 = r2_score(y_test, predictions)\n",
    "\n",
    "  y_test_list = np.array(y_test).tolist()\n",
    "  predictions_list = predictions.tolist()\n",
    "  acc = accuracy(y_test_list, predictions_list)\n",
    "\n",
    "  print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "  print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "  print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "  print(f\"R-squared (R²): {r2}\")\n",
    "  print(f\"Re-Defined Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding of columns\n",
    "# label encoding for province\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "X_train['SIZE ENCODE'] = label_encoder.fit_transform(X_train['CHICKEN SIZE'])\n",
    "X_test['SIZE ENCODE'] = label_encoder.transform(X_test['CHICKEN SIZE'])\n",
    "\n",
    "# dropping chicken size column\n",
    "X_train = X_train.drop(['CHICKEN SIZE'], axis = 1)\n",
    "X_test = X_test.drop(['CHICKEN SIZE'], axis = 1)\n",
    "\n",
    "\n",
    "# one hot encoding for province\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X_train[['PROVINCE']])\n",
    "X_train_encoded = encoder.transform(X_train[['PROVINCE']])\n",
    "X_test_encoded = encoder.transform(X_test[['PROVINCE']])\n",
    "\n",
    "# Convert the encoded matrices back to dataframes for easier manipulation\n",
    "columns = encoder.get_feature_names_out(['PROVINCE'])\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded.toarray(), columns=columns, index=X_train.index)\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded.toarray(), columns=columns, index=X_test.index)\n",
    "\n",
    "# merge back the dataframe\n",
    "X_train = pd.concat([X_train.drop('PROVINCE', axis=1), X_train_encoded_df], axis=1)\n",
    "X_test = pd.concat([X_test.drop('PROVINCE', axis=1), X_test_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# one hot encoding for unit\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X_train[['UNIT']])\n",
    "X_train_encoded_unit = encoder.transform(X_train[['UNIT']])\n",
    "X_test_encoded_unit = encoder.transform(X_test[['UNIT']])\n",
    "\n",
    "# Convert the encoded matrices back to dataframes for easier manipulation\n",
    "columns = encoder.get_feature_names_out(['UNIT'])\n",
    "X_train_encoded_df_unit = pd.DataFrame(X_train_encoded_unit.toarray(), columns=columns, index=X_train.index)\n",
    "X_test_encoded_df_unit = pd.DataFrame(X_test_encoded_unit.toarray(), columns=columns, index=X_test.index)\n",
    "\n",
    "# merge back the dataframe, dropping unit column\n",
    "X_train = pd.concat([X_train.drop('UNIT', axis=1), X_train_encoded_df_unit], axis=1)\n",
    "X_test = pd.concat([X_test.drop('UNIT', axis=1), X_test_encoded_df_unit], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1096.9887937565593\n",
      "Mean Squared Error (MSE): 2204010.1056202706\n",
      "Root Mean Squared Error (RMSE): 1484.5908882989518\n",
      "R-squared (R²): 0.5373888190756129\n",
      "Re-Defined Accuracy: 0.8465626037861176\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Use the custom accuracy function\\naccuracy_score = accuracy(y_test_list, predictions_list)\\nprint(f\"Custom Accuracy Score: {accuracy_score}\")'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying Logistic Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "predictions_lr = lr.predict(X_test)\n",
    "\n",
    "# print metrics\n",
    "print(results(y_test, predictions_lr))\n",
    "\n",
    "\n",
    "\n",
    "'''# Use the custom accuracy function\n",
    "accuracy_score = accuracy(y_test_list, predictions_list)\n",
    "print(f\"Custom Accuracy Score: {accuracy_score}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 481.8099547746834\n",
      "Mean Squared Error (MSE): 690170.1718080787\n",
      "Root Mean Squared Error (RMSE): 830.7648113684635\n",
      "R-squared (R²): 0.855136581540733\n",
      "Re-Defined Accuracy: 0.9637994021919628\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# random forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 400) # 400 trees\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "predictions_rf = rf.predict(X_test)\n",
    "\n",
    "# print accuracy score\n",
    "print(results(y_test, predictions_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 603.0214842705082\n",
      "Mean Squared Error (MSE): 853160.8484241929\n",
      "Root Mean Squared Error (RMSE): 923.6670657895045\n",
      "R-squared (R²): 0.8209256179898987\n",
      "Re-Defined Accuracy: 0.9554965127864496\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# applying xgboost\n",
    "xg = xgb.XGBRegressor()\n",
    "\n",
    "# fitting the model\n",
    "xg.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "predictions_xg = xg.predict(X_test) \n",
    "\n",
    "# print accuracy score\n",
    "print(results(y_test, predictions_xg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 622.3767745532588\n",
      "Mean Squared Error (MSE): 1301568.8692961177\n",
      "Root Mean Squared Error (RMSE): 1140.8632123511204\n",
      "R-squared (R²): 0.7268069188321427\n",
      "Re-Defined Accuracy: 0.9302557289936898\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# applying decision trees\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "predictions_dt = dt.predict(X_test)\n",
    "print(results(y_test, predictions_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1714.9721868000245\n",
      "Mean Squared Error (MSE): 4621680.866075736\n",
      "Root Mean Squared Error (RMSE): 2149.8094952985334\n",
      "R-squared (R²): 0.029931288491422237\n",
      "Re-Defined Accuracy: 0.6021255396878114\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# applying SVM\n",
    "from sklearn.svm import SVR\n",
    "svm = SVR()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "predictions_SVM = svm.predict(X_test)\n",
    "print(results(y_test, predictions_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 453.8822808106234\n",
      "Mean Squared Error (MSE): 658191.602126477\n",
      "Root Mean Squared Error (RMSE): 811.2900850660491\n",
      "R-squared (R²): 0.8618487303856746\n",
      "Re-Defined Accuracy: 0.9684490202590501\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# applying extra trees regressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "et = ExtraTreesRegressor()\n",
    "et.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "predictions_et = et.predict(X_test)\n",
    "print(results(y_test, predictions_et))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 248296928.0000\n",
      "Epoch 2/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 11056535.0000\n",
      "Epoch 3/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 7033267.5000\n",
      "Epoch 4/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 4480553.5000\n",
      "Epoch 5/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 3256021.5000\n",
      "Epoch 6/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2868693.7500\n",
      "Epoch 7/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2731434.2500\n",
      "Epoch 8/100\n",
      "377/377 [==============================] - 0s 987us/step - loss: 2645546.0000\n",
      "Epoch 9/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2577673.2500\n",
      "Epoch 10/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2521572.7500\n",
      "Epoch 11/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2472130.0000\n",
      "Epoch 12/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2434446.5000\n",
      "Epoch 13/100\n",
      "377/377 [==============================] - 0s 987us/step - loss: 2402036.7500\n",
      "Epoch 14/100\n",
      "377/377 [==============================] - 0s 983us/step - loss: 2371815.7500\n",
      "Epoch 15/100\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 2344632.2500\n",
      "Epoch 16/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2325152.7500\n",
      "Epoch 17/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2304475.0000\n",
      "Epoch 18/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2293511.0000\n",
      "Epoch 19/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2280111.5000\n",
      "Epoch 20/100\n",
      "377/377 [==============================] - 0s 997us/step - loss: 2267285.2500\n",
      "Epoch 21/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2250081.7500\n",
      "Epoch 22/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2245277.0000\n",
      "Epoch 23/100\n",
      "377/377 [==============================] - 0s 984us/step - loss: 2244734.7500\n",
      "Epoch 24/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2232537.0000\n",
      "Epoch 25/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2227947.7500\n",
      "Epoch 26/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2219397.0000\n",
      "Epoch 27/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2218457.2500\n",
      "Epoch 28/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2211685.2500\n",
      "Epoch 29/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2212997.5000\n",
      "Epoch 30/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2208086.0000\n",
      "Epoch 31/100\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 2205032.7500\n",
      "Epoch 32/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2203827.5000\n",
      "Epoch 33/100\n",
      "377/377 [==============================] - 0s 993us/step - loss: 2201115.2500\n",
      "Epoch 34/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2198796.7500\n",
      "Epoch 35/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2190792.0000\n",
      "Epoch 36/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2192303.7500\n",
      "Epoch 37/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2189959.7500\n",
      "Epoch 38/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2183779.2500\n",
      "Epoch 39/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2183342.0000\n",
      "Epoch 40/100\n",
      "377/377 [==============================] - 0s 998us/step - loss: 2179619.0000\n",
      "Epoch 41/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2180524.7500\n",
      "Epoch 42/100\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 2186749.2500\n",
      "Epoch 43/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2183878.7500\n",
      "Epoch 44/100\n",
      "377/377 [==============================] - 0s 975us/step - loss: 2181424.2500\n",
      "Epoch 45/100\n",
      "377/377 [==============================] - 0s 992us/step - loss: 2177947.7500\n",
      "Epoch 46/100\n",
      "377/377 [==============================] - 0s 991us/step - loss: 2175052.5000\n",
      "Epoch 47/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2171181.0000\n",
      "Epoch 48/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2171675.2500\n",
      "Epoch 49/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2168062.2500\n",
      "Epoch 50/100\n",
      "377/377 [==============================] - 0s 988us/step - loss: 2163733.0000\n",
      "Epoch 51/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2171232.7500\n",
      "Epoch 52/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2167635.0000\n",
      "Epoch 53/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2167038.0000\n",
      "Epoch 54/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2161177.7500\n",
      "Epoch 55/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2158963.5000\n",
      "Epoch 56/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2164453.7500\n",
      "Epoch 57/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2160235.2500\n",
      "Epoch 58/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2162609.5000\n",
      "Epoch 59/100\n",
      "377/377 [==============================] - 0s 994us/step - loss: 2160713.0000\n",
      "Epoch 60/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2159404.2500\n",
      "Epoch 61/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2158266.2500\n",
      "Epoch 62/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2152992.5000\n",
      "Epoch 63/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2155637.7500\n",
      "Epoch 64/100\n",
      "377/377 [==============================] - 0s 977us/step - loss: 2154312.2500\n",
      "Epoch 65/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2159884.2500\n",
      "Epoch 66/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2157186.5000\n",
      "Epoch 67/100\n",
      "377/377 [==============================] - 0s 987us/step - loss: 2153962.5000\n",
      "Epoch 68/100\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 2149474.0000\n",
      "Epoch 69/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2147011.5000\n",
      "Epoch 70/100\n",
      "377/377 [==============================] - 0s 988us/step - loss: 2148590.0000\n",
      "Epoch 71/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2148225.5000\n",
      "Epoch 72/100\n",
      "377/377 [==============================] - 0s 987us/step - loss: 2148292.2500\n",
      "Epoch 73/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2148072.7500\n",
      "Epoch 74/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2156407.0000\n",
      "Epoch 75/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2146000.7500\n",
      "Epoch 76/100\n",
      "377/377 [==============================] - 0s 998us/step - loss: 2146867.2500\n",
      "Epoch 77/100\n",
      "377/377 [==============================] - 0s 981us/step - loss: 2143359.2500\n",
      "Epoch 78/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2145746.0000\n",
      "Epoch 79/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2147382.5000\n",
      "Epoch 80/100\n",
      "377/377 [==============================] - 0s 990us/step - loss: 2134813.2500\n",
      "Epoch 81/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2143862.5000\n",
      "Epoch 82/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2134713.2500\n",
      "Epoch 83/100\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 2138314.2500\n",
      "Epoch 84/100\n",
      "377/377 [==============================] - 0s 994us/step - loss: 2138573.7500\n",
      "Epoch 85/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2133434.5000\n",
      "Epoch 86/100\n",
      "377/377 [==============================] - 0s 987us/step - loss: 2131331.2500\n",
      "Epoch 87/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2131713.0000\n",
      "Epoch 88/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2129160.2500\n",
      "Epoch 89/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2134477.2500\n",
      "Epoch 90/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2123729.0000\n",
      "Epoch 91/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2116855.5000\n",
      "Epoch 92/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2118149.0000\n",
      "Epoch 93/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2115559.7500\n",
      "Epoch 94/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2107806.7500\n",
      "Epoch 95/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2097645.2500\n",
      "Epoch 96/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2093398.6250\n",
      "Epoch 97/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2086465.2500\n",
      "Epoch 98/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2081706.6250\n",
      "Epoch 99/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2078521.8750\n",
      "Epoch 100/100\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 2069174.0000\n",
      "95/95 [==============================] - 0s 747us/step\n",
      "Mean Absolute Error (MAE): 1077.5226292358436\n",
      "Mean Squared Error (MSE): 2176902.444966778\n",
      "Root Mean Squared Error (RMSE): 1475.432968645739\n",
      "R-squared (R²): 0.5430785874097197\n",
      "Re-Defined Accuracy: 0.8515443374294255\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# applying neural network\n",
    "#!pip install tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# creating neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Single output node for regression\n",
    "])\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# training the model\n",
    "model.fit(X_train, y_train, epochs = 100, batch_size = 32)\n",
    "\n",
    "\n",
    "# print accuracy score\n",
    "def accuracy_nn(y_test, predictions): # new accuracy metrics for neural networks\n",
    "    cnt = 0\n",
    "    length = len(predictions)\n",
    "\n",
    "    for i in range(length):\n",
    "        prediction = predictions[i][0] if isinstance(predictions[i], list) else predictions[i]\n",
    "        above = math.ceil(prediction + (prediction * 0.1))\n",
    "        below = math.ceil(prediction - (prediction * 0.1))\n",
    "\n",
    "        if prediction == y_test[i]:\n",
    "            cnt += 1\n",
    "        elif y_test[i] >= prediction and y_test[i] <= above:\n",
    "            cnt += 1\n",
    "        elif y_test[i] <= prediction and y_test[i] >= below:\n",
    "            cnt += 1\n",
    "\n",
    "    actual = cnt / length\n",
    "    return actual\n",
    "\n",
    "\n",
    "# predictions\n",
    "predictions_nn = model.predict(X_test)\n",
    "predictions_nn = predictions_nn.flatten()\n",
    "\n",
    "print(results(y_test, predictions_nn))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
