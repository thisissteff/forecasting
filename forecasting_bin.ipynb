{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forecasting selling price of chicken with Bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing the relevant libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.6.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from category_encoders) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (1.12.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from category_encoders) (0.14.1)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from category_encoders) (0.5.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2023.4)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (3.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.10/site-packages (from statsmodels>=0.9.0->category_encoders) (23.2)\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "!pip install category_encoders\n",
    "import category_encoders as ce\n",
    "from category_encoders import TargetEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>SALES PER KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYAKUMBUH</td>\n",
       "      <td>1267</td>\n",
       "      <td>2856.0</td>\n",
       "      <td>18000.00000</td>\n",
       "      <td>2.254144</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3885216</td>\n",
       "      <td>5993194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINJAI</td>\n",
       "      <td>3310</td>\n",
       "      <td>7799.5</td>\n",
       "      <td>22637.89730</td>\n",
       "      <td>2.356344</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5447863</td>\n",
       "      <td>5931514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANDAR JAYA</td>\n",
       "      <td>8236</td>\n",
       "      <td>22197.0</td>\n",
       "      <td>15905.01419</td>\n",
       "      <td>2.695119</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANDAR LAMPUNG</td>\n",
       "      <td>2565</td>\n",
       "      <td>4971.0</td>\n",
       "      <td>18060.47073</td>\n",
       "      <td>1.938012</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANYUASIN</td>\n",
       "      <td>696</td>\n",
       "      <td>1464.4</td>\n",
       "      <td>16368.88828</td>\n",
       "      <td>2.104023</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5758528</td>\n",
       "      <td>7021239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             UNIT  TAILS       KG  SALES PER KG       ABW CHICKEN SIZE  \\\n",
       "0      PAYAKUMBUH   1267   2856.0   18000.00000  2.254144        LARGE   \n",
       "1          SINJAI   3310   7799.5   22637.89730  2.356344        LARGE   \n",
       "2     BANDAR JAYA   8236  22197.0   15905.01419  2.695119        LARGE   \n",
       "3  BANDAR LAMPUNG   2565   4971.0   18060.47073  1.938012       MEDIUM   \n",
       "4       BANYUASIN    696   1464.4   16368.88828  2.104023        LARGE   \n",
       "\n",
       "           PROVINCE  YEAR  MONTH  DAY  SupplyProvince  DemandProvince  \n",
       "0    SUMATERA BARAT    19     12    1         3885216         5993194  \n",
       "1  SULAWESI SELATAN    19     12    1         5447863         5931514  \n",
       "2           LAMPUNG    19     12    1         5404511         5618463  \n",
       "3           LAMPUNG    19     12    1         5404511         5618463  \n",
       "4  SUMATERA SELATAN    19     12    1         5758528         7021239  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading file\n",
    "df = pd.read_csv('/workspaces/forecasting/data/final.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>SALES PER KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.0</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>1.505500e+04</td>\n",
       "      <td>1.505500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8241.127532</td>\n",
       "      <td>15260.051938</td>\n",
       "      <td>19204.083254</td>\n",
       "      <td>1.829462</td>\n",
       "      <td>20.098439</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.780671</td>\n",
       "      <td>2.617008e+07</td>\n",
       "      <td>2.040207e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7135.717864</td>\n",
       "      <td>13785.152507</td>\n",
       "      <td>2153.773552</td>\n",
       "      <td>0.336812</td>\n",
       "      <td>0.985753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.879310</td>\n",
       "      <td>2.328217e+07</td>\n",
       "      <td>1.675878e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>6892.778929</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.322200e+04</td>\n",
       "      <td>3.913950e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3235.500000</td>\n",
       "      <td>5698.000000</td>\n",
       "      <td>17414.197155</td>\n",
       "      <td>1.596241</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.424703e+06</td>\n",
       "      <td>5.141045e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6532.000000</td>\n",
       "      <td>11683.200000</td>\n",
       "      <td>19072.570490</td>\n",
       "      <td>1.821657</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.256251e+07</td>\n",
       "      <td>1.123831e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11104.000000</td>\n",
       "      <td>20707.450000</td>\n",
       "      <td>20576.154140</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.994253e+07</td>\n",
       "      <td>3.453131e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>103280.000000</td>\n",
       "      <td>215666.400000</td>\n",
       "      <td>28621.861390</td>\n",
       "      <td>3.481132</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.499769e+07</td>\n",
       "      <td>5.193302e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TAILS             KG  SALES PER KG           ABW          YEAR  \\\n",
       "count   15055.000000   15055.000000  15055.000000  15055.000000  15055.000000   \n",
       "mean     8241.127532   15260.051938  19204.083254      1.829462     20.098439   \n",
       "std      7135.717864   13785.152507   2153.773552      0.336812      0.985753   \n",
       "min        15.000000      24.800000   6892.778929      0.547500     19.000000   \n",
       "25%      3235.500000    5698.000000  17414.197155      1.596241     19.000000   \n",
       "50%      6532.000000   11683.200000  19072.570490      1.821657     20.000000   \n",
       "75%     11104.000000   20707.450000  20576.154140      2.060000     21.000000   \n",
       "max    103280.000000  215666.400000  28621.861390      3.481132     23.000000   \n",
       "\n",
       "         MONTH           DAY  SupplyProvince  DemandProvince  \n",
       "count  15055.0  15055.000000    1.505500e+04    1.505500e+04  \n",
       "mean      12.0     15.780671    2.617008e+07    2.040207e+07  \n",
       "std        0.0      8.879310    2.328217e+07    1.675878e+07  \n",
       "min       12.0      1.000000    8.322200e+04    3.913950e+05  \n",
       "25%       12.0      8.000000    4.424703e+06    5.141045e+06  \n",
       "50%       12.0     16.000000    1.256251e+07    1.123831e+07  \n",
       "75%       12.0     23.000000    4.994253e+07    3.453131e+07  \n",
       "max       12.0     31.000000    6.499769e+07    5.193302e+07  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding the best number of bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of bins: 5 with F1 Score: 0.7085\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming df is your DataFrame\n",
    "prices = df['SALES PER KG']\n",
    "\n",
    "# Define the scoring function and the range of bin numbers to evaluate\n",
    "scoring_function = make_scorer(f1_score, average='weighted')\n",
    "bin_range = range(5, 16)  # Example range\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for bins in bin_range:\n",
    "    # Bin the data\n",
    "    df['price_bin'], bin_edges = pd.qcut(prices, q=bins, retbins=True, labels=False, duplicates='drop')\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = df.drop(['price_bin', 'SALES PER KG'], axis=1)  # Exclude target variable and original price column\n",
    "    y = df['price_bin']\n",
    "\n",
    "    # Define preprocessing for categorical variables (encode 'UNIT', 'CHICKEN SIZE', 'PROVINCE')\n",
    "    categorical_features = ['UNIT', 'CHICKEN SIZE', 'PROVINCE']\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features)],\n",
    "        remainder='passthrough'  # Passthrough numerical features as is\n",
    "    )\n",
    "\n",
    "    # Create the modeling pipeline\n",
    "    model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('classifier', xgb.XGBClassifier(objective='multi:softmax',\n",
    "                                                             num_class=bins,\n",
    "                                                             max_depth=5,\n",
    "                                                             eval_metric='mlogloss',\n",
    "                                                             use_label_encoder=False,\n",
    "                                                             seed=42))])\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X, y, cv=cv, scoring=scoring_function)\n",
    "    \n",
    "    # Store the average cross-validation score\n",
    "    cv_results[bins] = np.mean(cv_scores)\n",
    "\n",
    "# Find the number of bins with the best average F1 score\n",
    "best_bin_number = max(cv_results, key=cv_results.get)\n",
    "print(f\"Best number of bins: {best_bin_number} with F1 Score: {cv_results[best_bin_number]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin ranges: ['6892.78-16566.99', '16566.99-16850.00', '16850.00-17150.00', '17150.00-17500.00', '17500.00-17996.05', '17996.05-18496.56', '18496.56-18931.05', '18931.05-19327.07', '19327.07-19619.88', '19619.88-20049.18', '20049.18-20473.68', '20473.68-20973.08', '20973.08-21529.92', '21529.92-22555.13', '22555.13-28621.86']\n"
     ]
    }
   ],
   "source": [
    "# Creating bin labels and ranges for better understanding\n",
    "bin_labels = [f\"{bin_edges[i]:.2f}-{bin_edges[i+1]:.2f}\" for i in range(len(bin_edges)-1)]\n",
    "print(\"Bin ranges:\", bin_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split before label encoding to prevent data leakage\n",
    "\n",
    "\n",
    "X = df.drop('price_bin', axis=1)\n",
    "y = df['price_bin']\n",
    "\n",
    "# removing classes that have samples less than 2\n",
    "threshold = 2\n",
    "class_counts = y.value_counts()\n",
    "small_classes = class_counts[class_counts < threshold].index\n",
    "\n",
    "# removing samples belonging to small classes\n",
    "y_filtered = y[~y.isin(small_classes)]\n",
    "X_filtered = X.loc[y_filtered.index]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# checking for any nan values after splitting\n",
    "print(X_train.isna().sum())\n",
    "print(X_test.isna().sum())\n",
    "print(y_train.isna().sum())\n",
    "print(y_test.isna().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Perform cross-validation\u001b[39;00m\n\u001b[1;32m     26\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Store the average cross-validation score\u001b[39;00m\n\u001b[1;32m     30\u001b[0m cv_results[bins] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cv_scores)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/xgboost/sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1491\u001b[0m (\n\u001b[1;32m   1492\u001b[0m     model,\n\u001b[1;32m   1493\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1499\u001b[0m )\n\u001b[1;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1517\u001b[0m )\n\u001b[0;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/xgboost/core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     _check_call(\n\u001b[0;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2054\u001b[0m     )\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prices = df['SALES PER KG']\n",
    "\n",
    "# Define a range of possible bin numbers\n",
    "bin_range = range(5, 16)  # for example, from 2 to 20 bins\n",
    "\n",
    "# Define a scoring function, e.g., F1 score\n",
    "scoring_function = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# Prepare a dictionary to hold cross-validation results\n",
    "cv_results = {}\n",
    "\n",
    "for bins in bin_range:\n",
    "    # Bin the data\n",
    "    df['price_bin'], bin_edges = pd.qcut(prices, q=bins, retbins=True, labels=False, duplicates='drop')\n",
    "    \n",
    "    X = df\n",
    "    X_encoded = pd.get_dummies(X, columns=['UNIT', 'CHICKEN SIZE', 'PROVINCE'])\n",
    "    y = df['price_bin']  # your newly binned target variable\n",
    "    # One-hot encode categorical variables\n",
    "\n",
    "\n",
    "    # Initialize XGBClassifier (or any other model you're using)\n",
    "    model = xgb.XGBClassifier(objective='multi:softmax', num_class=bins, max_depth = 5, enable_categorical=True,)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_encoded, y, cv=cv, scoring=scoring_function)\n",
    "    \n",
    "    # Store the average cross-validation score\n",
    "    cv_results[bins] = np.mean(cv_scores)\n",
    "\n",
    "# Find the number of bins with the best average F1 score\n",
    "best_bin_number = max(cv_results, key=cv_results.get)\n",
    "print(f\"Best number of bins: {best_bin_number} with F1 Score: {cv_results[best_bin_number]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIT              0\n",
      "TAILS             0\n",
      "KG                0\n",
      "CHICKEN SIZE      0\n",
      "PROVINCE          0\n",
      "YEAR              0\n",
      "MONTH             0\n",
      "DAY               0\n",
      "SupplyProvince    0\n",
      "DemandProvince    0\n",
      "dtype: int64\n",
      "UNIT              0\n",
      "TAILS             0\n",
      "KG                0\n",
      "CHICKEN SIZE      0\n",
      "PROVINCE          0\n",
      "YEAR              0\n",
      "MONTH             0\n",
      "DAY               0\n",
      "SupplyProvince    0\n",
      "DemandProvince    0\n",
      "dtype: int64\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UNIT, TAILS, KG, CHICKEN SIZE, PROVINCE, YEAR, MONTH, DAY, SupplyProvince, DemandProvince]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out the nan rows in the x_train dataset\n",
    "X_train[X_train.isna().any(axis=1)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling numerical variable\n",
    "\n",
    "scaler = StandardScaler()\n",
    "columns_to_scale = ['KG', 'TAILS', 'SupplyProvince', 'DemandProvince']\n",
    "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>KARANGASEM</td>\n",
       "      <td>-0.872846</td>\n",
       "      <td>-0.862323</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>BALI</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.916943</td>\n",
       "      <td>-0.924149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9726</th>\n",
       "      <td>BALIKPAPAN</td>\n",
       "      <td>0.059049</td>\n",
       "      <td>0.155902</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>KALIMANTAN TIMUR</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.022624</td>\n",
       "      <td>-0.962814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13769</th>\n",
       "      <td>BOJONEGORO</td>\n",
       "      <td>-0.933067</td>\n",
       "      <td>-0.870435</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>JAWA TIMUR</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>0.090720</td>\n",
       "      <td>0.850420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10131</th>\n",
       "      <td>BOJONEGORO</td>\n",
       "      <td>0.263272</td>\n",
       "      <td>-0.058983</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>JAWA TIMUR</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.090720</td>\n",
       "      <td>0.850420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10643</th>\n",
       "      <td>DEMAK</td>\n",
       "      <td>0.689839</td>\n",
       "      <td>0.455114</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.789468</td>\n",
       "      <td>0.287419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>KARANGASEM</td>\n",
       "      <td>0.852101</td>\n",
       "      <td>0.913293</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>BALI</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.916943</td>\n",
       "      <td>-0.924149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13419</th>\n",
       "      <td>BANGKINANG</td>\n",
       "      <td>0.396957</td>\n",
       "      <td>0.330484</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>RIAU</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.763180</td>\n",
       "      <td>-0.872158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>SERANG</td>\n",
       "      <td>-0.269240</td>\n",
       "      <td>-0.542749</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>BANTEN</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.468474</td>\n",
       "      <td>-0.454299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>SUBANG(P)</td>\n",
       "      <td>1.897051</td>\n",
       "      <td>1.165433</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1.671334</td>\n",
       "      <td>1.891485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>SINGOSARI</td>\n",
       "      <td>-0.367378</td>\n",
       "      <td>-0.458573</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>JAWA TIMUR</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0.344926</td>\n",
       "      <td>1.276895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12043 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             UNIT     TAILS        KG CHICKEN SIZE          PROVINCE  YEAR  \\\n",
       "6463   KARANGASEM -0.872846 -0.862323       MEDIUM              BALI  2020   \n",
       "9726   BALIKPAPAN  0.059049  0.155902        LARGE  KALIMANTAN TIMUR  2021   \n",
       "13769  BOJONEGORO -0.933067 -0.870435        LARGE        JAWA TIMUR  2021   \n",
       "10131  BOJONEGORO  0.263272 -0.058983        SMALL        JAWA TIMUR  2021   \n",
       "10643       DEMAK  0.689839  0.455114       MEDIUM       JAWA TENGAH  2021   \n",
       "...           ...       ...       ...          ...               ...   ...   \n",
       "5192   KARANGASEM  0.852101  0.913293       MEDIUM              BALI  2020   \n",
       "13419  BANGKINANG  0.396957  0.330484       MEDIUM              RIAU  2021   \n",
       "5391       SERANG -0.269240 -0.542749        SMALL            BANTEN  2020   \n",
       "860     SUBANG(P)  1.897051  1.165433        SMALL        JAWA BARAT  2019   \n",
       "7271    SINGOSARI -0.367378 -0.458573       MEDIUM        JAWA TIMUR  2020   \n",
       "\n",
       "       MONTH  DAY  SupplyProvince  DemandProvince  \n",
       "6463      12   10       -0.916943       -0.924149  \n",
       "9726      12    2       -1.022624       -0.962814  \n",
       "13769     12   27        0.090720        0.850420  \n",
       "10131     12    4        0.090720        0.850420  \n",
       "10643     12    7        0.789468        0.287419  \n",
       "...      ...  ...             ...             ...  \n",
       "5192      12    1       -0.916943       -0.924149  \n",
       "13419     12   24       -0.763180       -0.872158  \n",
       "5391      12    2       -0.468474       -0.454299  \n",
       "860       12    5        1.671334        1.891485  \n",
       "7271      12   16        0.344926        1.276895  \n",
       "\n",
       "[12043 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to evaluate the model\n",
    "def results(y_test, predictions):\n",
    "  mae = mean_absolute_error(y_test, predictions)\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "  rmse = np.sqrt(mse)\n",
    "  r2 = r2_score(y_test, predictions)\n",
    "\n",
    "  print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "  print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "  print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "  print(f\"R-squared (R²): {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding of columns\n",
    "# label encoding for province\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "X_train['SIZE ENCODE'] = label_encoder.fit_transform(X_train['CHICKEN SIZE'])\n",
    "X_test['SIZE ENCODE'] = label_encoder.transform(X_test['CHICKEN SIZE'])\n",
    "\n",
    "# dropping chicken size column\n",
    "X_train = X_train.drop(['CHICKEN SIZE'], axis = 1)\n",
    "X_test = X_test.drop(['CHICKEN SIZE'], axis = 1)\n",
    "\n",
    "\n",
    "# one hot encoding for province\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X_train[['PROVINCE']])\n",
    "X_train_encoded = encoder.transform(X_train[['PROVINCE']])\n",
    "X_test_encoded = encoder.transform(X_test[['PROVINCE']])\n",
    "\n",
    "# Convert the encoded matrices back to dataframes for easier manipulation\n",
    "columns = encoder.get_feature_names_out(['PROVINCE'])\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded.toarray(), columns=columns, index=X_train.index)\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded.toarray(), columns=columns, index=X_test.index)\n",
    "\n",
    "# merge back the dataframe\n",
    "X_train = pd.concat([X_train.drop('PROVINCE', axis=1), X_train_encoded_df], axis=1)\n",
    "X_test = pd.concat([X_test.drop('PROVINCE', axis=1), X_test_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# one hot encoding for unit\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X_train[['UNIT']])\n",
    "X_train_encoded_unit = encoder.transform(X_train[['UNIT']])\n",
    "X_test_encoded_unit = encoder.transform(X_test[['UNIT']])\n",
    "\n",
    "# Convert the encoded matrices back to dataframes for easier manipulation\n",
    "columns = encoder.get_feature_names_out(['UNIT'])\n",
    "X_train_encoded_df_unit = pd.DataFrame(X_train_encoded_unit.toarray(), columns=columns, index=X_train.index)\n",
    "X_test_encoded_df_unit = pd.DataFrame(X_test_encoded_unit.toarray(), columns=columns, index=X_test.index)\n",
    "\n",
    "# merge back the dataframe, dropping unit column\n",
    "X_train = pd.concat([X_train.drop('UNIT', axis=1), X_train_encoded_df_unit], axis=1)\n",
    "X_test = pd.concat([X_test.drop('UNIT', axis=1), X_test_encoded_df_unit], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying lazy predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lazypredict in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.2.12)\n",
      "Requirement already satisfied: click in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (8.1.7)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (1.4.1.post1)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from lazypredict) (2.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (4.66.2)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from lazypredict) (1.3.2)\n",
      "Requirement already satisfied: lightgbm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (4.3.0)\n",
      "Requirement already satisfied: xgboost in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (2.0.3)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from lightgbm->lazypredict) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from lightgbm->lazypredict) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->lazypredict) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.16.0)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.utils import all_estimators\\nfrom sklearn.base import RegressorMixin'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libraries\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "'''from sklearn.utils import all_estimators\n",
    "from sklearn.base import RegressorMixin'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AdaBoostClassifier', <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>), ('BaggingClassifier', <class 'sklearn.ensemble._bagging.BaggingClassifier'>), ('BernoulliNB', <class 'sklearn.naive_bayes.BernoulliNB'>), ('CalibratedClassifierCV', <class 'sklearn.calibration.CalibratedClassifierCV'>), ('CategoricalNB', <class 'sklearn.naive_bayes.CategoricalNB'>), ('DecisionTreeClassifier', <class 'sklearn.tree._classes.DecisionTreeClassifier'>), ('DummyClassifier', <class 'sklearn.dummy.DummyClassifier'>), ('ExtraTreeClassifier', <class 'sklearn.tree._classes.ExtraTreeClassifier'>), ('ExtraTreesClassifier', <class 'sklearn.ensemble._forest.ExtraTreesClassifier'>), ('GaussianNB', <class 'sklearn.naive_bayes.GaussianNB'>), ('KNeighborsClassifier', <class 'sklearn.neighbors._classification.KNeighborsClassifier'>), ('LabelPropagation', <class 'sklearn.semi_supervised._label_propagation.LabelPropagation'>), ('LabelSpreading', <class 'sklearn.semi_supervised._label_propagation.LabelSpreading'>), ('LinearDiscriminantAnalysis', <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>), ('LinearSVC', <class 'sklearn.svm._classes.LinearSVC'>), ('LogisticRegression', <class 'sklearn.linear_model._logistic.LogisticRegression'>), ('NearestCentroid', <class 'sklearn.neighbors._nearest_centroid.NearestCentroid'>), ('NuSVC', <class 'sklearn.svm._classes.NuSVC'>), ('PassiveAggressiveClassifier', <class 'sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier'>), ('Perceptron', <class 'sklearn.linear_model._perceptron.Perceptron'>), ('QuadraticDiscriminantAnalysis', <class 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'>), ('RandomForestClassifier', <class 'sklearn.ensemble._forest.RandomForestClassifier'>), ('RidgeClassifier', <class 'sklearn.linear_model._ridge.RidgeClassifier'>), ('RidgeClassifierCV', <class 'sklearn.linear_model._ridge.RidgeClassifierCV'>), ('SGDClassifier', <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>), ('SVC', <class 'sklearn.svm._classes.SVC'>), ('StackingClassifier', <class 'sklearn.ensemble._stacking.StackingClassifier'>), ('XGBClassifier', <class 'xgboost.sklearn.XGBClassifier'>), ('LGBMClassifier', <class 'lightgbm.sklearn.LGBMClassifier'>)]\n"
     ]
    }
   ],
   "source": [
    "print(lazypredict.Supervised.CLASSIFIERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    chosen_regressors = [\n",
    "    'SVR', \n",
    "    'BaggingRegressor',\n",
    "    'ExtraTreesRegressor',\n",
    "    'RandomForestRegressor',\n",
    "    'GradientBoostingRegressor',\n",
    "    'LGBMRegressor',\n",
    "    'XGBRegressor',\n",
    "    'CatBoostRegressor',\n",
    "    'HistGradientBoostingRegressor',\n",
    "    'AdaBoostRegressor',\n",
    "    'KNeighborsRegressor',\n",
    "    'DecisionTreeRegressor'\n",
    "]\n",
    "\n",
    "REGRESSORS = [\n",
    "    est\n",
    "    for est in all_estimators()\n",
    "    if (issubclass(est[1], RegressorMixin) and est[0] in chosen_regressors)\n",
    "\n",
    "]'''\n",
    "\n",
    "# initialising the regressor with chosen regressors\n",
    "reg = LazyClassifier(verbose=1, ignore_warnings=False, custom_metric=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/29 [00:00<00:24,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for AdaBoostClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n",
      "{'Model': 'AdaBoostClassifier', 'Accuracy': 0.41149119893723013, 'Balanced Accuracy': 0.1354976736437217, 'ROC AUC': None, 'F1 Score': 0.32996162485507313, 'Time taken': 0.8639228343963623}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/29 [00:01<00:20,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for BaggingClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n",
      "{'Model': 'BaggingClassifier', 'Accuracy': 0.7499169711059449, 'Balanced Accuracy': 0.429473765876953, 'ROC AUC': None, 'F1 Score': 0.746572114415542, 'Time taken': 0.6885628700256348}\n",
      "ROC AUC couldn't be calculated for BernoulliNB\n",
      "multi_class must be in ('ovo', 'ovr')\n",
      "{'Model': 'BernoulliNB', 'Accuracy': 0.40983062105612755, 'Balanced Accuracy': 0.24126230101466106, 'ROC AUC': None, 'F1 Score': 0.4031425749212721, 'Time taken': 0.08809232711791992}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fitting and evaluate models\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out the top 5 models\n",
    "top_5_models = models.head(5)\n",
    "top_5_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.91%\n",
      "Confusion Matrix:\n",
      "[[  0   0   0   0   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   2   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0   0   0   0   0]\n",
      " [  0   1   1  25  15   4   1   0   0   0   0   0]\n",
      " [  0   1   0  50 507  99  24  11   4   5   0   0]\n",
      " [  1   1   2  25 148 470 111  34  25   4   1   0]\n",
      " [  0   0   0   5  30  95 513 141  58   5   2   0]\n",
      " [  0   0   0   1   4   8  63 237  79  10   0   0]\n",
      " [  0   0   0   1   4   4   4  29  79   8   0   0]\n",
      " [  0   0   0   0   0   0   0   5  12  32   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.23      0.53      0.32        47\n",
      "           5       0.71      0.72      0.72       701\n",
      "           6       0.69      0.57      0.62       822\n",
      "           7       0.72      0.60      0.66       849\n",
      "           8       0.52      0.59      0.55       402\n",
      "           9       0.30      0.61      0.41       129\n",
      "          10       0.50      0.65      0.57        49\n",
      "          11       0.25      0.33      0.29         3\n",
      "          12       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      3011\n",
      "   macro avg       0.33      0.38      0.34      3011\n",
      "weighted avg       0.65      0.62      0.63      3011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# trying XGBM model\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label encoding the target variable\n",
    "label_encoder = LabelEncoder().fit(y_train_resampled)  # Fit on y_train to learn all classes\n",
    "y_train_encoded = label_encoder.transform(y_train_resampled)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Dynamically set the number of classes\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "\n",
    "\n",
    "# Specify the parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # Specify multi-class classification\n",
    "    'num_class': num_classes,  # Dynamically set the number of classes\n",
    "    'max_depth': 4,  # Depth of the trees\n",
    "    'learning_rate': 0.1,  # Learning rate\n",
    "    'n_estimators': 100,  # Number of trees\n",
    "    'seed': 42  # Random seed for reproducibility\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "# Train the model with encoded targets\n",
    "clf.fit(X_train_resampled, y_train_encoded)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# getting unique classes for predicted labels\n",
    "unique_y_test = np.unique(y_test_encoded)\n",
    "unique_y_pred = np.unique(y_pred)\n",
    "\n",
    "# get unique classes \n",
    "all_unique_classes = np.unique(np.concatenate((y_test_encoded, y_pred)))\n",
    "\n",
    "# map the unique encoded classes back to original names\n",
    "target_names_adjusted = label_encoder.inverse_transform(all_unique_classes)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_encoded, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "using entity embeddings to train the neural network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting up the model\n",
    "creating entity embeddings <br>\n",
    "`cat_col1` = `PROVINCE` <br>\n",
    "`cat_col2` = `CHICKEN SIZE` <br>\n",
    "`cat_col3` = `SIZE` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset `df`\n",
    "\n",
    "# importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Reshape, Concatenate, Dense, Flatten\n",
    "\n",
    "# getting the unique values of the categorical columns\n",
    "cat_columns = ['PROVINCE', 'CHICKEN SIZE', 'UNIT']\n",
    "unique_cat1 = df['PROVINCE'].nunique()\n",
    "unique_cat2 = df['CHICKEN SIZE'].nunique()\n",
    "unique_cat3 = df['UNIT'].nunique()\n",
    "\n",
    "# getting numerical columns\n",
    "num_columns = df.columns.difference(cat_columns)\n",
    "numerical_data = df[num_columns]\n",
    "\n",
    "# scaling the numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
    "\n",
    "# defining the input layer\n",
    "num_input = Input(shape=(numerical_data_scaled.shape[1],), name='num_input')\n",
    "\n",
    "# embedding the categorical columns\n",
    "cat_input1 = Input(shape = (1,), name='cat_input1')\n",
    "cat_embed1 = Embedding(input_dim=unique_cat1, output_dim = int(min(np.ceil(unique_cat1 /2), 50)))(cat_input1)\n",
    "cat_embed1 = Flatten()(cat_embed1)\n",
    "\n",
    "cat_input2 = Input(shape = (1,), name='cat_input2')\n",
    "cat_embed2 = Embedding(input_dim=unique_cat2, output_dim = int(min(np.ceil(unique_cat2 /2), 50)))(cat_input2)\n",
    "cat_embed2 = Flatten()(cat_embed2)\n",
    "\n",
    "\n",
    "cat_input3 = Input(shape = (1,), name='cat_input3')\n",
    "cat_embed3 = Embedding(input_dim=unique_cat3, output_dim = int(min(np.ceil(unique_cat3 /2), 50)))(cat_input3)\n",
    "cat_embed3 = Flatten()(cat_embed3)\n",
    "\n",
    "\n",
    "# concatenate the embeddings with numerical input\n",
    "concatenated = Concatenate()([cat_embed1, cat_embed2, cat_embed3, num_input])\n",
    "\n",
    "\n",
    "# adding the dense layer ontop of the embeddings\n",
    "dense_output = Dense(128, activation = 'relu')(concatenated)\n",
    "dense_output = Dense(64, activation = 'relu')(dense_output)\n",
    "output = Dense(1)(dense_output)\n",
    "\n",
    "# creating the model\n",
    "model = Model(inputs = [cat_input1, cat_input2, cat_input3, num_input], outputs = output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "X_train_cat1 = X_train['PROVINCE']\n",
    "X_train_cat2 = X_train['CHICKEN SIZE']\n",
    "X_train_cat3 = X_train['UNIT']\n",
    "X_train_num = X_train.drop(['PROVINCE', 'CHICKEN SIZE', 'UNIT'], axis = 1)\n",
    "\n",
    "# fitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Single output node for regression\n",
    "])\n",
    "\n",
    "# Compile the model, specifying the optimizer, loss function, and metric\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Fit the model on the training data\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, epochs=100, verbose=1)\n",
    "\n",
    "# Predict the target on the testing set\n",
    "predictions = model.predict(X_test).flatten()\n",
    "\n",
    "# Evaluate the model performance using RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# You can plot the training history to check how the loss and metric evolved over epochs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
