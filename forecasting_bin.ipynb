{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forecasting selling price of chicken with Bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing the relevant libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "#!pip install category_encoders\n",
    "import category_encoders as ce\n",
    "from category_encoders import TargetEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>SALES PER KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYAKUMBUH</td>\n",
       "      <td>1267</td>\n",
       "      <td>2856.0</td>\n",
       "      <td>18000.00000</td>\n",
       "      <td>2.254144</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3885216</td>\n",
       "      <td>5993194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINJAI</td>\n",
       "      <td>3310</td>\n",
       "      <td>7799.5</td>\n",
       "      <td>22637.89730</td>\n",
       "      <td>2.356344</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5447863</td>\n",
       "      <td>5931514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANDAR JAYA</td>\n",
       "      <td>8236</td>\n",
       "      <td>22197.0</td>\n",
       "      <td>15905.01419</td>\n",
       "      <td>2.695119</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANDAR LAMPUNG</td>\n",
       "      <td>2565</td>\n",
       "      <td>4971.0</td>\n",
       "      <td>18060.47073</td>\n",
       "      <td>1.938012</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANYUASIN</td>\n",
       "      <td>696</td>\n",
       "      <td>1464.4</td>\n",
       "      <td>16368.88828</td>\n",
       "      <td>2.104023</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5758528</td>\n",
       "      <td>7021239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             UNIT  TAILS       KG  SALES PER KG       ABW CHICKEN SIZE  \\\n",
       "0      PAYAKUMBUH   1267   2856.0   18000.00000  2.254144        LARGE   \n",
       "1          SINJAI   3310   7799.5   22637.89730  2.356344        LARGE   \n",
       "2     BANDAR JAYA   8236  22197.0   15905.01419  2.695119        LARGE   \n",
       "3  BANDAR LAMPUNG   2565   4971.0   18060.47073  1.938012       MEDIUM   \n",
       "4       BANYUASIN    696   1464.4   16368.88828  2.104023        LARGE   \n",
       "\n",
       "           PROVINCE  YEAR  MONTH  DAY  SupplyProvince  DemandProvince  \n",
       "0    SUMATERA BARAT    19     12    1         3885216         5993194  \n",
       "1  SULAWESI SELATAN    19     12    1         5447863         5931514  \n",
       "2           LAMPUNG    19     12    1         5404511         5618463  \n",
       "3           LAMPUNG    19     12    1         5404511         5618463  \n",
       "4  SUMATERA SELATAN    19     12    1         5758528         7021239  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading file\n",
    "df = pd.read_csv('/workspaces/forecasting/data/final.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>SALES PER KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.0</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>1.505500e+04</td>\n",
       "      <td>1.505500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8241.127532</td>\n",
       "      <td>15260.051938</td>\n",
       "      <td>19204.083254</td>\n",
       "      <td>1.829462</td>\n",
       "      <td>20.098439</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.780671</td>\n",
       "      <td>2.617008e+07</td>\n",
       "      <td>2.040207e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7135.717864</td>\n",
       "      <td>13785.152507</td>\n",
       "      <td>2153.773552</td>\n",
       "      <td>0.336812</td>\n",
       "      <td>0.985753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.879310</td>\n",
       "      <td>2.328217e+07</td>\n",
       "      <td>1.675878e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>6892.778929</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.322200e+04</td>\n",
       "      <td>3.913950e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3235.500000</td>\n",
       "      <td>5698.000000</td>\n",
       "      <td>17414.197155</td>\n",
       "      <td>1.596241</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.424703e+06</td>\n",
       "      <td>5.141045e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6532.000000</td>\n",
       "      <td>11683.200000</td>\n",
       "      <td>19072.570490</td>\n",
       "      <td>1.821657</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.256251e+07</td>\n",
       "      <td>1.123831e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11104.000000</td>\n",
       "      <td>20707.450000</td>\n",
       "      <td>20576.154140</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.994253e+07</td>\n",
       "      <td>3.453131e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>103280.000000</td>\n",
       "      <td>215666.400000</td>\n",
       "      <td>28621.861390</td>\n",
       "      <td>3.481132</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.499769e+07</td>\n",
       "      <td>5.193302e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TAILS             KG  SALES PER KG           ABW          YEAR  \\\n",
       "count   15055.000000   15055.000000  15055.000000  15055.000000  15055.000000   \n",
       "mean     8241.127532   15260.051938  19204.083254      1.829462     20.098439   \n",
       "std      7135.717864   13785.152507   2153.773552      0.336812      0.985753   \n",
       "min        15.000000      24.800000   6892.778929      0.547500     19.000000   \n",
       "25%      3235.500000    5698.000000  17414.197155      1.596241     19.000000   \n",
       "50%      6532.000000   11683.200000  19072.570490      1.821657     20.000000   \n",
       "75%     11104.000000   20707.450000  20576.154140      2.060000     21.000000   \n",
       "max    103280.000000  215666.400000  28621.861390      3.481132     23.000000   \n",
       "\n",
       "         MONTH           DAY  SupplyProvince  DemandProvince  \n",
       "count  15055.0  15055.000000    1.505500e+04    1.505500e+04  \n",
       "mean      12.0     15.780671    2.617008e+07    2.040207e+07  \n",
       "std        0.0      8.879310    2.328217e+07    1.675878e+07  \n",
       "min       12.0      1.000000    8.322200e+04    3.913950e+05  \n",
       "25%       12.0      8.000000    4.424703e+06    5.141045e+06  \n",
       "50%       12.0     16.000000    1.256251e+07    1.123831e+07  \n",
       "75%       12.0     23.000000    4.994253e+07    3.453131e+07  \n",
       "max       12.0     31.000000    6.499769e+07    5.193302e+07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding the best number of bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of bins: 5 with F1 Score: 0.7085\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming df is your DataFrame\n",
    "prices = df['SALES PER KG']\n",
    "\n",
    "# Define the scoring function and the range of bin numbers to evaluate\n",
    "scoring_function = make_scorer(f1_score, average='weighted')\n",
    "bin_range = range(5, 16)  # Example range\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for bins in bin_range:\n",
    "    # making a copy of the original dataframe such that the original dataframe is not affected\n",
    "    dfCopy = df.copy()\n",
    "    # Bin the data\n",
    "    dfCopy['price_bin'], bin_edges = pd.qcut(prices, q=bins, retbins=True, labels=False, duplicates='drop')\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = dfCopy.drop(['price_bin', 'SALES PER KG'], axis=1)  # Exclude target variable and original price column\n",
    "    y = dfCopy['price_bin']\n",
    "\n",
    "    # Define preprocessing for categorical variables (encode 'UNIT', 'CHICKEN SIZE', 'PROVINCE')\n",
    "    categorical_features = ['UNIT', 'CHICKEN SIZE', 'PROVINCE']\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features)],\n",
    "        remainder='passthrough'  # Passthrough numerical features as is\n",
    "    )\n",
    "\n",
    "    # Create the modeling pipeline\n",
    "    model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('classifier', xgb.XGBClassifier(objective='multi:softmax',\n",
    "                                                             num_class=bins,\n",
    "                                                             max_depth=5,\n",
    "                                                             eval_metric='mlogloss',\n",
    "                                                             use_label_encoder=False,\n",
    "                                                             seed=42))])\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X, y, cv=cv, scoring=scoring_function)\n",
    "    \n",
    "    # Store the average cross-validation score\n",
    "    cv_results[bins] = np.mean(cv_scores)\n",
    "\n",
    "# Find the number of bins with the best average F1 score\n",
    "best_bin_number = max(cv_results, key=cv_results.get)\n",
    "print(f\"Best number of bins: {best_bin_number} with F1 Score: {cv_results[best_bin_number]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best number of bins is 5, highest F1 score of 0.7085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "      <th>price_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYAKUMBUH</td>\n",
       "      <td>1267</td>\n",
       "      <td>2856.0</td>\n",
       "      <td>2.254144</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3885216</td>\n",
       "      <td>5993194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINJAI</td>\n",
       "      <td>3310</td>\n",
       "      <td>7799.5</td>\n",
       "      <td>2.356344</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5447863</td>\n",
       "      <td>5931514</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANDAR JAYA</td>\n",
       "      <td>8236</td>\n",
       "      <td>22197.0</td>\n",
       "      <td>2.695119</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANDAR LAMPUNG</td>\n",
       "      <td>2565</td>\n",
       "      <td>4971.0</td>\n",
       "      <td>1.938012</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANYUASIN</td>\n",
       "      <td>696</td>\n",
       "      <td>1464.4</td>\n",
       "      <td>2.104023</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5758528</td>\n",
       "      <td>7021239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15050</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>430</td>\n",
       "      <td>901.4</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15051</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>294</td>\n",
       "      <td>605.0</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15052</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>432</td>\n",
       "      <td>962.4</td>\n",
       "      <td>2.230000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15053</th>\n",
       "      <td>GUNUNGKIDUL</td>\n",
       "      <td>200</td>\n",
       "      <td>370.8</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>DI YOGYAKARTA</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3993820</td>\n",
       "      <td>5186026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15054</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>400</td>\n",
       "      <td>865.8</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15055 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 UNIT  TAILS       KG       ABW CHICKEN SIZE  \\\n",
       "0          PAYAKUMBUH   1267   2856.0  2.254144        LARGE   \n",
       "1              SINJAI   3310   7799.5  2.356344        LARGE   \n",
       "2         BANDAR JAYA   8236  22197.0  2.695119        LARGE   \n",
       "3      BANDAR LAMPUNG   2565   4971.0  1.938012       MEDIUM   \n",
       "4           BANYUASIN    696   1464.4  2.104023        LARGE   \n",
       "...               ...    ...      ...       ...          ...   \n",
       "15050        BOYOLALI    430    901.4  2.100000          BIG   \n",
       "15051        BOYOLALI    294    605.0  2.060000          BIG   \n",
       "15052        BOYOLALI    432    962.4  2.230000          BIG   \n",
       "15053     GUNUNGKIDUL    200    370.8  1.850000       MEDIUM   \n",
       "15054        BOYOLALI    400    865.8  2.160000          BIG   \n",
       "\n",
       "               PROVINCE  YEAR  MONTH  DAY  SupplyProvince  DemandProvince  \\\n",
       "0        SUMATERA BARAT    19     12    1         3885216         5993194   \n",
       "1      SULAWESI SELATAN    19     12    1         5447863         5931514   \n",
       "2               LAMPUNG    19     12    1         5404511         5618463   \n",
       "3               LAMPUNG    19     12    1         5404511         5618463   \n",
       "4      SUMATERA SELATAN    19     12    1         5758528         7021239   \n",
       "...                 ...   ...    ...  ...             ...             ...   \n",
       "15050       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "15051       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "15052       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "15053     DI YOGYAKARTA    23     12   31         3993820         5186026   \n",
       "15054       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "\n",
       "       price_bin  \n",
       "0              1  \n",
       "1              4  \n",
       "2              0  \n",
       "3              1  \n",
       "4              0  \n",
       "...          ...  \n",
       "15050          0  \n",
       "15051          0  \n",
       "15052          0  \n",
       "15053          0  \n",
       "15054          0  \n",
       "\n",
       "[15055 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing quantile based binning\n",
    "df['price_bin'], bin_edges = pd.qcut(prices, q=best_bin_number, retbins=True, labels=False, duplicates='drop')\n",
    "df.drop(['SALES PER KG'], axis=1, inplace=True) # redundant \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin ranges: ['6892.78-17150.00', '17150.00-18496.56', '18496.56-19619.88', '19619.88-20973.08', '20973.08-28621.86']\n"
     ]
    }
   ],
   "source": [
    "# Creating bin labels and ranges for better understanding\n",
    "bin_labels = [f\"{bin_edges[i]:.2f}-{bin_edges[i+1]:.2f}\" for i in range(len(bin_edges)-1)]\n",
    "print(\"Bin ranges:\", bin_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "      <th>price_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYAKUMBUH</td>\n",
       "      <td>1267</td>\n",
       "      <td>2856.0</td>\n",
       "      <td>2.254144</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3885216</td>\n",
       "      <td>5993194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINJAI</td>\n",
       "      <td>3310</td>\n",
       "      <td>7799.5</td>\n",
       "      <td>2.356344</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5447863</td>\n",
       "      <td>5931514</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANDAR JAYA</td>\n",
       "      <td>8236</td>\n",
       "      <td>22197.0</td>\n",
       "      <td>2.695119</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANDAR LAMPUNG</td>\n",
       "      <td>2565</td>\n",
       "      <td>4971.0</td>\n",
       "      <td>1.938012</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANYUASIN</td>\n",
       "      <td>696</td>\n",
       "      <td>1464.4</td>\n",
       "      <td>2.104023</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5758528</td>\n",
       "      <td>7021239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15050</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>430</td>\n",
       "      <td>901.4</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15051</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>294</td>\n",
       "      <td>605.0</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15052</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>432</td>\n",
       "      <td>962.4</td>\n",
       "      <td>2.230000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15053</th>\n",
       "      <td>GUNUNGKIDUL</td>\n",
       "      <td>200</td>\n",
       "      <td>370.8</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>DI YOGYAKARTA</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3993820</td>\n",
       "      <td>5186026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15054</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>400</td>\n",
       "      <td>865.8</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15055 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 UNIT  TAILS       KG       ABW CHICKEN SIZE  \\\n",
       "0          PAYAKUMBUH   1267   2856.0  2.254144        LARGE   \n",
       "1              SINJAI   3310   7799.5  2.356344        LARGE   \n",
       "2         BANDAR JAYA   8236  22197.0  2.695119        LARGE   \n",
       "3      BANDAR LAMPUNG   2565   4971.0  1.938012       MEDIUM   \n",
       "4           BANYUASIN    696   1464.4  2.104023        LARGE   \n",
       "...               ...    ...      ...       ...          ...   \n",
       "15050        BOYOLALI    430    901.4  2.100000          BIG   \n",
       "15051        BOYOLALI    294    605.0  2.060000          BIG   \n",
       "15052        BOYOLALI    432    962.4  2.230000          BIG   \n",
       "15053     GUNUNGKIDUL    200    370.8  1.850000       MEDIUM   \n",
       "15054        BOYOLALI    400    865.8  2.160000          BIG   \n",
       "\n",
       "               PROVINCE  YEAR  MONTH  DAY  SupplyProvince  DemandProvince  \\\n",
       "0        SUMATERA BARAT    19     12    1         3885216         5993194   \n",
       "1      SULAWESI SELATAN    19     12    1         5447863         5931514   \n",
       "2               LAMPUNG    19     12    1         5404511         5618463   \n",
       "3               LAMPUNG    19     12    1         5404511         5618463   \n",
       "4      SUMATERA SELATAN    19     12    1         5758528         7021239   \n",
       "...                 ...   ...    ...  ...             ...             ...   \n",
       "15050       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "15051       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "15052       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "15053     DI YOGYAKARTA    23     12   31         3993820         5186026   \n",
       "15054       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "\n",
       "       price_bin  \n",
       "0              1  \n",
       "1              4  \n",
       "2              0  \n",
       "3              1  \n",
       "4              0  \n",
       "...          ...  \n",
       "15050          0  \n",
       "15051          0  \n",
       "15052          0  \n",
       "15053          0  \n",
       "15054          0  \n",
       "\n",
       "[15055 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting holiday data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>01/12/19</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02/12/19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>03/12/19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>04/12/19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>05/12/19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Date  Holiday\n",
       "0         NaN  01/12/19     True\n",
       "1         NaN  02/12/19    False\n",
       "2         NaN  03/12/19    False\n",
       "3         NaN  04/12/19    False\n",
       "4         NaN  05/12/19    False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading holiday dataset\n",
    "holiday = pd.read_csv('/workspaces/forecasting/data/holiday.csv')\n",
    "holiday.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Every Sunday is marked as a holiday as well as the whole month of Ramadan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    float64\n",
       "Date           object\n",
       "Holiday          bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holiday.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Holiday</th>\n",
       "      <th>DAY</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Holiday  DAY  MONTH  YEAR\n",
       "0        1    1     12    19\n",
       "1        0    2     12    19\n",
       "2        0    3     12    19\n",
       "3        0    4     12    19\n",
       "4        0    5     12    19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping unnecessary columns\n",
    "holiday = holiday.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# changing the date column to datetime\n",
    "holiday['Date'] = pd.to_datetime(holiday['Date'], format='%d/%m/%y')\n",
    "\n",
    "# splitting the date column into day, month and year\n",
    "holiday['DAY'] = holiday['Date'].dt.day\n",
    "holiday['MONTH'] = holiday['Date'].dt.month\n",
    "holiday['YEAR'] = holiday['Date'].dt.year\n",
    "holiday['YEAR'] = holiday['YEAR'] % 2000\n",
    "\n",
    "# changing the holiday column to object\n",
    "holiday['Holiday'] = holiday['Holiday'].astype(str)\n",
    "\n",
    "# changing values of holiday to numerical\n",
    "holiday['Holiday'] = holiday['Holiday'].map({'True': 1, 'False': 0})\n",
    "\n",
    "# drop date column\n",
    "holiday = holiday.drop('Date', axis=1)\n",
    "holiday.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "      <th>price_bin</th>\n",
       "      <th>Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYAKUMBUH</td>\n",
       "      <td>1267</td>\n",
       "      <td>2856.0</td>\n",
       "      <td>2.254144</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3885216</td>\n",
       "      <td>5993194</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINJAI</td>\n",
       "      <td>3310</td>\n",
       "      <td>7799.5</td>\n",
       "      <td>2.356344</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5447863</td>\n",
       "      <td>5931514</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANDAR JAYA</td>\n",
       "      <td>8236</td>\n",
       "      <td>22197.0</td>\n",
       "      <td>2.695119</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANDAR LAMPUNG</td>\n",
       "      <td>2565</td>\n",
       "      <td>4971.0</td>\n",
       "      <td>1.938012</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANYUASIN</td>\n",
       "      <td>696</td>\n",
       "      <td>1464.4</td>\n",
       "      <td>2.104023</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5758528</td>\n",
       "      <td>7021239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15050</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>430</td>\n",
       "      <td>901.4</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15051</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>294</td>\n",
       "      <td>605.0</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15052</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>432</td>\n",
       "      <td>962.4</td>\n",
       "      <td>2.230000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15053</th>\n",
       "      <td>GUNUNGKIDUL</td>\n",
       "      <td>200</td>\n",
       "      <td>370.8</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>DI YOGYAKARTA</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3993820</td>\n",
       "      <td>5186026</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15054</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>400</td>\n",
       "      <td>865.8</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15055 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 UNIT  TAILS       KG       ABW CHICKEN SIZE  \\\n",
       "0          PAYAKUMBUH   1267   2856.0  2.254144        LARGE   \n",
       "1              SINJAI   3310   7799.5  2.356344        LARGE   \n",
       "2         BANDAR JAYA   8236  22197.0  2.695119        LARGE   \n",
       "3      BANDAR LAMPUNG   2565   4971.0  1.938012       MEDIUM   \n",
       "4           BANYUASIN    696   1464.4  2.104023        LARGE   \n",
       "...               ...    ...      ...       ...          ...   \n",
       "15050        BOYOLALI    430    901.4  2.100000          BIG   \n",
       "15051        BOYOLALI    294    605.0  2.060000          BIG   \n",
       "15052        BOYOLALI    432    962.4  2.230000          BIG   \n",
       "15053     GUNUNGKIDUL    200    370.8  1.850000       MEDIUM   \n",
       "15054        BOYOLALI    400    865.8  2.160000          BIG   \n",
       "\n",
       "               PROVINCE  YEAR  MONTH  DAY  SupplyProvince  DemandProvince  \\\n",
       "0        SUMATERA BARAT    19     12    1         3885216         5993194   \n",
       "1      SULAWESI SELATAN    19     12    1         5447863         5931514   \n",
       "2               LAMPUNG    19     12    1         5404511         5618463   \n",
       "3               LAMPUNG    19     12    1         5404511         5618463   \n",
       "4      SUMATERA SELATAN    19     12    1         5758528         7021239   \n",
       "...                 ...   ...    ...  ...             ...             ...   \n",
       "15050       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "15051       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "15052       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "15053     DI YOGYAKARTA    23     12   31         3993820         5186026   \n",
       "15054       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "\n",
       "       price_bin  Holiday  \n",
       "0              1        1  \n",
       "1              4        1  \n",
       "2              0        1  \n",
       "3              1        1  \n",
       "4              0        1  \n",
       "...          ...      ...  \n",
       "15050          0        1  \n",
       "15051          0        1  \n",
       "15052          0        1  \n",
       "15053          0        1  \n",
       "15054          0        1  \n",
       "\n",
       "[15055 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging with main dataset, specifying custom suffixes\n",
    "df = pd.merge(df, holiday, left_on=['DAY', 'MONTH', 'YEAR'], right_on=['DAY', 'MONTH', 'YEAR'], how='left', suffixes=('', '_holiday'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting data with holiday\n",
    "df.to_csv('/workspaces/forecasting/data/final_holiday.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIT              0\n",
      "TAILS             0\n",
      "KG                0\n",
      "ABW               0\n",
      "CHICKEN SIZE      0\n",
      "PROVINCE          0\n",
      "YEAR              0\n",
      "MONTH             0\n",
      "DAY               0\n",
      "SupplyProvince    0\n",
      "DemandProvince    0\n",
      "Holiday           0\n",
      "dtype: int64\n",
      "UNIT              0\n",
      "TAILS             0\n",
      "KG                0\n",
      "ABW               0\n",
      "CHICKEN SIZE      0\n",
      "PROVINCE          0\n",
      "YEAR              0\n",
      "MONTH             0\n",
      "DAY               0\n",
      "SupplyProvince    0\n",
      "DemandProvince    0\n",
      "Holiday           0\n",
      "dtype: int64\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# train test split before label encoding to prevent data leakage\n",
    "\n",
    "\n",
    "X = df.drop('price_bin', axis=1)\n",
    "y = df['price_bin']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# checking for any nan values after splitting\n",
    "print(X_train.isna().sum())\n",
    "print(X_test.isna().sum())\n",
    "print(y_train.isna().sum())\n",
    "print(y_test.isna().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling numerical variable\n",
    "\n",
    "scaler = StandardScaler()\n",
    "columns_to_scale = ['KG', 'TAILS', 'SupplyProvince', 'DemandProvince']\n",
    "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "      <th>Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12179</th>\n",
       "      <td>SANGATTA</td>\n",
       "      <td>-0.868153</td>\n",
       "      <td>-0.903847</td>\n",
       "      <td>1.385429</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>KALIMANTAN TIMUR</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.024406</td>\n",
       "      <td>-0.964375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14448</th>\n",
       "      <td>SIJUNJUNG</td>\n",
       "      <td>-0.279093</td>\n",
       "      <td>-0.318778</td>\n",
       "      <td>1.739214</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.995010</td>\n",
       "      <td>-0.935591</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13769</th>\n",
       "      <td>BOJONEGORO</td>\n",
       "      <td>-0.943107</td>\n",
       "      <td>-0.881517</td>\n",
       "      <td>2.050574</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>JAWA TIMUR</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>0.087111</td>\n",
       "      <td>0.845235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12070</th>\n",
       "      <td>BENGKULU</td>\n",
       "      <td>0.485797</td>\n",
       "      <td>0.670116</td>\n",
       "      <td>2.089701</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>BENGKULU</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>-1.104780</td>\n",
       "      <td>-1.153716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11502</th>\n",
       "      <td>PALANGKARAYA</td>\n",
       "      <td>-0.470844</td>\n",
       "      <td>-0.300075</td>\n",
       "      <td>2.272398</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>KALIMANTAN TENGAH</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.060115</td>\n",
       "      <td>-1.051460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>GIANYAR</td>\n",
       "      <td>-0.105658</td>\n",
       "      <td>-0.134086</td>\n",
       "      <td>1.791001</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>BALI</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.918898</td>\n",
       "      <td>-0.925787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13418</th>\n",
       "      <td>50 KOTA</td>\n",
       "      <td>0.028610</td>\n",
       "      <td>-0.052511</td>\n",
       "      <td>1.721377</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.995010</td>\n",
       "      <td>-0.935591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>CIREBON</td>\n",
       "      <td>0.012689</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>1.864943</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1.468594</td>\n",
       "      <td>1.720036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>SUBANG(P)</td>\n",
       "      <td>1.917237</td>\n",
       "      <td>1.183325</td>\n",
       "      <td>1.440357</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1.665132</td>\n",
       "      <td>1.884218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>GOWA</td>\n",
       "      <td>0.127937</td>\n",
       "      <td>0.174144</td>\n",
       "      <td>1.927623</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.905846</td>\n",
       "      <td>-0.881091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12044 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UNIT     TAILS        KG       ABW CHICKEN SIZE  \\\n",
       "12179      SANGATTA -0.868153 -0.903847  1.385429        SMALL   \n",
       "14448     SIJUNJUNG -0.279093 -0.318778  1.739214       MEDIUM   \n",
       "13769    BOJONEGORO -0.943107 -0.881517  2.050574        LARGE   \n",
       "12070      BENGKULU  0.485797  0.670116  2.089701        LARGE   \n",
       "11502  PALANGKARAYA -0.470844 -0.300075  2.272398        LARGE   \n",
       "...             ...       ...       ...       ...          ...   \n",
       "5191        GIANYAR -0.105658 -0.134086  1.791001       MEDIUM   \n",
       "13418       50 KOTA  0.028610 -0.052511  1.721377       MEDIUM   \n",
       "5390        CIREBON  0.012689  0.020821  1.864943       MEDIUM   \n",
       "860       SUBANG(P)  1.917237  1.183325  1.440357        SMALL   \n",
       "7270           GOWA  0.127937  0.174144  1.927623       MEDIUM   \n",
       "\n",
       "                PROVINCE  YEAR  MONTH  DAY  SupplyProvince  DemandProvince  \\\n",
       "12179   KALIMANTAN TIMUR    21     12   17       -1.024406       -0.964375   \n",
       "14448     SUMATERA BARAT    21     12   31       -0.995010       -0.935591   \n",
       "13769         JAWA TIMUR    21     12   27        0.087111        0.845235   \n",
       "12070           BENGKULU    21     12   16       -1.104780       -1.153716   \n",
       "11502  KALIMANTAN TENGAH    21     12   13       -1.060115       -1.051460   \n",
       "...                  ...   ...    ...  ...             ...             ...   \n",
       "5191                BALI    20     12    1       -0.918898       -0.925787   \n",
       "13418     SUMATERA BARAT    21     12   24       -0.995010       -0.935591   \n",
       "5390          JAWA BARAT    20     12    2        1.468594        1.720036   \n",
       "860           JAWA BARAT    19     12    5        1.665132        1.884218   \n",
       "7270    SULAWESI SELATAN    20     12   16       -0.905846       -0.881091   \n",
       "\n",
       "       Holiday  \n",
       "12179        0  \n",
       "14448        0  \n",
       "13769        1  \n",
       "12070        0  \n",
       "11502        0  \n",
       "...        ...  \n",
       "5191         0  \n",
       "13418        1  \n",
       "5390         0  \n",
       "860          0  \n",
       "7270         0  \n",
       "\n",
       "[12044 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to evaluate the model\n",
    "def results(y_test, predictions):\n",
    "  mae = mean_absolute_error(y_test, predictions)\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "  rmse = np.sqrt(mse)\n",
    "  r2 = r2_score(y_test, predictions)\n",
    "\n",
    "  print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "  print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "  print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "  print(f\"R-squared (R²): {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding of columns\n",
    "# label encoding for province\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "X_train['SIZE ENCODE'] = label_encoder.fit_transform(X_train['CHICKEN SIZE'])\n",
    "X_test['SIZE ENCODE'] = label_encoder.transform(X_test['CHICKEN SIZE'])\n",
    "\n",
    "# dropping chicken size column\n",
    "X_train = X_train.drop(['CHICKEN SIZE'], axis = 1)\n",
    "X_test = X_test.drop(['CHICKEN SIZE'], axis = 1)\n",
    "\n",
    "\n",
    "# one hot encoding for province\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X_train[['PROVINCE']])\n",
    "X_train_encoded = encoder.transform(X_train[['PROVINCE']])\n",
    "X_test_encoded = encoder.transform(X_test[['PROVINCE']])\n",
    "\n",
    "# Convert the encoded matrices back to dataframes for easier manipulation\n",
    "columns = encoder.get_feature_names_out(['PROVINCE'])\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded.toarray(), columns=columns, index=X_train.index)\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded.toarray(), columns=columns, index=X_test.index)\n",
    "\n",
    "# merge back the dataframe\n",
    "X_train = pd.concat([X_train.drop('PROVINCE', axis=1), X_train_encoded_df], axis=1)\n",
    "X_test = pd.concat([X_test.drop('PROVINCE', axis=1), X_test_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# one hot encoding for unit\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X_train[['UNIT']])\n",
    "X_train_encoded_unit = encoder.transform(X_train[['UNIT']])\n",
    "X_test_encoded_unit = encoder.transform(X_test[['UNIT']])\n",
    "\n",
    "# Convert the encoded matrices back to dataframes for easier manipulation\n",
    "columns = encoder.get_feature_names_out(['UNIT'])\n",
    "X_train_encoded_df_unit = pd.DataFrame(X_train_encoded_unit.toarray(), columns=columns, index=X_train.index)\n",
    "X_test_encoded_df_unit = pd.DataFrame(X_test_encoded_unit.toarray(), columns=columns, index=X_test.index)\n",
    "\n",
    "# merge back the dataframe, dropping unit column\n",
    "X_train = pd.concat([X_train.drop('UNIT', axis=1), X_train_encoded_df_unit], axis=1)\n",
    "X_test = pd.concat([X_test.drop('UNIT', axis=1), X_test_encoded_df_unit], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying lazy predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lazypredict in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.2.12)\n",
      "Requirement already satisfied: click in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (8.1.7)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (1.4.1.post1)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from lazypredict) (2.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (4.66.2)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from lazypredict) (1.3.2)\n",
      "Requirement already satisfied: lightgbm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (4.3.0)\n",
      "Requirement already satisfied: xgboost in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (2.0.3)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from lightgbm->lazypredict) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from lightgbm->lazypredict) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->lazypredict) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.utils import all_estimators\\nfrom sklearn.base import RegressorMixin'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libraries\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "'''from sklearn.utils import all_estimators\n",
    "from sklearn.base import RegressorMixin'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AdaBoostClassifier', <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>), ('BaggingClassifier', <class 'sklearn.ensemble._bagging.BaggingClassifier'>), ('BernoulliNB', <class 'sklearn.naive_bayes.BernoulliNB'>), ('CalibratedClassifierCV', <class 'sklearn.calibration.CalibratedClassifierCV'>), ('CategoricalNB', <class 'sklearn.naive_bayes.CategoricalNB'>), ('DecisionTreeClassifier', <class 'sklearn.tree._classes.DecisionTreeClassifier'>), ('DummyClassifier', <class 'sklearn.dummy.DummyClassifier'>), ('ExtraTreeClassifier', <class 'sklearn.tree._classes.ExtraTreeClassifier'>), ('ExtraTreesClassifier', <class 'sklearn.ensemble._forest.ExtraTreesClassifier'>), ('GaussianNB', <class 'sklearn.naive_bayes.GaussianNB'>), ('KNeighborsClassifier', <class 'sklearn.neighbors._classification.KNeighborsClassifier'>), ('LabelPropagation', <class 'sklearn.semi_supervised._label_propagation.LabelPropagation'>), ('LabelSpreading', <class 'sklearn.semi_supervised._label_propagation.LabelSpreading'>), ('LinearDiscriminantAnalysis', <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>), ('LinearSVC', <class 'sklearn.svm._classes.LinearSVC'>), ('LogisticRegression', <class 'sklearn.linear_model._logistic.LogisticRegression'>), ('NearestCentroid', <class 'sklearn.neighbors._nearest_centroid.NearestCentroid'>), ('NuSVC', <class 'sklearn.svm._classes.NuSVC'>), ('PassiveAggressiveClassifier', <class 'sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier'>), ('Perceptron', <class 'sklearn.linear_model._perceptron.Perceptron'>), ('QuadraticDiscriminantAnalysis', <class 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'>), ('RandomForestClassifier', <class 'sklearn.ensemble._forest.RandomForestClassifier'>), ('RidgeClassifier', <class 'sklearn.linear_model._ridge.RidgeClassifier'>), ('RidgeClassifierCV', <class 'sklearn.linear_model._ridge.RidgeClassifierCV'>), ('SGDClassifier', <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>), ('SVC', <class 'sklearn.svm._classes.SVC'>), ('StackingClassifier', <class 'sklearn.ensemble._stacking.StackingClassifier'>), ('XGBClassifier', <class 'xgboost.sklearn.XGBClassifier'>), ('LGBMClassifier', <class 'lightgbm.sklearn.LGBMClassifier'>)]\n"
     ]
    }
   ],
   "source": [
    "print(lazypredict.Supervised.CLASSIFIERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    chosen_regressors = [\n",
    "    'SVR', \n",
    "    'BaggingRegressor',\n",
    "    'ExtraTreesRegressor',\n",
    "    'RandomForestRegressor',\n",
    "    'GradientBoostingRegressor',\n",
    "    'LGBMRegressor',\n",
    "    'XGBRegressor',\n",
    "    'CatBoostRegressor',\n",
    "    'HistGradientBoostingRegressor',\n",
    "    'AdaBoostRegressor',\n",
    "    'KNeighborsRegressor',\n",
    "    'DecisionTreeRegressor'\n",
    "]\n",
    "\n",
    "REGRESSORS = [\n",
    "    est\n",
    "    for est in all_estimators()\n",
    "    if (issubclass(est[1], RegressorMixin) and est[0] in chosen_regressors)\n",
    "\n",
    "]'''\n",
    "\n",
    "# initialising the regressor with chosen regressors\n",
    "reg = LazyClassifier(verbose=1, ignore_warnings=False, custom_metric=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/29 [00:01<00:28,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for AdaBoostClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n",
      "{'Model': 'AdaBoostClassifier', 'Accuracy': 0.46496180670873466, 'Balanced Accuracy': 0.4645024031811561, 'ROC AUC': None, 'F1 Score': 0.4643338200488807, 'Time taken': 1.002105474472046}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/29 [00:01<00:16,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for BaggingClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n",
      "{'Model': 'BaggingClassifier', 'Accuracy': 0.7356360013284623, 'Balanced Accuracy': 0.734941901152864, 'ROC AUC': None, 'F1 Score': 0.7360805580806883, 'Time taken': 0.7636623382568359}\n",
      "ROC AUC couldn't be calculated for BernoulliNB\n",
      "multi_class must be in ('ovo', 'ovr')\n",
      "{'Model': 'BernoulliNB', 'Accuracy': 0.42909332447691795, 'Balanced Accuracy': 0.42601129936614723, 'ROC AUC': None, 'F1 Score': 0.3898159581942892, 'Time taken': 0.08462786674499512}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fitting and evaluate models\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m models, predictions \u001b[38;5;241m=\u001b[39m \u001b[43mreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m models\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/lazypredict/Supervised.py:302\u001b[0m, in \u001b[0;36mLazyClassifier.fit\u001b[0;34m(self, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     pipe \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[1;32m    299\u001b[0m         steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m, preprocessor), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, model())]\n\u001b[1;32m    300\u001b[0m     )\n\u001b[0;32m--> 302\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[name] \u001b[38;5;241m=\u001b[39m pipe\n\u001b[1;32m    304\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/pipeline.py:471\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 471\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/pipeline.py:408\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params)\u001b[0m\n\u001b[1;32m    406\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/pipeline.py:1303\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1303\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1306\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1307\u001b[0m         )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:914\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    912\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[0;32m--> 914\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:823\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[0;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[1;32m    811\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    812\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    813\u001b[0m             delayed(func)(\n\u001b[1;32m    814\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m             )\n\u001b[1;32m    821\u001b[0m         )\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/pipeline.py:1303\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1303\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1306\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1307\u001b[0m         )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/pipeline.py:535\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \n\u001b[1;32m    494\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;124;03m    Transformed samples.\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    534\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 535\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m last_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/pipeline.py:408\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params)\u001b[0m\n\u001b[1;32m    406\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/pipeline.py:1303\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1303\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1306\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1307\u001b[0m         )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/base.py:1101\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/impute/_base.py:427\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_fit(\n\u001b[1;32m    424\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values, fill_value\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dense_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/impute/_base.py:484\u001b[0m, in \u001b[0;36mSimpleImputer._dense_fit\u001b[0;34m(self, X, strategy, missing_values, fill_value)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# Mean\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 484\u001b[0m     mean_masked \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;66;03m# Avoid the warning \"Warning: converting a masked element to nan.\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mgetdata(mean_masked)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/ma/core.py:6882\u001b[0m, in \u001b[0;36m_frommethod.__call__\u001b[0;34m(self, a, *args, **params)\u001b[0m\n\u001b[1;32m   6878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6879\u001b[0m     \u001b[38;5;66;03m# use the corresponding np function\u001b[39;00m\n\u001b[1;32m   6880\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(np, method_name)\n\u001b[0;32m-> 6882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/ma/core.py:5343\u001b[0m, in \u001b[0;36mMaskedArray.mean\u001b[0;34m(self, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   5341\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   5342\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 5343\u001b[0m dsum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5344\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount(axis\u001b[38;5;241m=\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   5345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cnt\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m () \u001b[38;5;129;01mand\u001b[39;00m (cnt \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/ma/core.py:5172\u001b[0m, in \u001b[0;36mMaskedArray.sum\u001b[0;34m(self, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   5169\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims}\n\u001b[1;32m   5171\u001b[0m _mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask\n\u001b[0;32m-> 5172\u001b[0m newmask \u001b[38;5;241m=\u001b[39m \u001b[43m_check_mask_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5173\u001b[0m \u001b[38;5;66;03m# No explicit output\u001b[39;00m\n\u001b[1;32m   5174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/ma/core.py:1820\u001b[0m, in \u001b[0;36m_check_mask_axis\u001b[0;34m(mask, axis, keepdims)\u001b[0m\n\u001b[1;32m   1818\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims}\n\u001b[1;32m   1819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nomask:\n\u001b[0;32m-> 1820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nomask\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_methods.py:64\u001b[0m, in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_all\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# fitting and evaluate models\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out the top 5 models\n",
    "top_5_models = models.head(5)\n",
    "top_5_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62       672\n",
      "           1       0.41      0.41      0.41       582\n",
      "           2       0.39      0.42      0.40       552\n",
      "           3       0.39      0.47      0.43       503\n",
      "           4       0.66      0.56      0.61       702\n",
      "\n",
      "    accuracy                           0.50      3011\n",
      "   macro avg       0.50      0.49      0.49      3011\n",
      "weighted avg       0.51      0.50      0.50      3011\n",
      "\n",
      "Accuracy: 0.4995018266356692\n"
     ]
    }
   ],
   "source": [
    "#Applying Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(multi_class = 'multinomial', solver = 'saga',  max_iter = 10000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "predictions_lr = lr.predict(X_test)\n",
    "print(classification_report(predictions, y_test))\n",
    "\n",
    "# print accuracy score\n",
    "acc_lr = metrics.accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {acc_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77       620\n",
      "           1       0.65      0.68      0.66       567\n",
      "           2       0.70      0.65      0.67       642\n",
      "           3       0.70      0.73      0.72       579\n",
      "           4       0.86      0.85      0.85       603\n",
      "\n",
      "    accuracy                           0.74      3011\n",
      "   macro avg       0.74      0.74      0.74      3011\n",
      "weighted avg       0.74      0.74      0.74      3011\n",
      "\n",
      "Accuracy: 0.7363002324809034\n"
     ]
    }
   ],
   "source": [
    "# random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 400) # 400 trees\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "predictions_rf = rf.predict(X_test)\n",
    "print(classification_report(predictions_rf, y_test))\n",
    "\n",
    "# print accuracy score\n",
    "acc_rf = metrics.accuracy_score(y_test, predictions_rf)\n",
    "print(f\"Accuracy: {acc_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       619\n",
      "           1       0.64      0.64      0.64       594\n",
      "           2       0.65      0.67      0.66       575\n",
      "           3       0.68      0.67      0.68       610\n",
      "           4       0.84      0.82      0.83       613\n",
      "\n",
      "    accuracy                           0.71      3011\n",
      "   macro avg       0.71      0.71      0.71      3011\n",
      "weighted avg       0.72      0.71      0.71      3011\n",
      "\n",
      "Accuracy: 0.7140484888741282\n"
     ]
    }
   ],
   "source": [
    "# applying xgboost\n",
    "xgb = xgb.XGBClassifier(objective='multi:softmax', num_class=best_bin_number, max_depth=5, eval_metric='mlogloss', use_label_encoder=False, seed=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "predictions_xgb = xgb.predict(X_test)\n",
    "print(classification_report(predictions_xgb, y_test))\n",
    "\n",
    "# accuracy\n",
    "acc_xgb = metrics.accuracy_score(y_test, predictions_xgb)\n",
    "print(f\"Accuracy: {acc_xgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 232 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.5498542\ttotal: 56.2ms\tremaining: 56.1s\n",
      "1:\tlearn: 1.4957460\ttotal: 65.5ms\tremaining: 32.7s\n",
      "2:\tlearn: 1.4495605\ttotal: 80.6ms\tremaining: 26.8s\n",
      "3:\tlearn: 1.4103174\ttotal: 87.8ms\tremaining: 21.9s\n",
      "4:\tlearn: 1.3732804\ttotal: 95.1ms\tremaining: 18.9s\n",
      "5:\tlearn: 1.3464259\ttotal: 102ms\tremaining: 16.9s\n",
      "6:\tlearn: 1.3194497\ttotal: 109ms\tremaining: 15.5s\n",
      "7:\tlearn: 1.2966463\ttotal: 117ms\tremaining: 14.4s\n",
      "8:\tlearn: 1.2722093\ttotal: 125ms\tremaining: 13.7s\n",
      "9:\tlearn: 1.2539168\ttotal: 132ms\tremaining: 13.1s\n",
      "10:\tlearn: 1.2354226\ttotal: 139ms\tremaining: 12.5s\n",
      "11:\tlearn: 1.2177092\ttotal: 147ms\tremaining: 12.1s\n",
      "12:\tlearn: 1.2046153\ttotal: 157ms\tremaining: 11.9s\n",
      "13:\tlearn: 1.1908928\ttotal: 164ms\tremaining: 11.5s\n",
      "14:\tlearn: 1.1776773\ttotal: 171ms\tremaining: 11.2s\n",
      "15:\tlearn: 1.1653959\ttotal: 178ms\tremaining: 10.9s\n",
      "16:\tlearn: 1.1535093\ttotal: 185ms\tremaining: 10.7s\n",
      "17:\tlearn: 1.1422866\ttotal: 192ms\tremaining: 10.5s\n",
      "18:\tlearn: 1.1325437\ttotal: 199ms\tremaining: 10.3s\n",
      "19:\tlearn: 1.1233001\ttotal: 206ms\tremaining: 10.1s\n",
      "20:\tlearn: 1.1158963\ttotal: 213ms\tremaining: 9.94s\n",
      "21:\tlearn: 1.1094884\ttotal: 222ms\tremaining: 9.89s\n",
      "22:\tlearn: 1.1049975\ttotal: 229ms\tremaining: 9.72s\n",
      "23:\tlearn: 1.0942115\ttotal: 236ms\tremaining: 9.61s\n",
      "24:\tlearn: 1.0868226\ttotal: 243ms\tremaining: 9.5s\n",
      "25:\tlearn: 1.0778472\ttotal: 257ms\tremaining: 9.63s\n",
      "26:\tlearn: 1.0712414\ttotal: 266ms\tremaining: 9.57s\n",
      "27:\tlearn: 1.0635213\ttotal: 276ms\tremaining: 9.57s\n",
      "28:\tlearn: 1.0603999\ttotal: 282ms\tremaining: 9.44s\n",
      "29:\tlearn: 1.0545472\ttotal: 289ms\tremaining: 9.34s\n",
      "30:\tlearn: 1.0494148\ttotal: 304ms\tremaining: 9.5s\n",
      "31:\tlearn: 1.0416518\ttotal: 315ms\tremaining: 9.52s\n",
      "32:\tlearn: 1.0353793\ttotal: 321ms\tremaining: 9.42s\n",
      "33:\tlearn: 1.0291239\ttotal: 329ms\tremaining: 9.36s\n",
      "34:\tlearn: 1.0254610\ttotal: 337ms\tremaining: 9.29s\n",
      "35:\tlearn: 1.0209303\ttotal: 344ms\tremaining: 9.2s\n",
      "36:\tlearn: 1.0149897\ttotal: 352ms\tremaining: 9.16s\n",
      "37:\tlearn: 1.0133069\ttotal: 358ms\tremaining: 9.07s\n",
      "38:\tlearn: 1.0089025\ttotal: 366ms\tremaining: 9.01s\n",
      "39:\tlearn: 1.0068288\ttotal: 372ms\tremaining: 8.93s\n",
      "40:\tlearn: 1.0037866\ttotal: 379ms\tremaining: 8.88s\n",
      "41:\tlearn: 1.0004653\ttotal: 386ms\tremaining: 8.8s\n",
      "42:\tlearn: 0.9967993\ttotal: 393ms\tremaining: 8.75s\n",
      "43:\tlearn: 0.9906347\ttotal: 400ms\tremaining: 8.69s\n",
      "44:\tlearn: 0.9857088\ttotal: 408ms\tremaining: 8.66s\n",
      "45:\tlearn: 0.9838789\ttotal: 417ms\tremaining: 8.64s\n",
      "46:\tlearn: 0.9781487\ttotal: 424ms\tremaining: 8.6s\n",
      "47:\tlearn: 0.9741800\ttotal: 431ms\tremaining: 8.55s\n",
      "48:\tlearn: 0.9707900\ttotal: 438ms\tremaining: 8.51s\n",
      "49:\tlearn: 0.9694651\ttotal: 446ms\tremaining: 8.47s\n",
      "50:\tlearn: 0.9660360\ttotal: 453ms\tremaining: 8.42s\n",
      "51:\tlearn: 0.9634467\ttotal: 460ms\tremaining: 8.39s\n",
      "52:\tlearn: 0.9594966\ttotal: 468ms\tremaining: 8.36s\n",
      "53:\tlearn: 0.9560281\ttotal: 475ms\tremaining: 8.32s\n",
      "54:\tlearn: 0.9533984\ttotal: 481ms\tremaining: 8.27s\n",
      "55:\tlearn: 0.9511742\ttotal: 488ms\tremaining: 8.22s\n",
      "56:\tlearn: 0.9496742\ttotal: 497ms\tremaining: 8.22s\n",
      "57:\tlearn: 0.9474592\ttotal: 504ms\tremaining: 8.19s\n",
      "58:\tlearn: 0.9448663\ttotal: 511ms\tremaining: 8.15s\n",
      "59:\tlearn: 0.9409968\ttotal: 519ms\tremaining: 8.13s\n",
      "60:\tlearn: 0.9378124\ttotal: 526ms\tremaining: 8.09s\n",
      "61:\tlearn: 0.9360229\ttotal: 532ms\tremaining: 8.05s\n",
      "62:\tlearn: 0.9332362\ttotal: 539ms\tremaining: 8.02s\n",
      "63:\tlearn: 0.9308909\ttotal: 548ms\tremaining: 8.01s\n",
      "64:\tlearn: 0.9281435\ttotal: 555ms\tremaining: 7.99s\n",
      "65:\tlearn: 0.9258903\ttotal: 562ms\tremaining: 7.95s\n",
      "66:\tlearn: 0.9236177\ttotal: 569ms\tremaining: 7.92s\n",
      "67:\tlearn: 0.9202661\ttotal: 575ms\tremaining: 7.89s\n",
      "68:\tlearn: 0.9184371\ttotal: 582ms\tremaining: 7.85s\n",
      "69:\tlearn: 0.9168025\ttotal: 589ms\tremaining: 7.82s\n",
      "70:\tlearn: 0.9131920\ttotal: 596ms\tremaining: 7.8s\n",
      "71:\tlearn: 0.9106625\ttotal: 603ms\tremaining: 7.77s\n",
      "72:\tlearn: 0.9083377\ttotal: 610ms\tremaining: 7.74s\n",
      "73:\tlearn: 0.9071538\ttotal: 617ms\tremaining: 7.72s\n",
      "74:\tlearn: 0.9052687\ttotal: 624ms\tremaining: 7.69s\n",
      "75:\tlearn: 0.9026328\ttotal: 630ms\tremaining: 7.67s\n",
      "76:\tlearn: 0.9016092\ttotal: 637ms\tremaining: 7.63s\n",
      "77:\tlearn: 0.8994348\ttotal: 646ms\tremaining: 7.63s\n",
      "78:\tlearn: 0.8987156\ttotal: 652ms\tremaining: 7.6s\n",
      "79:\tlearn: 0.8963805\ttotal: 660ms\tremaining: 7.58s\n",
      "80:\tlearn: 0.8952759\ttotal: 666ms\tremaining: 7.56s\n",
      "81:\tlearn: 0.8927158\ttotal: 674ms\tremaining: 7.54s\n",
      "82:\tlearn: 0.8907593\ttotal: 680ms\tremaining: 7.52s\n",
      "83:\tlearn: 0.8870090\ttotal: 688ms\tremaining: 7.5s\n",
      "84:\tlearn: 0.8860125\ttotal: 697ms\tremaining: 7.5s\n",
      "85:\tlearn: 0.8827832\ttotal: 704ms\tremaining: 7.48s\n",
      "86:\tlearn: 0.8809770\ttotal: 710ms\tremaining: 7.45s\n",
      "87:\tlearn: 0.8785928\ttotal: 717ms\tremaining: 7.43s\n",
      "88:\tlearn: 0.8755228\ttotal: 725ms\tremaining: 7.42s\n",
      "89:\tlearn: 0.8741985\ttotal: 733ms\tremaining: 7.41s\n",
      "90:\tlearn: 0.8709418\ttotal: 742ms\tremaining: 7.41s\n",
      "91:\tlearn: 0.8695733\ttotal: 748ms\tremaining: 7.38s\n",
      "92:\tlearn: 0.8685146\ttotal: 755ms\tremaining: 7.36s\n",
      "93:\tlearn: 0.8665759\ttotal: 761ms\tremaining: 7.34s\n",
      "94:\tlearn: 0.8652549\ttotal: 768ms\tremaining: 7.31s\n",
      "95:\tlearn: 0.8627812\ttotal: 775ms\tremaining: 7.3s\n",
      "96:\tlearn: 0.8608105\ttotal: 782ms\tremaining: 7.28s\n",
      "97:\tlearn: 0.8590703\ttotal: 788ms\tremaining: 7.25s\n",
      "98:\tlearn: 0.8572586\ttotal: 795ms\tremaining: 7.23s\n",
      "99:\tlearn: 0.8564969\ttotal: 801ms\tremaining: 7.21s\n",
      "100:\tlearn: 0.8551444\ttotal: 808ms\tremaining: 7.19s\n",
      "101:\tlearn: 0.8540159\ttotal: 814ms\tremaining: 7.17s\n",
      "102:\tlearn: 0.8523221\ttotal: 821ms\tremaining: 7.15s\n",
      "103:\tlearn: 0.8496485\ttotal: 828ms\tremaining: 7.13s\n",
      "104:\tlearn: 0.8482809\ttotal: 834ms\tremaining: 7.11s\n",
      "105:\tlearn: 0.8460500\ttotal: 842ms\tremaining: 7.1s\n",
      "106:\tlearn: 0.8441137\ttotal: 849ms\tremaining: 7.09s\n",
      "107:\tlearn: 0.8428654\ttotal: 856ms\tremaining: 7.07s\n",
      "108:\tlearn: 0.8411007\ttotal: 863ms\tremaining: 7.05s\n",
      "109:\tlearn: 0.8398361\ttotal: 870ms\tremaining: 7.04s\n",
      "110:\tlearn: 0.8367807\ttotal: 881ms\tremaining: 7.05s\n",
      "111:\tlearn: 0.8355242\ttotal: 888ms\tremaining: 7.04s\n",
      "112:\tlearn: 0.8340810\ttotal: 897ms\tremaining: 7.04s\n",
      "113:\tlearn: 0.8329166\ttotal: 904ms\tremaining: 7.03s\n",
      "114:\tlearn: 0.8318250\ttotal: 911ms\tremaining: 7.01s\n",
      "115:\tlearn: 0.8292926\ttotal: 918ms\tremaining: 7s\n",
      "116:\tlearn: 0.8280355\ttotal: 926ms\tremaining: 6.99s\n",
      "117:\tlearn: 0.8270225\ttotal: 932ms\tremaining: 6.97s\n",
      "118:\tlearn: 0.8260007\ttotal: 940ms\tremaining: 6.96s\n",
      "119:\tlearn: 0.8251291\ttotal: 946ms\tremaining: 6.94s\n",
      "120:\tlearn: 0.8245190\ttotal: 953ms\tremaining: 6.92s\n",
      "121:\tlearn: 0.8231055\ttotal: 962ms\tremaining: 6.92s\n",
      "122:\tlearn: 0.8216957\ttotal: 977ms\tremaining: 6.96s\n",
      "123:\tlearn: 0.8206365\ttotal: 995ms\tremaining: 7.03s\n",
      "124:\tlearn: 0.8189157\ttotal: 1s\tremaining: 7.04s\n",
      "125:\tlearn: 0.8177220\ttotal: 1.01s\tremaining: 7.02s\n",
      "126:\tlearn: 0.8162202\ttotal: 1.02s\tremaining: 7s\n",
      "127:\tlearn: 0.8147125\ttotal: 1.03s\tremaining: 7s\n",
      "128:\tlearn: 0.8134263\ttotal: 1.04s\tremaining: 7.05s\n",
      "129:\tlearn: 0.8122724\ttotal: 1.08s\tremaining: 7.21s\n",
      "130:\tlearn: 0.8114222\ttotal: 1.09s\tremaining: 7.25s\n",
      "131:\tlearn: 0.8093374\ttotal: 1.11s\tremaining: 7.32s\n",
      "132:\tlearn: 0.8086429\ttotal: 1.13s\tremaining: 7.38s\n",
      "133:\tlearn: 0.8075673\ttotal: 1.14s\tremaining: 7.39s\n",
      "134:\tlearn: 0.8067174\ttotal: 1.15s\tremaining: 7.37s\n",
      "135:\tlearn: 0.8049223\ttotal: 1.16s\tremaining: 7.35s\n",
      "136:\tlearn: 0.8041887\ttotal: 1.17s\tremaining: 7.34s\n",
      "137:\tlearn: 0.8026587\ttotal: 1.17s\tremaining: 7.32s\n",
      "138:\tlearn: 0.8014631\ttotal: 1.18s\tremaining: 7.3s\n",
      "139:\tlearn: 0.8001103\ttotal: 1.19s\tremaining: 7.28s\n",
      "140:\tlearn: 0.7986073\ttotal: 1.19s\tremaining: 7.27s\n",
      "141:\tlearn: 0.7977376\ttotal: 1.2s\tremaining: 7.25s\n",
      "142:\tlearn: 0.7957058\ttotal: 1.21s\tremaining: 7.23s\n",
      "143:\tlearn: 0.7942148\ttotal: 1.21s\tremaining: 7.21s\n",
      "144:\tlearn: 0.7931013\ttotal: 1.22s\tremaining: 7.19s\n",
      "145:\tlearn: 0.7919098\ttotal: 1.23s\tremaining: 7.19s\n",
      "146:\tlearn: 0.7904159\ttotal: 1.24s\tremaining: 7.18s\n",
      "147:\tlearn: 0.7898099\ttotal: 1.24s\tremaining: 7.16s\n",
      "148:\tlearn: 0.7889259\ttotal: 1.25s\tremaining: 7.14s\n",
      "149:\tlearn: 0.7870475\ttotal: 1.26s\tremaining: 7.12s\n",
      "150:\tlearn: 0.7856186\ttotal: 1.26s\tremaining: 7.1s\n",
      "151:\tlearn: 0.7848281\ttotal: 1.27s\tremaining: 7.08s\n",
      "152:\tlearn: 0.7833361\ttotal: 1.28s\tremaining: 7.08s\n",
      "153:\tlearn: 0.7821220\ttotal: 1.28s\tremaining: 7.06s\n",
      "154:\tlearn: 0.7815419\ttotal: 1.29s\tremaining: 7.04s\n",
      "155:\tlearn: 0.7799305\ttotal: 1.3s\tremaining: 7.03s\n",
      "156:\tlearn: 0.7791670\ttotal: 1.31s\tremaining: 7.02s\n",
      "157:\tlearn: 0.7783183\ttotal: 1.32s\tremaining: 7.02s\n",
      "158:\tlearn: 0.7770068\ttotal: 1.32s\tremaining: 7s\n",
      "159:\tlearn: 0.7762116\ttotal: 1.33s\tremaining: 6.98s\n",
      "160:\tlearn: 0.7756395\ttotal: 1.34s\tremaining: 6.97s\n",
      "161:\tlearn: 0.7751012\ttotal: 1.34s\tremaining: 6.95s\n",
      "162:\tlearn: 0.7743468\ttotal: 1.35s\tremaining: 6.93s\n",
      "163:\tlearn: 0.7737378\ttotal: 1.36s\tremaining: 6.92s\n",
      "164:\tlearn: 0.7731083\ttotal: 1.36s\tremaining: 6.9s\n",
      "165:\tlearn: 0.7719019\ttotal: 1.37s\tremaining: 6.88s\n",
      "166:\tlearn: 0.7705060\ttotal: 1.38s\tremaining: 6.87s\n",
      "167:\tlearn: 0.7694694\ttotal: 1.38s\tremaining: 6.86s\n",
      "168:\tlearn: 0.7684504\ttotal: 1.39s\tremaining: 6.85s\n",
      "169:\tlearn: 0.7679291\ttotal: 1.4s\tremaining: 6.83s\n",
      "170:\tlearn: 0.7665751\ttotal: 1.41s\tremaining: 6.82s\n",
      "171:\tlearn: 0.7661771\ttotal: 1.41s\tremaining: 6.8s\n",
      "172:\tlearn: 0.7648253\ttotal: 1.42s\tremaining: 6.79s\n",
      "173:\tlearn: 0.7640539\ttotal: 1.43s\tremaining: 6.78s\n",
      "174:\tlearn: 0.7632606\ttotal: 1.43s\tremaining: 6.76s\n",
      "175:\tlearn: 0.7621120\ttotal: 1.44s\tremaining: 6.75s\n",
      "176:\tlearn: 0.7615391\ttotal: 1.45s\tremaining: 6.73s\n",
      "177:\tlearn: 0.7609004\ttotal: 1.45s\tremaining: 6.71s\n",
      "178:\tlearn: 0.7597881\ttotal: 1.46s\tremaining: 6.7s\n",
      "179:\tlearn: 0.7590745\ttotal: 1.47s\tremaining: 6.68s\n",
      "180:\tlearn: 0.7575043\ttotal: 1.48s\tremaining: 6.68s\n",
      "181:\tlearn: 0.7562800\ttotal: 1.48s\tremaining: 6.67s\n",
      "182:\tlearn: 0.7556710\ttotal: 1.49s\tremaining: 6.65s\n",
      "183:\tlearn: 0.7541450\ttotal: 1.5s\tremaining: 6.64s\n",
      "184:\tlearn: 0.7532450\ttotal: 1.5s\tremaining: 6.62s\n",
      "185:\tlearn: 0.7525974\ttotal: 1.51s\tremaining: 6.61s\n",
      "186:\tlearn: 0.7521447\ttotal: 1.52s\tremaining: 6.61s\n",
      "187:\tlearn: 0.7513845\ttotal: 1.53s\tremaining: 6.6s\n",
      "188:\tlearn: 0.7507427\ttotal: 1.53s\tremaining: 6.59s\n",
      "189:\tlearn: 0.7502351\ttotal: 1.54s\tremaining: 6.57s\n",
      "190:\tlearn: 0.7496209\ttotal: 1.55s\tremaining: 6.57s\n",
      "191:\tlearn: 0.7483422\ttotal: 1.57s\tremaining: 6.61s\n",
      "192:\tlearn: 0.7474862\ttotal: 1.59s\tremaining: 6.63s\n",
      "193:\tlearn: 0.7466167\ttotal: 1.61s\tremaining: 6.69s\n",
      "194:\tlearn: 0.7458677\ttotal: 1.63s\tremaining: 6.73s\n",
      "195:\tlearn: 0.7451125\ttotal: 1.65s\tremaining: 6.76s\n",
      "196:\tlearn: 0.7438310\ttotal: 1.66s\tremaining: 6.79s\n",
      "197:\tlearn: 0.7422834\ttotal: 1.68s\tremaining: 6.79s\n",
      "198:\tlearn: 0.7416221\ttotal: 1.7s\tremaining: 6.83s\n",
      "199:\tlearn: 0.7409959\ttotal: 1.71s\tremaining: 6.84s\n",
      "200:\tlearn: 0.7395194\ttotal: 1.72s\tremaining: 6.83s\n",
      "201:\tlearn: 0.7388708\ttotal: 1.73s\tremaining: 6.83s\n",
      "202:\tlearn: 0.7383218\ttotal: 1.74s\tremaining: 6.81s\n",
      "203:\tlearn: 0.7370741\ttotal: 1.74s\tremaining: 6.8s\n",
      "204:\tlearn: 0.7365590\ttotal: 1.75s\tremaining: 6.78s\n",
      "205:\tlearn: 0.7357496\ttotal: 1.76s\tremaining: 6.77s\n",
      "206:\tlearn: 0.7350004\ttotal: 1.76s\tremaining: 6.75s\n",
      "207:\tlearn: 0.7337498\ttotal: 1.77s\tremaining: 6.74s\n",
      "208:\tlearn: 0.7329689\ttotal: 1.77s\tremaining: 6.72s\n",
      "209:\tlearn: 0.7321742\ttotal: 1.78s\tremaining: 6.7s\n",
      "210:\tlearn: 0.7314671\ttotal: 1.79s\tremaining: 6.69s\n",
      "211:\tlearn: 0.7310644\ttotal: 1.79s\tremaining: 6.67s\n",
      "212:\tlearn: 0.7299037\ttotal: 1.8s\tremaining: 6.66s\n",
      "213:\tlearn: 0.7289754\ttotal: 1.81s\tremaining: 6.65s\n",
      "214:\tlearn: 0.7279988\ttotal: 1.82s\tremaining: 6.64s\n",
      "215:\tlearn: 0.7272232\ttotal: 1.82s\tremaining: 6.63s\n",
      "216:\tlearn: 0.7260852\ttotal: 1.83s\tremaining: 6.61s\n",
      "217:\tlearn: 0.7250698\ttotal: 1.84s\tremaining: 6.6s\n",
      "218:\tlearn: 0.7240035\ttotal: 1.85s\tremaining: 6.59s\n",
      "219:\tlearn: 0.7232488\ttotal: 1.85s\tremaining: 6.58s\n",
      "220:\tlearn: 0.7227205\ttotal: 1.86s\tremaining: 6.56s\n",
      "221:\tlearn: 0.7219134\ttotal: 1.87s\tremaining: 6.55s\n",
      "222:\tlearn: 0.7213752\ttotal: 1.88s\tremaining: 6.54s\n",
      "223:\tlearn: 0.7207903\ttotal: 1.88s\tremaining: 6.52s\n",
      "224:\tlearn: 0.7200658\ttotal: 1.89s\tremaining: 6.51s\n",
      "225:\tlearn: 0.7195685\ttotal: 1.9s\tremaining: 6.5s\n",
      "226:\tlearn: 0.7184195\ttotal: 1.9s\tremaining: 6.48s\n",
      "227:\tlearn: 0.7178699\ttotal: 1.91s\tremaining: 6.48s\n",
      "228:\tlearn: 0.7171727\ttotal: 1.92s\tremaining: 6.47s\n",
      "229:\tlearn: 0.7166765\ttotal: 1.93s\tremaining: 6.45s\n",
      "230:\tlearn: 0.7160633\ttotal: 1.93s\tremaining: 6.44s\n",
      "231:\tlearn: 0.7149123\ttotal: 1.94s\tremaining: 6.42s\n",
      "232:\tlearn: 0.7141529\ttotal: 1.95s\tremaining: 6.41s\n",
      "233:\tlearn: 0.7138978\ttotal: 1.95s\tremaining: 6.4s\n",
      "234:\tlearn: 0.7126844\ttotal: 1.96s\tremaining: 6.38s\n",
      "235:\tlearn: 0.7121322\ttotal: 1.97s\tremaining: 6.37s\n",
      "236:\tlearn: 0.7114806\ttotal: 1.97s\tremaining: 6.35s\n",
      "237:\tlearn: 0.7108636\ttotal: 1.98s\tremaining: 6.34s\n",
      "238:\tlearn: 0.7100938\ttotal: 1.99s\tremaining: 6.33s\n",
      "239:\tlearn: 0.7097196\ttotal: 1.99s\tremaining: 6.31s\n",
      "240:\tlearn: 0.7088849\ttotal: 2s\tremaining: 6.3s\n",
      "241:\tlearn: 0.7081655\ttotal: 2.01s\tremaining: 6.29s\n",
      "242:\tlearn: 0.7075045\ttotal: 2.01s\tremaining: 6.27s\n",
      "243:\tlearn: 0.7060557\ttotal: 2.02s\tremaining: 6.26s\n",
      "244:\tlearn: 0.7055130\ttotal: 2.03s\tremaining: 6.25s\n",
      "245:\tlearn: 0.7047408\ttotal: 2.04s\tremaining: 6.24s\n",
      "246:\tlearn: 0.7041261\ttotal: 2.04s\tremaining: 6.23s\n",
      "247:\tlearn: 0.7033140\ttotal: 2.05s\tremaining: 6.22s\n",
      "248:\tlearn: 0.7024906\ttotal: 2.06s\tremaining: 6.22s\n",
      "249:\tlearn: 0.7016387\ttotal: 2.07s\tremaining: 6.21s\n",
      "250:\tlearn: 0.7011188\ttotal: 2.08s\tremaining: 6.2s\n",
      "251:\tlearn: 0.6999074\ttotal: 2.09s\tremaining: 6.19s\n",
      "252:\tlearn: 0.6993938\ttotal: 2.09s\tremaining: 6.18s\n",
      "253:\tlearn: 0.6984935\ttotal: 2.1s\tremaining: 6.17s\n",
      "254:\tlearn: 0.6980569\ttotal: 2.11s\tremaining: 6.16s\n",
      "255:\tlearn: 0.6975414\ttotal: 2.12s\tremaining: 6.15s\n",
      "256:\tlearn: 0.6971223\ttotal: 2.12s\tremaining: 6.14s\n",
      "257:\tlearn: 0.6964522\ttotal: 2.13s\tremaining: 6.13s\n",
      "258:\tlearn: 0.6960795\ttotal: 2.14s\tremaining: 6.12s\n",
      "259:\tlearn: 0.6957840\ttotal: 2.14s\tremaining: 6.1s\n",
      "260:\tlearn: 0.6952110\ttotal: 2.15s\tremaining: 6.09s\n",
      "261:\tlearn: 0.6943681\ttotal: 2.16s\tremaining: 6.08s\n",
      "262:\tlearn: 0.6937381\ttotal: 2.16s\tremaining: 6.06s\n",
      "263:\tlearn: 0.6931941\ttotal: 2.17s\tremaining: 6.05s\n",
      "264:\tlearn: 0.6926792\ttotal: 2.18s\tremaining: 6.04s\n",
      "265:\tlearn: 0.6922745\ttotal: 2.18s\tremaining: 6.02s\n",
      "266:\tlearn: 0.6913823\ttotal: 2.19s\tremaining: 6.01s\n",
      "267:\tlearn: 0.6903257\ttotal: 2.2s\tremaining: 6.01s\n",
      "268:\tlearn: 0.6898178\ttotal: 2.21s\tremaining: 6s\n",
      "269:\tlearn: 0.6892617\ttotal: 2.22s\tremaining: 6s\n",
      "270:\tlearn: 0.6885178\ttotal: 2.23s\tremaining: 5.99s\n",
      "271:\tlearn: 0.6881113\ttotal: 2.24s\tremaining: 5.99s\n",
      "272:\tlearn: 0.6872373\ttotal: 2.25s\tremaining: 5.98s\n",
      "273:\tlearn: 0.6867448\ttotal: 2.25s\tremaining: 5.97s\n",
      "274:\tlearn: 0.6861701\ttotal: 2.26s\tremaining: 5.96s\n",
      "275:\tlearn: 0.6853947\ttotal: 2.27s\tremaining: 5.95s\n",
      "276:\tlearn: 0.6850631\ttotal: 2.28s\tremaining: 5.94s\n",
      "277:\tlearn: 0.6844600\ttotal: 2.29s\tremaining: 5.96s\n",
      "278:\tlearn: 0.6840420\ttotal: 2.31s\tremaining: 5.97s\n",
      "279:\tlearn: 0.6836147\ttotal: 2.33s\tremaining: 5.98s\n",
      "280:\tlearn: 0.6830198\ttotal: 2.34s\tremaining: 5.98s\n",
      "281:\tlearn: 0.6821219\ttotal: 2.35s\tremaining: 5.97s\n",
      "282:\tlearn: 0.6815171\ttotal: 2.35s\tremaining: 5.97s\n",
      "283:\tlearn: 0.6806263\ttotal: 2.37s\tremaining: 5.96s\n",
      "284:\tlearn: 0.6800857\ttotal: 2.37s\tremaining: 5.96s\n",
      "285:\tlearn: 0.6796119\ttotal: 2.38s\tremaining: 5.95s\n",
      "286:\tlearn: 0.6790921\ttotal: 2.39s\tremaining: 5.95s\n",
      "287:\tlearn: 0.6782533\ttotal: 2.41s\tremaining: 5.95s\n",
      "288:\tlearn: 0.6775965\ttotal: 2.41s\tremaining: 5.94s\n",
      "289:\tlearn: 0.6773235\ttotal: 2.42s\tremaining: 5.93s\n",
      "290:\tlearn: 0.6770473\ttotal: 2.43s\tremaining: 5.91s\n",
      "291:\tlearn: 0.6765743\ttotal: 2.43s\tremaining: 5.9s\n",
      "292:\tlearn: 0.6757998\ttotal: 2.44s\tremaining: 5.89s\n",
      "293:\tlearn: 0.6753135\ttotal: 2.45s\tremaining: 5.88s\n",
      "294:\tlearn: 0.6748374\ttotal: 2.45s\tremaining: 5.86s\n",
      "295:\tlearn: 0.6741164\ttotal: 2.46s\tremaining: 5.85s\n",
      "296:\tlearn: 0.6737138\ttotal: 2.47s\tremaining: 5.84s\n",
      "297:\tlearn: 0.6726339\ttotal: 2.47s\tremaining: 5.83s\n",
      "298:\tlearn: 0.6719190\ttotal: 2.48s\tremaining: 5.82s\n",
      "299:\tlearn: 0.6712252\ttotal: 2.49s\tremaining: 5.81s\n",
      "300:\tlearn: 0.6706521\ttotal: 2.5s\tremaining: 5.8s\n",
      "301:\tlearn: 0.6701432\ttotal: 2.5s\tremaining: 5.78s\n",
      "302:\tlearn: 0.6698496\ttotal: 2.51s\tremaining: 5.77s\n",
      "303:\tlearn: 0.6691619\ttotal: 2.52s\tremaining: 5.76s\n",
      "304:\tlearn: 0.6687459\ttotal: 2.52s\tremaining: 5.75s\n",
      "305:\tlearn: 0.6683783\ttotal: 2.53s\tremaining: 5.74s\n",
      "306:\tlearn: 0.6675311\ttotal: 2.54s\tremaining: 5.73s\n",
      "307:\tlearn: 0.6667188\ttotal: 2.54s\tremaining: 5.72s\n",
      "308:\tlearn: 0.6663867\ttotal: 2.55s\tremaining: 5.71s\n",
      "309:\tlearn: 0.6659768\ttotal: 2.56s\tremaining: 5.7s\n",
      "310:\tlearn: 0.6652767\ttotal: 2.57s\tremaining: 5.69s\n",
      "311:\tlearn: 0.6647019\ttotal: 2.57s\tremaining: 5.68s\n",
      "312:\tlearn: 0.6638792\ttotal: 2.58s\tremaining: 5.67s\n",
      "313:\tlearn: 0.6631355\ttotal: 2.59s\tremaining: 5.66s\n",
      "314:\tlearn: 0.6626719\ttotal: 2.6s\tremaining: 5.64s\n",
      "315:\tlearn: 0.6622367\ttotal: 2.6s\tremaining: 5.63s\n",
      "316:\tlearn: 0.6618976\ttotal: 2.61s\tremaining: 5.62s\n",
      "317:\tlearn: 0.6610822\ttotal: 2.62s\tremaining: 5.61s\n",
      "318:\tlearn: 0.6604292\ttotal: 2.62s\tremaining: 5.6s\n",
      "319:\tlearn: 0.6601643\ttotal: 2.63s\tremaining: 5.59s\n",
      "320:\tlearn: 0.6596803\ttotal: 2.64s\tremaining: 5.58s\n",
      "321:\tlearn: 0.6592611\ttotal: 2.64s\tremaining: 5.56s\n",
      "322:\tlearn: 0.6588092\ttotal: 2.65s\tremaining: 5.55s\n",
      "323:\tlearn: 0.6583598\ttotal: 2.66s\tremaining: 5.54s\n",
      "324:\tlearn: 0.6579535\ttotal: 2.66s\tremaining: 5.53s\n",
      "325:\tlearn: 0.6572724\ttotal: 2.67s\tremaining: 5.52s\n",
      "326:\tlearn: 0.6568341\ttotal: 2.68s\tremaining: 5.51s\n",
      "327:\tlearn: 0.6563911\ttotal: 2.69s\tremaining: 5.5s\n",
      "328:\tlearn: 0.6556512\ttotal: 2.69s\tremaining: 5.49s\n",
      "329:\tlearn: 0.6551163\ttotal: 2.7s\tremaining: 5.48s\n",
      "330:\tlearn: 0.6545294\ttotal: 2.71s\tremaining: 5.47s\n",
      "331:\tlearn: 0.6541497\ttotal: 2.71s\tremaining: 5.46s\n",
      "332:\tlearn: 0.6534012\ttotal: 2.72s\tremaining: 5.45s\n",
      "333:\tlearn: 0.6530528\ttotal: 2.73s\tremaining: 5.44s\n",
      "334:\tlearn: 0.6525800\ttotal: 2.74s\tremaining: 5.44s\n",
      "335:\tlearn: 0.6519375\ttotal: 2.76s\tremaining: 5.45s\n",
      "336:\tlearn: 0.6515214\ttotal: 2.77s\tremaining: 5.44s\n",
      "337:\tlearn: 0.6507990\ttotal: 2.79s\tremaining: 5.46s\n",
      "338:\tlearn: 0.6496515\ttotal: 2.8s\tremaining: 5.46s\n",
      "339:\tlearn: 0.6493256\ttotal: 2.81s\tremaining: 5.45s\n",
      "340:\tlearn: 0.6489266\ttotal: 2.82s\tremaining: 5.45s\n",
      "341:\tlearn: 0.6481693\ttotal: 2.84s\tremaining: 5.46s\n",
      "342:\tlearn: 0.6478619\ttotal: 2.85s\tremaining: 5.45s\n",
      "343:\tlearn: 0.6475812\ttotal: 2.86s\tremaining: 5.45s\n",
      "344:\tlearn: 0.6469662\ttotal: 2.88s\tremaining: 5.46s\n",
      "345:\tlearn: 0.6466579\ttotal: 2.88s\tremaining: 5.45s\n",
      "346:\tlearn: 0.6458530\ttotal: 2.9s\tremaining: 5.46s\n",
      "347:\tlearn: 0.6453905\ttotal: 2.92s\tremaining: 5.47s\n",
      "348:\tlearn: 0.6450697\ttotal: 2.94s\tremaining: 5.48s\n",
      "349:\tlearn: 0.6447459\ttotal: 2.95s\tremaining: 5.49s\n",
      "350:\tlearn: 0.6441725\ttotal: 2.96s\tremaining: 5.48s\n",
      "351:\tlearn: 0.6438456\ttotal: 2.98s\tremaining: 5.48s\n",
      "352:\tlearn: 0.6434992\ttotal: 2.99s\tremaining: 5.48s\n",
      "353:\tlearn: 0.6431729\ttotal: 3s\tremaining: 5.47s\n",
      "354:\tlearn: 0.6429179\ttotal: 3s\tremaining: 5.46s\n",
      "355:\tlearn: 0.6423782\ttotal: 3.01s\tremaining: 5.45s\n",
      "356:\tlearn: 0.6419360\ttotal: 3.02s\tremaining: 5.44s\n",
      "357:\tlearn: 0.6412128\ttotal: 3.03s\tremaining: 5.43s\n",
      "358:\tlearn: 0.6405552\ttotal: 3.04s\tremaining: 5.42s\n",
      "359:\tlearn: 0.6402053\ttotal: 3.05s\tremaining: 5.42s\n",
      "360:\tlearn: 0.6398894\ttotal: 3.06s\tremaining: 5.41s\n",
      "361:\tlearn: 0.6396018\ttotal: 3.06s\tremaining: 5.4s\n",
      "362:\tlearn: 0.6391573\ttotal: 3.07s\tremaining: 5.39s\n",
      "363:\tlearn: 0.6388483\ttotal: 3.08s\tremaining: 5.38s\n",
      "364:\tlearn: 0.6383781\ttotal: 3.08s\tremaining: 5.37s\n",
      "365:\tlearn: 0.6371850\ttotal: 3.09s\tremaining: 5.36s\n",
      "366:\tlearn: 0.6366821\ttotal: 3.1s\tremaining: 5.35s\n",
      "367:\tlearn: 0.6356403\ttotal: 3.11s\tremaining: 5.34s\n",
      "368:\tlearn: 0.6352393\ttotal: 3.12s\tremaining: 5.33s\n",
      "369:\tlearn: 0.6344262\ttotal: 3.12s\tremaining: 5.32s\n",
      "370:\tlearn: 0.6338813\ttotal: 3.13s\tremaining: 5.3s\n",
      "371:\tlearn: 0.6332882\ttotal: 3.13s\tremaining: 5.29s\n",
      "372:\tlearn: 0.6329969\ttotal: 3.14s\tremaining: 5.28s\n",
      "373:\tlearn: 0.6326332\ttotal: 3.15s\tremaining: 5.27s\n",
      "374:\tlearn: 0.6322700\ttotal: 3.15s\tremaining: 5.26s\n",
      "375:\tlearn: 0.6319541\ttotal: 3.16s\tremaining: 5.25s\n",
      "376:\tlearn: 0.6315624\ttotal: 3.17s\tremaining: 5.24s\n",
      "377:\tlearn: 0.6311331\ttotal: 3.18s\tremaining: 5.23s\n",
      "378:\tlearn: 0.6308495\ttotal: 3.19s\tremaining: 5.22s\n",
      "379:\tlearn: 0.6305548\ttotal: 3.19s\tremaining: 5.21s\n",
      "380:\tlearn: 0.6299766\ttotal: 3.2s\tremaining: 5.2s\n",
      "381:\tlearn: 0.6294684\ttotal: 3.21s\tremaining: 5.18s\n",
      "382:\tlearn: 0.6290545\ttotal: 3.21s\tremaining: 5.17s\n",
      "383:\tlearn: 0.6287444\ttotal: 3.22s\tremaining: 5.16s\n",
      "384:\tlearn: 0.6284565\ttotal: 3.22s\tremaining: 5.15s\n",
      "385:\tlearn: 0.6280755\ttotal: 3.23s\tremaining: 5.14s\n",
      "386:\tlearn: 0.6272613\ttotal: 3.24s\tremaining: 5.13s\n",
      "387:\tlearn: 0.6267762\ttotal: 3.25s\tremaining: 5.12s\n",
      "388:\tlearn: 0.6263225\ttotal: 3.25s\tremaining: 5.11s\n",
      "389:\tlearn: 0.6259608\ttotal: 3.26s\tremaining: 5.1s\n",
      "390:\tlearn: 0.6254079\ttotal: 3.27s\tremaining: 5.08s\n",
      "391:\tlearn: 0.6247283\ttotal: 3.27s\tremaining: 5.08s\n",
      "392:\tlearn: 0.6242290\ttotal: 3.28s\tremaining: 5.07s\n",
      "393:\tlearn: 0.6238092\ttotal: 3.29s\tremaining: 5.06s\n",
      "394:\tlearn: 0.6235273\ttotal: 3.29s\tremaining: 5.04s\n",
      "395:\tlearn: 0.6231590\ttotal: 3.3s\tremaining: 5.04s\n",
      "396:\tlearn: 0.6226400\ttotal: 3.31s\tremaining: 5.03s\n",
      "397:\tlearn: 0.6219880\ttotal: 3.32s\tremaining: 5.02s\n",
      "398:\tlearn: 0.6213487\ttotal: 3.33s\tremaining: 5.01s\n",
      "399:\tlearn: 0.6209667\ttotal: 3.33s\tremaining: 5s\n",
      "400:\tlearn: 0.6207076\ttotal: 3.34s\tremaining: 4.99s\n",
      "401:\tlearn: 0.6200524\ttotal: 3.35s\tremaining: 4.98s\n",
      "402:\tlearn: 0.6196165\ttotal: 3.35s\tremaining: 4.97s\n",
      "403:\tlearn: 0.6193138\ttotal: 3.36s\tremaining: 4.96s\n",
      "404:\tlearn: 0.6189000\ttotal: 3.37s\tremaining: 4.95s\n",
      "405:\tlearn: 0.6185711\ttotal: 3.38s\tremaining: 4.94s\n",
      "406:\tlearn: 0.6181569\ttotal: 3.38s\tremaining: 4.93s\n",
      "407:\tlearn: 0.6177005\ttotal: 3.39s\tremaining: 4.92s\n",
      "408:\tlearn: 0.6174683\ttotal: 3.4s\tremaining: 4.91s\n",
      "409:\tlearn: 0.6169431\ttotal: 3.4s\tremaining: 4.9s\n",
      "410:\tlearn: 0.6164883\ttotal: 3.41s\tremaining: 4.88s\n",
      "411:\tlearn: 0.6157716\ttotal: 3.42s\tremaining: 4.88s\n",
      "412:\tlearn: 0.6154234\ttotal: 3.42s\tremaining: 4.86s\n",
      "413:\tlearn: 0.6150531\ttotal: 3.43s\tremaining: 4.85s\n",
      "414:\tlearn: 0.6146355\ttotal: 3.44s\tremaining: 4.84s\n",
      "415:\tlearn: 0.6141613\ttotal: 3.44s\tremaining: 4.83s\n",
      "416:\tlearn: 0.6139242\ttotal: 3.45s\tremaining: 4.82s\n",
      "417:\tlearn: 0.6134388\ttotal: 3.46s\tremaining: 4.81s\n",
      "418:\tlearn: 0.6130648\ttotal: 3.46s\tremaining: 4.8s\n",
      "419:\tlearn: 0.6127850\ttotal: 3.47s\tremaining: 4.79s\n",
      "420:\tlearn: 0.6123271\ttotal: 3.48s\tremaining: 4.78s\n",
      "421:\tlearn: 0.6120950\ttotal: 3.48s\tremaining: 4.77s\n",
      "422:\tlearn: 0.6117932\ttotal: 3.49s\tremaining: 4.76s\n",
      "423:\tlearn: 0.6113848\ttotal: 3.5s\tremaining: 4.75s\n",
      "424:\tlearn: 0.6110510\ttotal: 3.5s\tremaining: 4.74s\n",
      "425:\tlearn: 0.6106841\ttotal: 3.51s\tremaining: 4.73s\n",
      "426:\tlearn: 0.6103698\ttotal: 3.52s\tremaining: 4.72s\n",
      "427:\tlearn: 0.6100583\ttotal: 3.52s\tremaining: 4.71s\n",
      "428:\tlearn: 0.6096770\ttotal: 3.53s\tremaining: 4.7s\n",
      "429:\tlearn: 0.6093401\ttotal: 3.54s\tremaining: 4.69s\n",
      "430:\tlearn: 0.6089776\ttotal: 3.54s\tremaining: 4.68s\n",
      "431:\tlearn: 0.6087455\ttotal: 3.55s\tremaining: 4.67s\n",
      "432:\tlearn: 0.6083333\ttotal: 3.56s\tremaining: 4.66s\n",
      "433:\tlearn: 0.6078575\ttotal: 3.57s\tremaining: 4.65s\n",
      "434:\tlearn: 0.6076285\ttotal: 3.58s\tremaining: 4.65s\n",
      "435:\tlearn: 0.6072846\ttotal: 3.6s\tremaining: 4.65s\n",
      "436:\tlearn: 0.6070754\ttotal: 3.61s\tremaining: 4.65s\n",
      "437:\tlearn: 0.6067195\ttotal: 3.62s\tremaining: 4.64s\n",
      "438:\tlearn: 0.6064934\ttotal: 3.63s\tremaining: 4.64s\n",
      "439:\tlearn: 0.6059450\ttotal: 3.63s\tremaining: 4.63s\n",
      "440:\tlearn: 0.6051369\ttotal: 3.65s\tremaining: 4.62s\n",
      "441:\tlearn: 0.6047088\ttotal: 3.65s\tremaining: 4.61s\n",
      "442:\tlearn: 0.6044308\ttotal: 3.66s\tremaining: 4.6s\n",
      "443:\tlearn: 0.6041314\ttotal: 3.67s\tremaining: 4.59s\n",
      "444:\tlearn: 0.6034664\ttotal: 3.68s\tremaining: 4.58s\n",
      "445:\tlearn: 0.6032705\ttotal: 3.68s\tremaining: 4.58s\n",
      "446:\tlearn: 0.6029273\ttotal: 3.69s\tremaining: 4.57s\n",
      "447:\tlearn: 0.6026322\ttotal: 3.7s\tremaining: 4.55s\n",
      "448:\tlearn: 0.6024319\ttotal: 3.7s\tremaining: 4.54s\n",
      "449:\tlearn: 0.6019726\ttotal: 3.71s\tremaining: 4.54s\n",
      "450:\tlearn: 0.6015573\ttotal: 3.72s\tremaining: 4.53s\n",
      "451:\tlearn: 0.6007544\ttotal: 3.73s\tremaining: 4.52s\n",
      "452:\tlearn: 0.6004168\ttotal: 3.73s\tremaining: 4.51s\n",
      "453:\tlearn: 0.5997642\ttotal: 3.74s\tremaining: 4.5s\n",
      "454:\tlearn: 0.5991740\ttotal: 3.75s\tremaining: 4.49s\n",
      "455:\tlearn: 0.5987544\ttotal: 3.75s\tremaining: 4.48s\n",
      "456:\tlearn: 0.5984059\ttotal: 3.76s\tremaining: 4.47s\n",
      "457:\tlearn: 0.5978491\ttotal: 3.77s\tremaining: 4.46s\n",
      "458:\tlearn: 0.5974828\ttotal: 3.77s\tremaining: 4.45s\n",
      "459:\tlearn: 0.5971729\ttotal: 3.78s\tremaining: 4.44s\n",
      "460:\tlearn: 0.5969038\ttotal: 3.79s\tremaining: 4.43s\n",
      "461:\tlearn: 0.5964228\ttotal: 3.81s\tremaining: 4.43s\n",
      "462:\tlearn: 0.5961314\ttotal: 3.82s\tremaining: 4.43s\n",
      "463:\tlearn: 0.5956645\ttotal: 3.83s\tremaining: 4.42s\n",
      "464:\tlearn: 0.5954392\ttotal: 3.84s\tremaining: 4.41s\n",
      "465:\tlearn: 0.5951628\ttotal: 3.84s\tremaining: 4.4s\n",
      "466:\tlearn: 0.5947995\ttotal: 3.85s\tremaining: 4.39s\n",
      "467:\tlearn: 0.5943714\ttotal: 3.86s\tremaining: 4.38s\n",
      "468:\tlearn: 0.5940384\ttotal: 3.86s\tremaining: 4.37s\n",
      "469:\tlearn: 0.5938001\ttotal: 3.87s\tremaining: 4.36s\n",
      "470:\tlearn: 0.5934316\ttotal: 3.88s\tremaining: 4.35s\n",
      "471:\tlearn: 0.5931502\ttotal: 3.88s\tremaining: 4.34s\n",
      "472:\tlearn: 0.5926697\ttotal: 3.89s\tremaining: 4.33s\n",
      "473:\tlearn: 0.5922692\ttotal: 3.9s\tremaining: 4.33s\n",
      "474:\tlearn: 0.5920970\ttotal: 3.9s\tremaining: 4.32s\n",
      "475:\tlearn: 0.5917786\ttotal: 3.91s\tremaining: 4.31s\n",
      "476:\tlearn: 0.5915359\ttotal: 3.92s\tremaining: 4.3s\n",
      "477:\tlearn: 0.5913117\ttotal: 3.93s\tremaining: 4.29s\n",
      "478:\tlearn: 0.5909702\ttotal: 3.93s\tremaining: 4.28s\n",
      "479:\tlearn: 0.5905870\ttotal: 3.94s\tremaining: 4.27s\n",
      "480:\tlearn: 0.5901243\ttotal: 3.95s\tremaining: 4.26s\n",
      "481:\tlearn: 0.5897428\ttotal: 3.95s\tremaining: 4.25s\n",
      "482:\tlearn: 0.5891785\ttotal: 3.96s\tremaining: 4.24s\n",
      "483:\tlearn: 0.5887124\ttotal: 3.97s\tremaining: 4.23s\n",
      "484:\tlearn: 0.5885234\ttotal: 3.98s\tremaining: 4.22s\n",
      "485:\tlearn: 0.5882737\ttotal: 4s\tremaining: 4.23s\n",
      "486:\tlearn: 0.5880173\ttotal: 4.01s\tremaining: 4.23s\n",
      "487:\tlearn: 0.5877005\ttotal: 4.02s\tremaining: 4.22s\n",
      "488:\tlearn: 0.5872623\ttotal: 4.04s\tremaining: 4.22s\n",
      "489:\tlearn: 0.5867728\ttotal: 4.04s\tremaining: 4.21s\n",
      "490:\tlearn: 0.5865276\ttotal: 4.05s\tremaining: 4.2s\n",
      "491:\tlearn: 0.5861412\ttotal: 4.06s\tremaining: 4.19s\n",
      "492:\tlearn: 0.5858103\ttotal: 4.06s\tremaining: 4.18s\n",
      "493:\tlearn: 0.5854649\ttotal: 4.07s\tremaining: 4.17s\n",
      "494:\tlearn: 0.5851589\ttotal: 4.08s\tremaining: 4.16s\n",
      "495:\tlearn: 0.5848157\ttotal: 4.08s\tremaining: 4.15s\n",
      "496:\tlearn: 0.5844385\ttotal: 4.09s\tremaining: 4.14s\n",
      "497:\tlearn: 0.5842556\ttotal: 4.1s\tremaining: 4.13s\n",
      "498:\tlearn: 0.5838132\ttotal: 4.11s\tremaining: 4.12s\n",
      "499:\tlearn: 0.5833782\ttotal: 4.11s\tremaining: 4.11s\n",
      "500:\tlearn: 0.5831482\ttotal: 4.12s\tremaining: 4.1s\n",
      "501:\tlearn: 0.5828387\ttotal: 4.13s\tremaining: 4.09s\n",
      "502:\tlearn: 0.5825085\ttotal: 4.13s\tremaining: 4.08s\n",
      "503:\tlearn: 0.5819574\ttotal: 4.14s\tremaining: 4.08s\n",
      "504:\tlearn: 0.5816845\ttotal: 4.15s\tremaining: 4.07s\n",
      "505:\tlearn: 0.5814567\ttotal: 4.16s\tremaining: 4.06s\n",
      "506:\tlearn: 0.5809287\ttotal: 4.17s\tremaining: 4.05s\n",
      "507:\tlearn: 0.5806415\ttotal: 4.17s\tremaining: 4.04s\n",
      "508:\tlearn: 0.5803605\ttotal: 4.18s\tremaining: 4.03s\n",
      "509:\tlearn: 0.5801506\ttotal: 4.18s\tremaining: 4.02s\n",
      "510:\tlearn: 0.5797009\ttotal: 4.19s\tremaining: 4.01s\n",
      "511:\tlearn: 0.5793465\ttotal: 4.2s\tremaining: 4s\n",
      "512:\tlearn: 0.5789372\ttotal: 4.21s\tremaining: 3.99s\n",
      "513:\tlearn: 0.5785839\ttotal: 4.21s\tremaining: 3.98s\n",
      "514:\tlearn: 0.5781659\ttotal: 4.22s\tremaining: 3.97s\n",
      "515:\tlearn: 0.5778706\ttotal: 4.23s\tremaining: 3.96s\n",
      "516:\tlearn: 0.5772654\ttotal: 4.23s\tremaining: 3.95s\n",
      "517:\tlearn: 0.5769913\ttotal: 4.24s\tremaining: 3.94s\n",
      "518:\tlearn: 0.5764939\ttotal: 4.25s\tremaining: 3.94s\n",
      "519:\tlearn: 0.5761732\ttotal: 4.25s\tremaining: 3.93s\n",
      "520:\tlearn: 0.5758587\ttotal: 4.26s\tremaining: 3.92s\n",
      "521:\tlearn: 0.5756721\ttotal: 4.27s\tremaining: 3.91s\n",
      "522:\tlearn: 0.5754343\ttotal: 4.27s\tremaining: 3.9s\n",
      "523:\tlearn: 0.5750763\ttotal: 4.28s\tremaining: 3.89s\n",
      "524:\tlearn: 0.5748189\ttotal: 4.29s\tremaining: 3.88s\n",
      "525:\tlearn: 0.5745346\ttotal: 4.29s\tremaining: 3.87s\n",
      "526:\tlearn: 0.5742684\ttotal: 4.3s\tremaining: 3.86s\n",
      "527:\tlearn: 0.5738576\ttotal: 4.31s\tremaining: 3.85s\n",
      "528:\tlearn: 0.5735074\ttotal: 4.32s\tremaining: 3.85s\n",
      "529:\tlearn: 0.5730286\ttotal: 4.33s\tremaining: 3.84s\n",
      "530:\tlearn: 0.5726578\ttotal: 4.33s\tremaining: 3.83s\n",
      "531:\tlearn: 0.5723341\ttotal: 4.34s\tremaining: 3.82s\n",
      "532:\tlearn: 0.5721432\ttotal: 4.35s\tremaining: 3.81s\n",
      "533:\tlearn: 0.5718082\ttotal: 4.36s\tremaining: 3.8s\n",
      "534:\tlearn: 0.5714500\ttotal: 4.36s\tremaining: 3.79s\n",
      "535:\tlearn: 0.5713214\ttotal: 4.37s\tremaining: 3.78s\n",
      "536:\tlearn: 0.5710480\ttotal: 4.38s\tremaining: 3.77s\n",
      "537:\tlearn: 0.5708644\ttotal: 4.38s\tremaining: 3.76s\n",
      "538:\tlearn: 0.5705197\ttotal: 4.39s\tremaining: 3.75s\n",
      "539:\tlearn: 0.5703124\ttotal: 4.39s\tremaining: 3.74s\n",
      "540:\tlearn: 0.5698421\ttotal: 4.4s\tremaining: 3.73s\n",
      "541:\tlearn: 0.5694887\ttotal: 4.41s\tremaining: 3.73s\n",
      "542:\tlearn: 0.5691416\ttotal: 4.42s\tremaining: 3.72s\n",
      "543:\tlearn: 0.5688205\ttotal: 4.42s\tremaining: 3.71s\n",
      "544:\tlearn: 0.5685415\ttotal: 4.43s\tremaining: 3.7s\n",
      "545:\tlearn: 0.5682906\ttotal: 4.44s\tremaining: 3.69s\n",
      "546:\tlearn: 0.5675834\ttotal: 4.44s\tremaining: 3.68s\n",
      "547:\tlearn: 0.5671512\ttotal: 4.46s\tremaining: 3.68s\n",
      "548:\tlearn: 0.5667848\ttotal: 4.47s\tremaining: 3.67s\n",
      "549:\tlearn: 0.5664615\ttotal: 4.49s\tremaining: 3.67s\n",
      "550:\tlearn: 0.5662626\ttotal: 4.5s\tremaining: 3.66s\n",
      "551:\tlearn: 0.5659176\ttotal: 4.5s\tremaining: 3.65s\n",
      "552:\tlearn: 0.5657486\ttotal: 4.51s\tremaining: 3.65s\n",
      "553:\tlearn: 0.5652124\ttotal: 4.52s\tremaining: 3.64s\n",
      "554:\tlearn: 0.5649066\ttotal: 4.53s\tremaining: 3.63s\n",
      "555:\tlearn: 0.5646246\ttotal: 4.53s\tremaining: 3.62s\n",
      "556:\tlearn: 0.5641927\ttotal: 4.54s\tremaining: 3.61s\n",
      "557:\tlearn: 0.5639478\ttotal: 4.55s\tremaining: 3.6s\n",
      "558:\tlearn: 0.5636608\ttotal: 4.55s\tremaining: 3.59s\n",
      "559:\tlearn: 0.5632310\ttotal: 4.56s\tremaining: 3.58s\n",
      "560:\tlearn: 0.5630205\ttotal: 4.57s\tremaining: 3.57s\n",
      "561:\tlearn: 0.5628599\ttotal: 4.57s\tremaining: 3.56s\n",
      "562:\tlearn: 0.5624757\ttotal: 4.58s\tremaining: 3.56s\n",
      "563:\tlearn: 0.5620593\ttotal: 4.59s\tremaining: 3.54s\n",
      "564:\tlearn: 0.5617065\ttotal: 4.59s\tremaining: 3.54s\n",
      "565:\tlearn: 0.5611341\ttotal: 4.6s\tremaining: 3.53s\n",
      "566:\tlearn: 0.5608389\ttotal: 4.61s\tremaining: 3.52s\n",
      "567:\tlearn: 0.5605322\ttotal: 4.61s\tremaining: 3.51s\n",
      "568:\tlearn: 0.5603092\ttotal: 4.62s\tremaining: 3.5s\n",
      "569:\tlearn: 0.5599902\ttotal: 4.63s\tremaining: 3.49s\n",
      "570:\tlearn: 0.5592240\ttotal: 4.63s\tremaining: 3.48s\n",
      "571:\tlearn: 0.5589297\ttotal: 4.64s\tremaining: 3.47s\n",
      "572:\tlearn: 0.5586371\ttotal: 4.65s\tremaining: 3.46s\n",
      "573:\tlearn: 0.5584746\ttotal: 4.66s\tremaining: 3.46s\n",
      "574:\tlearn: 0.5583082\ttotal: 4.66s\tremaining: 3.45s\n",
      "575:\tlearn: 0.5581233\ttotal: 4.67s\tremaining: 3.44s\n",
      "576:\tlearn: 0.5576952\ttotal: 4.68s\tremaining: 3.43s\n",
      "577:\tlearn: 0.5574602\ttotal: 4.69s\tremaining: 3.42s\n",
      "578:\tlearn: 0.5570794\ttotal: 4.69s\tremaining: 3.41s\n",
      "579:\tlearn: 0.5567434\ttotal: 4.7s\tremaining: 3.4s\n",
      "580:\tlearn: 0.5563992\ttotal: 4.71s\tremaining: 3.4s\n",
      "581:\tlearn: 0.5560089\ttotal: 4.73s\tremaining: 3.4s\n",
      "582:\tlearn: 0.5554311\ttotal: 4.75s\tremaining: 3.4s\n",
      "583:\tlearn: 0.5552873\ttotal: 4.76s\tremaining: 3.39s\n",
      "584:\tlearn: 0.5549775\ttotal: 4.78s\tremaining: 3.39s\n",
      "585:\tlearn: 0.5547803\ttotal: 4.79s\tremaining: 3.38s\n",
      "586:\tlearn: 0.5546078\ttotal: 4.81s\tremaining: 3.38s\n",
      "587:\tlearn: 0.5543651\ttotal: 4.82s\tremaining: 3.38s\n",
      "588:\tlearn: 0.5539932\ttotal: 4.84s\tremaining: 3.38s\n",
      "589:\tlearn: 0.5535812\ttotal: 4.85s\tremaining: 3.37s\n",
      "590:\tlearn: 0.5532756\ttotal: 4.86s\tremaining: 3.36s\n",
      "591:\tlearn: 0.5530575\ttotal: 4.86s\tremaining: 3.35s\n",
      "592:\tlearn: 0.5527481\ttotal: 4.87s\tremaining: 3.34s\n",
      "593:\tlearn: 0.5523695\ttotal: 4.88s\tremaining: 3.33s\n",
      "594:\tlearn: 0.5520359\ttotal: 4.89s\tremaining: 3.33s\n",
      "595:\tlearn: 0.5518059\ttotal: 4.89s\tremaining: 3.32s\n",
      "596:\tlearn: 0.5515245\ttotal: 4.9s\tremaining: 3.31s\n",
      "597:\tlearn: 0.5513554\ttotal: 4.91s\tremaining: 3.3s\n",
      "598:\tlearn: 0.5510385\ttotal: 4.91s\tremaining: 3.29s\n",
      "599:\tlearn: 0.5505665\ttotal: 4.92s\tremaining: 3.28s\n",
      "600:\tlearn: 0.5501125\ttotal: 4.93s\tremaining: 3.27s\n",
      "601:\tlearn: 0.5495115\ttotal: 4.93s\tremaining: 3.26s\n",
      "602:\tlearn: 0.5492162\ttotal: 4.94s\tremaining: 3.25s\n",
      "603:\tlearn: 0.5488629\ttotal: 4.95s\tremaining: 3.24s\n",
      "604:\tlearn: 0.5484198\ttotal: 4.96s\tremaining: 3.23s\n",
      "605:\tlearn: 0.5482576\ttotal: 4.96s\tremaining: 3.23s\n",
      "606:\tlearn: 0.5481102\ttotal: 4.97s\tremaining: 3.22s\n",
      "607:\tlearn: 0.5479095\ttotal: 4.97s\tremaining: 3.21s\n",
      "608:\tlearn: 0.5476889\ttotal: 4.98s\tremaining: 3.2s\n",
      "609:\tlearn: 0.5474293\ttotal: 4.99s\tremaining: 3.19s\n",
      "610:\tlearn: 0.5470692\ttotal: 4.99s\tremaining: 3.18s\n",
      "611:\tlearn: 0.5468767\ttotal: 5s\tremaining: 3.17s\n",
      "612:\tlearn: 0.5466473\ttotal: 5.01s\tremaining: 3.16s\n",
      "613:\tlearn: 0.5463116\ttotal: 5.02s\tremaining: 3.15s\n",
      "614:\tlearn: 0.5459482\ttotal: 5.03s\tremaining: 3.15s\n",
      "615:\tlearn: 0.5456041\ttotal: 5.04s\tremaining: 3.14s\n",
      "616:\tlearn: 0.5454116\ttotal: 5.04s\tremaining: 3.13s\n",
      "617:\tlearn: 0.5451375\ttotal: 5.05s\tremaining: 3.12s\n",
      "618:\tlearn: 0.5449509\ttotal: 5.06s\tremaining: 3.11s\n",
      "619:\tlearn: 0.5445093\ttotal: 5.07s\tremaining: 3.1s\n",
      "620:\tlearn: 0.5442558\ttotal: 5.07s\tremaining: 3.1s\n",
      "621:\tlearn: 0.5440653\ttotal: 5.08s\tremaining: 3.09s\n",
      "622:\tlearn: 0.5438030\ttotal: 5.09s\tremaining: 3.08s\n",
      "623:\tlearn: 0.5436320\ttotal: 5.1s\tremaining: 3.07s\n",
      "624:\tlearn: 0.5432207\ttotal: 5.11s\tremaining: 3.06s\n",
      "625:\tlearn: 0.5430445\ttotal: 5.11s\tremaining: 3.06s\n",
      "626:\tlearn: 0.5427943\ttotal: 5.12s\tremaining: 3.05s\n",
      "627:\tlearn: 0.5424595\ttotal: 5.13s\tremaining: 3.04s\n",
      "628:\tlearn: 0.5422264\ttotal: 5.14s\tremaining: 3.03s\n",
      "629:\tlearn: 0.5420747\ttotal: 5.14s\tremaining: 3.02s\n",
      "630:\tlearn: 0.5418002\ttotal: 5.15s\tremaining: 3.01s\n",
      "631:\tlearn: 0.5414810\ttotal: 5.16s\tremaining: 3s\n",
      "632:\tlearn: 0.5412755\ttotal: 5.16s\tremaining: 2.99s\n",
      "633:\tlearn: 0.5408771\ttotal: 5.17s\tremaining: 2.98s\n",
      "634:\tlearn: 0.5405411\ttotal: 5.18s\tremaining: 2.98s\n",
      "635:\tlearn: 0.5402513\ttotal: 5.18s\tremaining: 2.97s\n",
      "636:\tlearn: 0.5400757\ttotal: 5.19s\tremaining: 2.96s\n",
      "637:\tlearn: 0.5396394\ttotal: 5.2s\tremaining: 2.95s\n",
      "638:\tlearn: 0.5393799\ttotal: 5.2s\tremaining: 2.94s\n",
      "639:\tlearn: 0.5391841\ttotal: 5.21s\tremaining: 2.93s\n",
      "640:\tlearn: 0.5389464\ttotal: 5.22s\tremaining: 2.92s\n",
      "641:\tlearn: 0.5386700\ttotal: 5.22s\tremaining: 2.91s\n",
      "642:\tlearn: 0.5381243\ttotal: 5.23s\tremaining: 2.9s\n",
      "643:\tlearn: 0.5378091\ttotal: 5.24s\tremaining: 2.9s\n",
      "644:\tlearn: 0.5374191\ttotal: 5.25s\tremaining: 2.89s\n",
      "645:\tlearn: 0.5372565\ttotal: 5.26s\tremaining: 2.88s\n",
      "646:\tlearn: 0.5370475\ttotal: 5.26s\tremaining: 2.87s\n",
      "647:\tlearn: 0.5368515\ttotal: 5.27s\tremaining: 2.87s\n",
      "648:\tlearn: 0.5362997\ttotal: 5.28s\tremaining: 2.86s\n",
      "649:\tlearn: 0.5361491\ttotal: 5.29s\tremaining: 2.85s\n",
      "650:\tlearn: 0.5359009\ttotal: 5.31s\tremaining: 2.85s\n",
      "651:\tlearn: 0.5357735\ttotal: 5.33s\tremaining: 2.84s\n",
      "652:\tlearn: 0.5353931\ttotal: 5.34s\tremaining: 2.83s\n",
      "653:\tlearn: 0.5351787\ttotal: 5.34s\tremaining: 2.83s\n",
      "654:\tlearn: 0.5349410\ttotal: 5.35s\tremaining: 2.82s\n",
      "655:\tlearn: 0.5343530\ttotal: 5.36s\tremaining: 2.81s\n",
      "656:\tlearn: 0.5340998\ttotal: 5.37s\tremaining: 2.8s\n",
      "657:\tlearn: 0.5337978\ttotal: 5.37s\tremaining: 2.79s\n",
      "658:\tlearn: 0.5336120\ttotal: 5.38s\tremaining: 2.78s\n",
      "659:\tlearn: 0.5332926\ttotal: 5.39s\tremaining: 2.77s\n",
      "660:\tlearn: 0.5330498\ttotal: 5.39s\tremaining: 2.77s\n",
      "661:\tlearn: 0.5326450\ttotal: 5.4s\tremaining: 2.76s\n",
      "662:\tlearn: 0.5324007\ttotal: 5.41s\tremaining: 2.75s\n",
      "663:\tlearn: 0.5321787\ttotal: 5.42s\tremaining: 2.74s\n",
      "664:\tlearn: 0.5318750\ttotal: 5.42s\tremaining: 2.73s\n",
      "665:\tlearn: 0.5316179\ttotal: 5.43s\tremaining: 2.72s\n",
      "666:\tlearn: 0.5313486\ttotal: 5.44s\tremaining: 2.71s\n",
      "667:\tlearn: 0.5309360\ttotal: 5.44s\tremaining: 2.71s\n",
      "668:\tlearn: 0.5306542\ttotal: 5.45s\tremaining: 2.7s\n",
      "669:\tlearn: 0.5303500\ttotal: 5.46s\tremaining: 2.69s\n",
      "670:\tlearn: 0.5301663\ttotal: 5.46s\tremaining: 2.68s\n",
      "671:\tlearn: 0.5298802\ttotal: 5.47s\tremaining: 2.67s\n",
      "672:\tlearn: 0.5295996\ttotal: 5.48s\tremaining: 2.66s\n",
      "673:\tlearn: 0.5294025\ttotal: 5.49s\tremaining: 2.65s\n",
      "674:\tlearn: 0.5290440\ttotal: 5.5s\tremaining: 2.65s\n",
      "675:\tlearn: 0.5287558\ttotal: 5.5s\tremaining: 2.64s\n",
      "676:\tlearn: 0.5285970\ttotal: 5.51s\tremaining: 2.63s\n",
      "677:\tlearn: 0.5282462\ttotal: 5.52s\tremaining: 2.62s\n",
      "678:\tlearn: 0.5280013\ttotal: 5.52s\tremaining: 2.61s\n",
      "679:\tlearn: 0.5275959\ttotal: 5.53s\tremaining: 2.6s\n",
      "680:\tlearn: 0.5272977\ttotal: 5.54s\tremaining: 2.6s\n",
      "681:\tlearn: 0.5270963\ttotal: 5.55s\tremaining: 2.59s\n",
      "682:\tlearn: 0.5269024\ttotal: 5.55s\tremaining: 2.58s\n",
      "683:\tlearn: 0.5266011\ttotal: 5.56s\tremaining: 2.57s\n",
      "684:\tlearn: 0.5261045\ttotal: 5.57s\tremaining: 2.56s\n",
      "685:\tlearn: 0.5258438\ttotal: 5.58s\tremaining: 2.55s\n",
      "686:\tlearn: 0.5255667\ttotal: 5.58s\tremaining: 2.54s\n",
      "687:\tlearn: 0.5253253\ttotal: 5.59s\tremaining: 2.53s\n",
      "688:\tlearn: 0.5252309\ttotal: 5.6s\tremaining: 2.53s\n",
      "689:\tlearn: 0.5250707\ttotal: 5.6s\tremaining: 2.52s\n",
      "690:\tlearn: 0.5246765\ttotal: 5.61s\tremaining: 2.51s\n",
      "691:\tlearn: 0.5243827\ttotal: 5.62s\tremaining: 2.5s\n",
      "692:\tlearn: 0.5240494\ttotal: 5.62s\tremaining: 2.49s\n",
      "693:\tlearn: 0.5238952\ttotal: 5.63s\tremaining: 2.48s\n",
      "694:\tlearn: 0.5236226\ttotal: 5.64s\tremaining: 2.47s\n",
      "695:\tlearn: 0.5233704\ttotal: 5.64s\tremaining: 2.46s\n",
      "696:\tlearn: 0.5231807\ttotal: 5.65s\tremaining: 2.46s\n",
      "697:\tlearn: 0.5229948\ttotal: 5.66s\tremaining: 2.45s\n",
      "698:\tlearn: 0.5227015\ttotal: 5.67s\tremaining: 2.44s\n",
      "699:\tlearn: 0.5224461\ttotal: 5.67s\tremaining: 2.43s\n",
      "700:\tlearn: 0.5221321\ttotal: 5.68s\tremaining: 2.42s\n",
      "701:\tlearn: 0.5218173\ttotal: 5.69s\tremaining: 2.41s\n",
      "702:\tlearn: 0.5216765\ttotal: 5.69s\tremaining: 2.4s\n",
      "703:\tlearn: 0.5214060\ttotal: 5.7s\tremaining: 2.4s\n",
      "704:\tlearn: 0.5211076\ttotal: 5.71s\tremaining: 2.39s\n",
      "705:\tlearn: 0.5207786\ttotal: 5.71s\tremaining: 2.38s\n",
      "706:\tlearn: 0.5204925\ttotal: 5.72s\tremaining: 2.37s\n",
      "707:\tlearn: 0.5202724\ttotal: 5.73s\tremaining: 2.36s\n",
      "708:\tlearn: 0.5201111\ttotal: 5.74s\tremaining: 2.35s\n",
      "709:\tlearn: 0.5197626\ttotal: 5.75s\tremaining: 2.35s\n",
      "710:\tlearn: 0.5195366\ttotal: 5.75s\tremaining: 2.34s\n",
      "711:\tlearn: 0.5192374\ttotal: 5.76s\tremaining: 2.33s\n",
      "712:\tlearn: 0.5189894\ttotal: 5.76s\tremaining: 2.32s\n",
      "713:\tlearn: 0.5187823\ttotal: 5.77s\tremaining: 2.31s\n",
      "714:\tlearn: 0.5185395\ttotal: 5.78s\tremaining: 2.3s\n",
      "715:\tlearn: 0.5184144\ttotal: 5.79s\tremaining: 2.29s\n",
      "716:\tlearn: 0.5181020\ttotal: 5.79s\tremaining: 2.29s\n",
      "717:\tlearn: 0.5177744\ttotal: 5.8s\tremaining: 2.28s\n",
      "718:\tlearn: 0.5173855\ttotal: 5.81s\tremaining: 2.27s\n",
      "719:\tlearn: 0.5171925\ttotal: 5.81s\tremaining: 2.26s\n",
      "720:\tlearn: 0.5169008\ttotal: 5.82s\tremaining: 2.25s\n",
      "721:\tlearn: 0.5167416\ttotal: 5.83s\tremaining: 2.24s\n",
      "722:\tlearn: 0.5163140\ttotal: 5.83s\tremaining: 2.23s\n",
      "723:\tlearn: 0.5161706\ttotal: 5.84s\tremaining: 2.23s\n",
      "724:\tlearn: 0.5158881\ttotal: 5.85s\tremaining: 2.22s\n",
      "725:\tlearn: 0.5156683\ttotal: 5.85s\tremaining: 2.21s\n",
      "726:\tlearn: 0.5154390\ttotal: 5.86s\tremaining: 2.2s\n",
      "727:\tlearn: 0.5152015\ttotal: 5.87s\tremaining: 2.19s\n",
      "728:\tlearn: 0.5150007\ttotal: 5.87s\tremaining: 2.18s\n",
      "729:\tlearn: 0.5148127\ttotal: 5.88s\tremaining: 2.17s\n",
      "730:\tlearn: 0.5145201\ttotal: 5.89s\tremaining: 2.17s\n",
      "731:\tlearn: 0.5141709\ttotal: 5.89s\tremaining: 2.16s\n",
      "732:\tlearn: 0.5140042\ttotal: 5.9s\tremaining: 2.15s\n",
      "733:\tlearn: 0.5137338\ttotal: 5.91s\tremaining: 2.14s\n",
      "734:\tlearn: 0.5135000\ttotal: 5.92s\tremaining: 2.13s\n",
      "735:\tlearn: 0.5133475\ttotal: 5.92s\tremaining: 2.12s\n",
      "736:\tlearn: 0.5131544\ttotal: 5.93s\tremaining: 2.12s\n",
      "737:\tlearn: 0.5129582\ttotal: 5.94s\tremaining: 2.11s\n",
      "738:\tlearn: 0.5125473\ttotal: 5.94s\tremaining: 2.1s\n",
      "739:\tlearn: 0.5120591\ttotal: 5.95s\tremaining: 2.09s\n",
      "740:\tlearn: 0.5118497\ttotal: 5.96s\tremaining: 2.08s\n",
      "741:\tlearn: 0.5116845\ttotal: 5.96s\tremaining: 2.07s\n",
      "742:\tlearn: 0.5115252\ttotal: 5.97s\tremaining: 2.06s\n",
      "743:\tlearn: 0.5112816\ttotal: 5.98s\tremaining: 2.06s\n",
      "744:\tlearn: 0.5108623\ttotal: 5.98s\tremaining: 2.05s\n",
      "745:\tlearn: 0.5107347\ttotal: 5.99s\tremaining: 2.04s\n",
      "746:\tlearn: 0.5105368\ttotal: 6s\tremaining: 2.03s\n",
      "747:\tlearn: 0.5101464\ttotal: 6.01s\tremaining: 2.02s\n",
      "748:\tlearn: 0.5100130\ttotal: 6.02s\tremaining: 2.02s\n",
      "749:\tlearn: 0.5097780\ttotal: 6.03s\tremaining: 2.01s\n",
      "750:\tlearn: 0.5095923\ttotal: 6.05s\tremaining: 2.01s\n",
      "751:\tlearn: 0.5094226\ttotal: 6.06s\tremaining: 2s\n",
      "752:\tlearn: 0.5092447\ttotal: 6.07s\tremaining: 1.99s\n",
      "753:\tlearn: 0.5090622\ttotal: 6.08s\tremaining: 1.98s\n",
      "754:\tlearn: 0.5088590\ttotal: 6.1s\tremaining: 1.98s\n",
      "755:\tlearn: 0.5086218\ttotal: 6.11s\tremaining: 1.97s\n",
      "756:\tlearn: 0.5084614\ttotal: 6.12s\tremaining: 1.97s\n",
      "757:\tlearn: 0.5080627\ttotal: 6.13s\tremaining: 1.96s\n",
      "758:\tlearn: 0.5078646\ttotal: 6.14s\tremaining: 1.95s\n",
      "759:\tlearn: 0.5076795\ttotal: 6.15s\tremaining: 1.94s\n",
      "760:\tlearn: 0.5072856\ttotal: 6.15s\tremaining: 1.93s\n",
      "761:\tlearn: 0.5070154\ttotal: 6.16s\tremaining: 1.92s\n",
      "762:\tlearn: 0.5068852\ttotal: 6.17s\tremaining: 1.92s\n",
      "763:\tlearn: 0.5066677\ttotal: 6.17s\tremaining: 1.91s\n",
      "764:\tlearn: 0.5064240\ttotal: 6.18s\tremaining: 1.9s\n",
      "765:\tlearn: 0.5062008\ttotal: 6.19s\tremaining: 1.89s\n",
      "766:\tlearn: 0.5060103\ttotal: 6.19s\tremaining: 1.88s\n",
      "767:\tlearn: 0.5058313\ttotal: 6.2s\tremaining: 1.87s\n",
      "768:\tlearn: 0.5056472\ttotal: 6.21s\tremaining: 1.86s\n",
      "769:\tlearn: 0.5052147\ttotal: 6.21s\tremaining: 1.86s\n",
      "770:\tlearn: 0.5050541\ttotal: 6.22s\tremaining: 1.85s\n",
      "771:\tlearn: 0.5048371\ttotal: 6.23s\tremaining: 1.84s\n",
      "772:\tlearn: 0.5046856\ttotal: 6.24s\tremaining: 1.83s\n",
      "773:\tlearn: 0.5042475\ttotal: 6.24s\tremaining: 1.82s\n",
      "774:\tlearn: 0.5039315\ttotal: 6.25s\tremaining: 1.81s\n",
      "775:\tlearn: 0.5037206\ttotal: 6.25s\tremaining: 1.8s\n",
      "776:\tlearn: 0.5035285\ttotal: 6.26s\tremaining: 1.8s\n",
      "777:\tlearn: 0.5033728\ttotal: 6.27s\tremaining: 1.79s\n",
      "778:\tlearn: 0.5031266\ttotal: 6.28s\tremaining: 1.78s\n",
      "779:\tlearn: 0.5029202\ttotal: 6.28s\tremaining: 1.77s\n",
      "780:\tlearn: 0.5027465\ttotal: 6.29s\tremaining: 1.76s\n",
      "781:\tlearn: 0.5023500\ttotal: 6.3s\tremaining: 1.76s\n",
      "782:\tlearn: 0.5021760\ttotal: 6.31s\tremaining: 1.75s\n",
      "783:\tlearn: 0.5018280\ttotal: 6.31s\tremaining: 1.74s\n",
      "784:\tlearn: 0.5016093\ttotal: 6.32s\tremaining: 1.73s\n",
      "785:\tlearn: 0.5014465\ttotal: 6.33s\tremaining: 1.72s\n",
      "786:\tlearn: 0.5012251\ttotal: 6.34s\tremaining: 1.72s\n",
      "787:\tlearn: 0.5010062\ttotal: 6.34s\tremaining: 1.71s\n",
      "788:\tlearn: 0.5007962\ttotal: 6.35s\tremaining: 1.7s\n",
      "789:\tlearn: 0.5006298\ttotal: 6.36s\tremaining: 1.69s\n",
      "790:\tlearn: 0.5004475\ttotal: 6.36s\tremaining: 1.68s\n",
      "791:\tlearn: 0.5002281\ttotal: 6.37s\tremaining: 1.67s\n",
      "792:\tlearn: 0.4998162\ttotal: 6.38s\tremaining: 1.67s\n",
      "793:\tlearn: 0.4995420\ttotal: 6.4s\tremaining: 1.66s\n",
      "794:\tlearn: 0.4992363\ttotal: 6.41s\tremaining: 1.65s\n",
      "795:\tlearn: 0.4990750\ttotal: 6.43s\tremaining: 1.65s\n",
      "796:\tlearn: 0.4988291\ttotal: 6.45s\tremaining: 1.64s\n",
      "797:\tlearn: 0.4985741\ttotal: 6.45s\tremaining: 1.63s\n",
      "798:\tlearn: 0.4983266\ttotal: 6.46s\tremaining: 1.62s\n",
      "799:\tlearn: 0.4980888\ttotal: 6.46s\tremaining: 1.62s\n",
      "800:\tlearn: 0.4977979\ttotal: 6.47s\tremaining: 1.61s\n",
      "801:\tlearn: 0.4975832\ttotal: 6.48s\tremaining: 1.6s\n",
      "802:\tlearn: 0.4974450\ttotal: 6.49s\tremaining: 1.59s\n",
      "803:\tlearn: 0.4971986\ttotal: 6.49s\tremaining: 1.58s\n",
      "804:\tlearn: 0.4970184\ttotal: 6.5s\tremaining: 1.57s\n",
      "805:\tlearn: 0.4966318\ttotal: 6.51s\tremaining: 1.57s\n",
      "806:\tlearn: 0.4964130\ttotal: 6.51s\tremaining: 1.56s\n",
      "807:\tlearn: 0.4959834\ttotal: 6.52s\tremaining: 1.55s\n",
      "808:\tlearn: 0.4958149\ttotal: 6.53s\tremaining: 1.54s\n",
      "809:\tlearn: 0.4955834\ttotal: 6.54s\tremaining: 1.53s\n",
      "810:\tlearn: 0.4952817\ttotal: 6.54s\tremaining: 1.52s\n",
      "811:\tlearn: 0.4950384\ttotal: 6.55s\tremaining: 1.52s\n",
      "812:\tlearn: 0.4948971\ttotal: 6.56s\tremaining: 1.51s\n",
      "813:\tlearn: 0.4946943\ttotal: 6.57s\tremaining: 1.5s\n",
      "814:\tlearn: 0.4945496\ttotal: 6.57s\tremaining: 1.49s\n",
      "815:\tlearn: 0.4943876\ttotal: 6.58s\tremaining: 1.48s\n",
      "816:\tlearn: 0.4941311\ttotal: 6.6s\tremaining: 1.48s\n",
      "817:\tlearn: 0.4938614\ttotal: 6.61s\tremaining: 1.47s\n",
      "818:\tlearn: 0.4936816\ttotal: 6.63s\tremaining: 1.47s\n",
      "819:\tlearn: 0.4934201\ttotal: 6.65s\tremaining: 1.46s\n",
      "820:\tlearn: 0.4929421\ttotal: 6.67s\tremaining: 1.45s\n",
      "821:\tlearn: 0.4927062\ttotal: 6.68s\tremaining: 1.45s\n",
      "822:\tlearn: 0.4925590\ttotal: 6.69s\tremaining: 1.44s\n",
      "823:\tlearn: 0.4922747\ttotal: 6.7s\tremaining: 1.43s\n",
      "824:\tlearn: 0.4920706\ttotal: 6.71s\tremaining: 1.42s\n",
      "825:\tlearn: 0.4919133\ttotal: 6.72s\tremaining: 1.42s\n",
      "826:\tlearn: 0.4916403\ttotal: 6.74s\tremaining: 1.41s\n",
      "827:\tlearn: 0.4914869\ttotal: 6.75s\tremaining: 1.4s\n",
      "828:\tlearn: 0.4912501\ttotal: 6.76s\tremaining: 1.39s\n",
      "829:\tlearn: 0.4910635\ttotal: 6.76s\tremaining: 1.39s\n",
      "830:\tlearn: 0.4907827\ttotal: 6.77s\tremaining: 1.38s\n",
      "831:\tlearn: 0.4906467\ttotal: 6.78s\tremaining: 1.37s\n",
      "832:\tlearn: 0.4904216\ttotal: 6.78s\tremaining: 1.36s\n",
      "833:\tlearn: 0.4902057\ttotal: 6.79s\tremaining: 1.35s\n",
      "834:\tlearn: 0.4898962\ttotal: 6.8s\tremaining: 1.34s\n",
      "835:\tlearn: 0.4896925\ttotal: 6.8s\tremaining: 1.33s\n",
      "836:\tlearn: 0.4894445\ttotal: 6.81s\tremaining: 1.33s\n",
      "837:\tlearn: 0.4891573\ttotal: 6.82s\tremaining: 1.32s\n",
      "838:\tlearn: 0.4890097\ttotal: 6.83s\tremaining: 1.31s\n",
      "839:\tlearn: 0.4888381\ttotal: 6.83s\tremaining: 1.3s\n",
      "840:\tlearn: 0.4886895\ttotal: 6.84s\tremaining: 1.29s\n",
      "841:\tlearn: 0.4885211\ttotal: 6.84s\tremaining: 1.28s\n",
      "842:\tlearn: 0.4883607\ttotal: 6.85s\tremaining: 1.28s\n",
      "843:\tlearn: 0.4882314\ttotal: 6.86s\tremaining: 1.27s\n",
      "844:\tlearn: 0.4880062\ttotal: 6.86s\tremaining: 1.26s\n",
      "845:\tlearn: 0.4878230\ttotal: 6.87s\tremaining: 1.25s\n",
      "846:\tlearn: 0.4876181\ttotal: 6.88s\tremaining: 1.24s\n",
      "847:\tlearn: 0.4873119\ttotal: 6.88s\tremaining: 1.23s\n",
      "848:\tlearn: 0.4871228\ttotal: 6.89s\tremaining: 1.23s\n",
      "849:\tlearn: 0.4867617\ttotal: 6.9s\tremaining: 1.22s\n",
      "850:\tlearn: 0.4864116\ttotal: 6.91s\tremaining: 1.21s\n",
      "851:\tlearn: 0.4860382\ttotal: 6.91s\tremaining: 1.2s\n",
      "852:\tlearn: 0.4858901\ttotal: 6.92s\tremaining: 1.19s\n",
      "853:\tlearn: 0.4857579\ttotal: 6.93s\tremaining: 1.18s\n",
      "854:\tlearn: 0.4856141\ttotal: 6.94s\tremaining: 1.18s\n",
      "855:\tlearn: 0.4852988\ttotal: 6.94s\tremaining: 1.17s\n",
      "856:\tlearn: 0.4851409\ttotal: 6.95s\tremaining: 1.16s\n",
      "857:\tlearn: 0.4847816\ttotal: 6.96s\tremaining: 1.15s\n",
      "858:\tlearn: 0.4845960\ttotal: 6.96s\tremaining: 1.14s\n",
      "859:\tlearn: 0.4843742\ttotal: 6.97s\tremaining: 1.13s\n",
      "860:\tlearn: 0.4839881\ttotal: 6.98s\tremaining: 1.13s\n",
      "861:\tlearn: 0.4837586\ttotal: 6.98s\tremaining: 1.12s\n",
      "862:\tlearn: 0.4835651\ttotal: 6.99s\tremaining: 1.11s\n",
      "863:\tlearn: 0.4833088\ttotal: 7s\tremaining: 1.1s\n",
      "864:\tlearn: 0.4831592\ttotal: 7.01s\tremaining: 1.09s\n",
      "865:\tlearn: 0.4829682\ttotal: 7.02s\tremaining: 1.09s\n",
      "866:\tlearn: 0.4827513\ttotal: 7.03s\tremaining: 1.08s\n",
      "867:\tlearn: 0.4826088\ttotal: 7.03s\tremaining: 1.07s\n",
      "868:\tlearn: 0.4824058\ttotal: 7.04s\tremaining: 1.06s\n",
      "869:\tlearn: 0.4822309\ttotal: 7.05s\tremaining: 1.05s\n",
      "870:\tlearn: 0.4820127\ttotal: 7.05s\tremaining: 1.04s\n",
      "871:\tlearn: 0.4818673\ttotal: 7.06s\tremaining: 1.04s\n",
      "872:\tlearn: 0.4816592\ttotal: 7.07s\tremaining: 1.03s\n",
      "873:\tlearn: 0.4814880\ttotal: 7.08s\tremaining: 1.02s\n",
      "874:\tlearn: 0.4812798\ttotal: 7.08s\tremaining: 1.01s\n",
      "875:\tlearn: 0.4811051\ttotal: 7.09s\tremaining: 1s\n",
      "876:\tlearn: 0.4807757\ttotal: 7.1s\tremaining: 995ms\n",
      "877:\tlearn: 0.4805653\ttotal: 7.1s\tremaining: 987ms\n",
      "878:\tlearn: 0.4804001\ttotal: 7.11s\tremaining: 979ms\n",
      "879:\tlearn: 0.4802534\ttotal: 7.12s\tremaining: 970ms\n",
      "880:\tlearn: 0.4800176\ttotal: 7.12s\tremaining: 962ms\n",
      "881:\tlearn: 0.4797540\ttotal: 7.13s\tremaining: 954ms\n",
      "882:\tlearn: 0.4795083\ttotal: 7.14s\tremaining: 947ms\n",
      "883:\tlearn: 0.4793240\ttotal: 7.16s\tremaining: 940ms\n",
      "884:\tlearn: 0.4791712\ttotal: 7.18s\tremaining: 933ms\n",
      "885:\tlearn: 0.4790330\ttotal: 7.19s\tremaining: 926ms\n",
      "886:\tlearn: 0.4786366\ttotal: 7.21s\tremaining: 919ms\n",
      "887:\tlearn: 0.4784247\ttotal: 7.23s\tremaining: 912ms\n",
      "888:\tlearn: 0.4782217\ttotal: 7.24s\tremaining: 904ms\n",
      "889:\tlearn: 0.4780714\ttotal: 7.26s\tremaining: 898ms\n",
      "890:\tlearn: 0.4779498\ttotal: 7.27s\tremaining: 890ms\n",
      "891:\tlearn: 0.4778360\ttotal: 7.28s\tremaining: 882ms\n",
      "892:\tlearn: 0.4776518\ttotal: 7.29s\tremaining: 873ms\n",
      "893:\tlearn: 0.4775321\ttotal: 7.3s\tremaining: 865ms\n",
      "894:\tlearn: 0.4770649\ttotal: 7.3s\tremaining: 857ms\n",
      "895:\tlearn: 0.4768643\ttotal: 7.31s\tremaining: 849ms\n",
      "896:\tlearn: 0.4765655\ttotal: 7.32s\tremaining: 840ms\n",
      "897:\tlearn: 0.4764113\ttotal: 7.32s\tremaining: 832ms\n",
      "898:\tlearn: 0.4762203\ttotal: 7.33s\tremaining: 824ms\n",
      "899:\tlearn: 0.4760911\ttotal: 7.34s\tremaining: 816ms\n",
      "900:\tlearn: 0.4759299\ttotal: 7.35s\tremaining: 807ms\n",
      "901:\tlearn: 0.4757287\ttotal: 7.35s\tremaining: 799ms\n",
      "902:\tlearn: 0.4755249\ttotal: 7.36s\tremaining: 791ms\n",
      "903:\tlearn: 0.4752075\ttotal: 7.37s\tremaining: 782ms\n",
      "904:\tlearn: 0.4750453\ttotal: 7.37s\tremaining: 774ms\n",
      "905:\tlearn: 0.4749349\ttotal: 7.38s\tremaining: 766ms\n",
      "906:\tlearn: 0.4747310\ttotal: 7.39s\tremaining: 758ms\n",
      "907:\tlearn: 0.4745569\ttotal: 7.39s\tremaining: 749ms\n",
      "908:\tlearn: 0.4743130\ttotal: 7.4s\tremaining: 741ms\n",
      "909:\tlearn: 0.4741800\ttotal: 7.41s\tremaining: 733ms\n",
      "910:\tlearn: 0.4739991\ttotal: 7.41s\tremaining: 724ms\n",
      "911:\tlearn: 0.4738056\ttotal: 7.42s\tremaining: 716ms\n",
      "912:\tlearn: 0.4736285\ttotal: 7.43s\tremaining: 708ms\n",
      "913:\tlearn: 0.4734986\ttotal: 7.43s\tremaining: 700ms\n",
      "914:\tlearn: 0.4731352\ttotal: 7.44s\tremaining: 691ms\n",
      "915:\tlearn: 0.4728031\ttotal: 7.45s\tremaining: 683ms\n",
      "916:\tlearn: 0.4725568\ttotal: 7.46s\tremaining: 675ms\n",
      "917:\tlearn: 0.4722128\ttotal: 7.46s\tremaining: 667ms\n",
      "918:\tlearn: 0.4721093\ttotal: 7.47s\tremaining: 658ms\n",
      "919:\tlearn: 0.4718184\ttotal: 7.48s\tremaining: 650ms\n",
      "920:\tlearn: 0.4716809\ttotal: 7.48s\tremaining: 642ms\n",
      "921:\tlearn: 0.4714834\ttotal: 7.49s\tremaining: 634ms\n",
      "922:\tlearn: 0.4711981\ttotal: 7.5s\tremaining: 626ms\n",
      "923:\tlearn: 0.4710495\ttotal: 7.51s\tremaining: 617ms\n",
      "924:\tlearn: 0.4708771\ttotal: 7.51s\tremaining: 609ms\n",
      "925:\tlearn: 0.4707450\ttotal: 7.52s\tremaining: 601ms\n",
      "926:\tlearn: 0.4704329\ttotal: 7.53s\tremaining: 593ms\n",
      "927:\tlearn: 0.4702507\ttotal: 7.54s\tremaining: 585ms\n",
      "928:\tlearn: 0.4700579\ttotal: 7.54s\tremaining: 577ms\n",
      "929:\tlearn: 0.4699469\ttotal: 7.55s\tremaining: 568ms\n",
      "930:\tlearn: 0.4698080\ttotal: 7.56s\tremaining: 560ms\n",
      "931:\tlearn: 0.4696119\ttotal: 7.56s\tremaining: 552ms\n",
      "932:\tlearn: 0.4692843\ttotal: 7.57s\tremaining: 544ms\n",
      "933:\tlearn: 0.4691180\ttotal: 7.58s\tremaining: 536ms\n",
      "934:\tlearn: 0.4690080\ttotal: 7.59s\tremaining: 527ms\n",
      "935:\tlearn: 0.4688034\ttotal: 7.59s\tremaining: 519ms\n",
      "936:\tlearn: 0.4686112\ttotal: 7.6s\tremaining: 511ms\n",
      "937:\tlearn: 0.4684679\ttotal: 7.61s\tremaining: 503ms\n",
      "938:\tlearn: 0.4682351\ttotal: 7.61s\tremaining: 495ms\n",
      "939:\tlearn: 0.4680574\ttotal: 7.62s\tremaining: 486ms\n",
      "940:\tlearn: 0.4678843\ttotal: 7.63s\tremaining: 478ms\n",
      "941:\tlearn: 0.4676806\ttotal: 7.63s\tremaining: 470ms\n",
      "942:\tlearn: 0.4674796\ttotal: 7.64s\tremaining: 462ms\n",
      "943:\tlearn: 0.4673136\ttotal: 7.65s\tremaining: 454ms\n",
      "944:\tlearn: 0.4671943\ttotal: 7.66s\tremaining: 446ms\n",
      "945:\tlearn: 0.4670874\ttotal: 7.66s\tremaining: 437ms\n",
      "946:\tlearn: 0.4668912\ttotal: 7.67s\tremaining: 429ms\n",
      "947:\tlearn: 0.4667013\ttotal: 7.67s\tremaining: 421ms\n",
      "948:\tlearn: 0.4661775\ttotal: 7.68s\tremaining: 413ms\n",
      "949:\tlearn: 0.4660183\ttotal: 7.69s\tremaining: 405ms\n",
      "950:\tlearn: 0.4658048\ttotal: 7.7s\tremaining: 397ms\n",
      "951:\tlearn: 0.4655972\ttotal: 7.7s\tremaining: 388ms\n",
      "952:\tlearn: 0.4654889\ttotal: 7.71s\tremaining: 380ms\n",
      "953:\tlearn: 0.4653982\ttotal: 7.71s\tremaining: 372ms\n",
      "954:\tlearn: 0.4651703\ttotal: 7.72s\tremaining: 364ms\n",
      "955:\tlearn: 0.4649710\ttotal: 7.73s\tremaining: 356ms\n",
      "956:\tlearn: 0.4648293\ttotal: 7.74s\tremaining: 348ms\n",
      "957:\tlearn: 0.4646332\ttotal: 7.74s\tremaining: 340ms\n",
      "958:\tlearn: 0.4644943\ttotal: 7.75s\tremaining: 331ms\n",
      "959:\tlearn: 0.4642973\ttotal: 7.76s\tremaining: 323ms\n",
      "960:\tlearn: 0.4641720\ttotal: 7.76s\tremaining: 315ms\n",
      "961:\tlearn: 0.4640046\ttotal: 7.77s\tremaining: 307ms\n",
      "962:\tlearn: 0.4637895\ttotal: 7.78s\tremaining: 299ms\n",
      "963:\tlearn: 0.4635246\ttotal: 7.79s\tremaining: 291ms\n",
      "964:\tlearn: 0.4632667\ttotal: 7.79s\tremaining: 283ms\n",
      "965:\tlearn: 0.4631013\ttotal: 7.8s\tremaining: 275ms\n",
      "966:\tlearn: 0.4628777\ttotal: 7.8s\tremaining: 266ms\n",
      "967:\tlearn: 0.4626341\ttotal: 7.81s\tremaining: 258ms\n",
      "968:\tlearn: 0.4624488\ttotal: 7.82s\tremaining: 250ms\n",
      "969:\tlearn: 0.4623746\ttotal: 7.83s\tremaining: 242ms\n",
      "970:\tlearn: 0.4621808\ttotal: 7.83s\tremaining: 234ms\n",
      "971:\tlearn: 0.4619371\ttotal: 7.84s\tremaining: 226ms\n",
      "972:\tlearn: 0.4617999\ttotal: 7.85s\tremaining: 218ms\n",
      "973:\tlearn: 0.4616667\ttotal: 7.85s\tremaining: 210ms\n",
      "974:\tlearn: 0.4615148\ttotal: 7.86s\tremaining: 202ms\n",
      "975:\tlearn: 0.4613310\ttotal: 7.87s\tremaining: 193ms\n",
      "976:\tlearn: 0.4609788\ttotal: 7.87s\tremaining: 185ms\n",
      "977:\tlearn: 0.4607272\ttotal: 7.88s\tremaining: 177ms\n",
      "978:\tlearn: 0.4606527\ttotal: 7.89s\tremaining: 169ms\n",
      "979:\tlearn: 0.4604693\ttotal: 7.89s\tremaining: 161ms\n",
      "980:\tlearn: 0.4603323\ttotal: 7.9s\tremaining: 153ms\n",
      "981:\tlearn: 0.4600790\ttotal: 7.91s\tremaining: 145ms\n",
      "982:\tlearn: 0.4598829\ttotal: 7.91s\tremaining: 137ms\n",
      "983:\tlearn: 0.4597732\ttotal: 7.92s\tremaining: 129ms\n",
      "984:\tlearn: 0.4595433\ttotal: 7.93s\tremaining: 121ms\n",
      "985:\tlearn: 0.4593825\ttotal: 7.94s\tremaining: 113ms\n",
      "986:\tlearn: 0.4590828\ttotal: 7.94s\tremaining: 105ms\n",
      "987:\tlearn: 0.4589074\ttotal: 7.95s\tremaining: 96.6ms\n",
      "988:\tlearn: 0.4586896\ttotal: 7.96s\tremaining: 88.5ms\n",
      "989:\tlearn: 0.4584942\ttotal: 7.96s\tremaining: 80.5ms\n",
      "990:\tlearn: 0.4583512\ttotal: 7.97s\tremaining: 72.4ms\n",
      "991:\tlearn: 0.4581735\ttotal: 7.98s\tremaining: 64.3ms\n",
      "992:\tlearn: 0.4579709\ttotal: 7.99s\tremaining: 56.3ms\n",
      "993:\tlearn: 0.4578471\ttotal: 8s\tremaining: 48.3ms\n",
      "994:\tlearn: 0.4577361\ttotal: 8.01s\tremaining: 40.2ms\n",
      "995:\tlearn: 0.4576336\ttotal: 8.01s\tremaining: 32.2ms\n",
      "996:\tlearn: 0.4574990\ttotal: 8.02s\tremaining: 24.1ms\n",
      "997:\tlearn: 0.4573553\ttotal: 8.03s\tremaining: 16.1ms\n",
      "998:\tlearn: 0.4572155\ttotal: 8.03s\tremaining: 8.04ms\n",
      "999:\tlearn: 0.4570688\ttotal: 8.04s\tremaining: 0us\n",
      "Accuracy: 0.737960810362006\n"
     ]
    }
   ],
   "source": [
    "# applying Catboost\n",
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, loss_function='MultiClass')\n",
    "\n",
    "# predictions\n",
    "cat.fit(X_train, y_train)\n",
    "predictions_cat = cat.predict(X_test)\n",
    "\n",
    "# accuracy_score\n",
    "acc_cat = metrics.accuracy_score(y_test, predictions_cat)\n",
    "print(f\"Accuracy: {acc_cat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71       694\n",
      "           1       0.60      0.57      0.58       627\n",
      "           2       0.58      0.62      0.60       557\n",
      "           3       0.60      0.67      0.64       539\n",
      "           4       0.77      0.76      0.76       594\n",
      "\n",
      "    accuracy                           0.66      3011\n",
      "   macro avg       0.66      0.66      0.66      3011\n",
      "weighted avg       0.66      0.66      0.66      3011\n",
      "\n",
      "Accuracy: 0.6592494187977416\n"
     ]
    }
   ],
   "source": [
    "# applying KNN classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predictions \n",
    "predictions_knn = knn.predict(X_test)\n",
    "print(classification_report(predictions_knn, y_test))\n",
    "\n",
    "# print accuracy score\n",
    "acc_knn = metrics.accuracy_score(y_test, predictions_knn)\n",
    "print(f\"Accuracy: {acc_knn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       605\n",
      "           1       0.63      0.61      0.62       614\n",
      "           2       0.62      0.60      0.61       620\n",
      "           3       0.65      0.67      0.66       587\n",
      "           4       0.81      0.82      0.81       585\n",
      "\n",
      "    accuracy                           0.69      3011\n",
      "   macro avg       0.69      0.69      0.69      3011\n",
      "weighted avg       0.69      0.69      0.69      3011\n",
      "\n",
      "Accuracy: 0.6884755895051478\n"
     ]
    }
   ],
   "source": [
    "# applying decision trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "predictions_dt = dt.predict(X_test)\n",
    "print(classification_report(predictions_dt, y_test))\n",
    "\n",
    "# print accuracy score\n",
    "acc_dt = metrics.accuracy_score(y_test, predictions_dt)\n",
    "print(f\"Accuracy: {acc_dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier with Linear\n",
    "the worst results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.70      0.56       429\n",
      "           1       0.37      0.46      0.41       473\n",
      "           2       0.26      0.35      0.30       440\n",
      "           3       0.67      0.35      0.46      1138\n",
      "           4       0.51      0.57      0.54       531\n",
      "\n",
      "    accuracy                           0.46      3011\n",
      "   macro avg       0.46      0.49      0.45      3011\n",
      "weighted avg       0.50      0.46      0.46      3011\n",
      "\n",
      "Accuracy: 0.4559946861507805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# appling linear SVM Classifier\n",
    "from sklearn import svm\n",
    "\n",
    "svm_clf = svm.LinearSVC(multi_class='ovr', max_iter = 1000)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "predictions_svmClf = svm_clf.predict(X_test)\n",
    "print(classification_report(predictions_svmClf, y_test))\n",
    "\n",
    "# print accuracy score\n",
    "acc_svmClf = metrics.accuracy_score(y_test, predictions_svmClf)\n",
    "print(f\"Accuracy: {acc_svmClf}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74       564\n",
      "           1       0.66      0.58      0.61       673\n",
      "           2       0.60      0.63      0.62       567\n",
      "           3       0.65      0.70      0.68       554\n",
      "           4       0.83      0.75      0.79       653\n",
      "\n",
      "    accuracy                           0.69      3011\n",
      "   macro avg       0.69      0.69      0.69      3011\n",
      "weighted avg       0.69      0.69      0.69      3011\n",
      "\n",
      "Accuracy: 0.6878113583527068\n"
     ]
    }
   ],
   "source": [
    "# applying a RBF Kernel\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "rbf_svc = SVC(kernel='rbf', random_state = 0, gamma=0.1, C = 1)\n",
    "rbf_svc.fit(X_train, y_train)  \n",
    "\n",
    "# predictions\n",
    "predictions_rbf = rbf_svc.predict(X_test)\n",
    "print(classification_report(predictions_rbf, y_test))\n",
    "\n",
    "# print accuracy score\n",
    "acc_rbf = metrics.accuracy_score(y_test, predictions_rbf)   \n",
    "print(f\"Accuracy: {acc_rbf}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gaussian naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.31      0.46      1784\n",
      "           1       0.14      0.36      0.20       224\n",
      "           2       0.10      0.30      0.15       192\n",
      "           3       0.03      0.42      0.05        38\n",
      "           4       0.65      0.50      0.56       773\n",
      "\n",
      "    accuracy                           0.36      3011\n",
      "   macro avg       0.35      0.38      0.28      3011\n",
      "weighted avg       0.70      0.36      0.44      3011\n",
      "\n",
      "Accuracy: 0.36067751577548984\n"
     ]
    }
   ],
   "source": [
    "# applying Gaussian NB classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# print classification report\n",
    "predictions_gnb = gnb.predict(X_test)\n",
    "print(classification_report(predictions_gnb, y_test))\n",
    "\n",
    "# print accuracy score\n",
    "acc_gnb = metrics.accuracy_score(y_test, predictions_gnb)\n",
    "print(f\"Accuracy: {acc_gnb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.91%\n",
      "Confusion Matrix:\n",
      "[[  0   0   0   0   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   2   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0   0   0   0   0]\n",
      " [  0   1   1  25  15   4   1   0   0   0   0   0]\n",
      " [  0   1   0  50 507  99  24  11   4   5   0   0]\n",
      " [  1   1   2  25 148 470 111  34  25   4   1   0]\n",
      " [  0   0   0   5  30  95 513 141  58   5   2   0]\n",
      " [  0   0   0   1   4   8  63 237  79  10   0   0]\n",
      " [  0   0   0   1   4   4   4  29  79   8   0   0]\n",
      " [  0   0   0   0   0   0   0   5  12  32   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.23      0.53      0.32        47\n",
      "           5       0.71      0.72      0.72       701\n",
      "           6       0.69      0.57      0.62       822\n",
      "           7       0.72      0.60      0.66       849\n",
      "           8       0.52      0.59      0.55       402\n",
      "           9       0.30      0.61      0.41       129\n",
      "          10       0.50      0.65      0.57        49\n",
      "          11       0.25      0.33      0.29         3\n",
      "          12       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      3011\n",
      "   macro avg       0.33      0.38      0.34      3011\n",
      "weighted avg       0.65      0.62      0.63      3011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# trying XGBM model\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label encoding the target variable\n",
    "label_encoder = LabelEncoder().fit(y_train_resampled)  # Fit on y_train to learn all classes\n",
    "y_train_encoded = label_encoder.transform(y_train_resampled)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Dynamically set the number of classes\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "\n",
    "\n",
    "# Specify the parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # Specify multi-class classification\n",
    "    'num_class': num_classes,  # Dynamically set the number of classes\n",
    "    'max_depth': 4,  # Depth of the trees\n",
    "    'learning_rate': 0.1,  # Learning rate\n",
    "    'n_estimators': 100,  # Number of trees\n",
    "    'seed': 42  # Random seed for reproducibility\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "# Train the model with encoded targets\n",
    "clf.fit(X_train_resampled, y_train_encoded)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# getting unique classes for predicted labels\n",
    "unique_y_test = np.unique(y_test_encoded)\n",
    "unique_y_pred = np.unique(y_pred)\n",
    "\n",
    "# get unique classes \n",
    "all_unique_classes = np.unique(np.concatenate((y_test_encoded, y_pred)))\n",
    "\n",
    "# map the unique encoded classes back to original names\n",
    "target_names_adjusted = label_encoder.inverse_transform(all_unique_classes)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_encoded, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "using entity embeddings to train the neural network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting up the model\n",
    "creating entity embeddings <br>\n",
    "`cat_col1` = `PROVINCE` <br>\n",
    "`cat_col2` = `CHICKEN SIZE` <br>\n",
    "`cat_col3` = `SIZE` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset `df`\n",
    "\n",
    "# importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Reshape, Concatenate, Dense, Flatten\n",
    "\n",
    "# getting the unique values of the categorical columns\n",
    "cat_columns = ['PROVINCE', 'CHICKEN SIZE', 'UNIT']\n",
    "unique_cat1 = df['PROVINCE'].nunique()\n",
    "unique_cat2 = df['CHICKEN SIZE'].nunique()\n",
    "unique_cat3 = df['UNIT'].nunique()\n",
    "\n",
    "# getting numerical columns\n",
    "num_columns = df.columns.difference(cat_columns)\n",
    "numerical_data = df[num_columns]\n",
    "\n",
    "# scaling the numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
    "\n",
    "# defining the input layer\n",
    "num_input = Input(shape=(numerical_data_scaled.shape[1],), name='num_input')\n",
    "\n",
    "# embedding the categorical columns\n",
    "cat_input1 = Input(shape = (1,), name='cat_input1')\n",
    "cat_embed1 = Embedding(input_dim=unique_cat1, output_dim = int(min(np.ceil(unique_cat1 /2), 50)))(cat_input1)\n",
    "cat_embed1 = Flatten()(cat_embed1)\n",
    "\n",
    "cat_input2 = Input(shape = (1,), name='cat_input2')\n",
    "cat_embed2 = Embedding(input_dim=unique_cat2, output_dim = int(min(np.ceil(unique_cat2 /2), 50)))(cat_input2)\n",
    "cat_embed2 = Flatten()(cat_embed2)\n",
    "\n",
    "\n",
    "cat_input3 = Input(shape = (1,), name='cat_input3')\n",
    "cat_embed3 = Embedding(input_dim=unique_cat3, output_dim = int(min(np.ceil(unique_cat3 /2), 50)))(cat_input3)\n",
    "cat_embed3 = Flatten()(cat_embed3)\n",
    "\n",
    "\n",
    "# concatenate the embeddings with numerical input\n",
    "concatenated = Concatenate()([cat_embed1, cat_embed2, cat_embed3, num_input])\n",
    "\n",
    "\n",
    "# adding the dense layer ontop of the embeddings\n",
    "dense_output = Dense(128, activation = 'relu')(concatenated)\n",
    "dense_output = Dense(64, activation = 'relu')(dense_output)\n",
    "output = Dense(1)(dense_output)\n",
    "\n",
    "# creating the model\n",
    "model = Model(inputs = [cat_input1, cat_input2, cat_input3, num_input], outputs = output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "X_train_cat1 = X_train['PROVINCE']\n",
    "X_train_cat2 = X_train['CHICKEN SIZE']\n",
    "X_train_cat3 = X_train['UNIT']\n",
    "X_train_num = X_train.drop(['PROVINCE', 'CHICKEN SIZE', 'UNIT'], axis = 1)\n",
    "\n",
    "# fitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Single output node for regression\n",
    "])\n",
    "\n",
    "# Compile the model, specifying the optimizer, loss function, and metric\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Fit the model on the training data\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, epochs=100, verbose=1)\n",
    "\n",
    "# Predict the target on the testing set\n",
    "predictions = model.predict(X_test).flatten()\n",
    "\n",
    "# Evaluate the model performance using RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# You can plot the training history to check how the loss and metric evolved over epochs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
