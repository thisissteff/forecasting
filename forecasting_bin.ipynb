{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forecasting selling price of chicken with Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.6.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from category_encoders) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (1.12.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from category_encoders) (0.14.1)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from category_encoders) (0.5.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2023.4)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (3.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.10/site-packages (from statsmodels>=0.9.0->category_encoders) (23.2)\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "!pip install category_encoders\n",
    "import category_encoders as ce\n",
    "from category_encoders import TargetEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY_DATE</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>SALES PER KG</th>\n",
       "      <th>TOTAL SALES</th>\n",
       "      <th>ABW</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>LOMBOK</td>\n",
       "      <td>6237</td>\n",
       "      <td>11356.50</td>\n",
       "      <td>22000.00</td>\n",
       "      <td>249843000</td>\n",
       "      <td>1.82</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>NUSA TENGGARA BARAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>GARUT</td>\n",
       "      <td>2625</td>\n",
       "      <td>5446.80</td>\n",
       "      <td>17000.00</td>\n",
       "      <td>92595600</td>\n",
       "      <td>2.07</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>SUMEDANG</td>\n",
       "      <td>7788</td>\n",
       "      <td>14176.80</td>\n",
       "      <td>16106.05</td>\n",
       "      <td>228332300</td>\n",
       "      <td>1.82</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>CIREBON</td>\n",
       "      <td>7504</td>\n",
       "      <td>15958.00</td>\n",
       "      <td>17000.00</td>\n",
       "      <td>271286000</td>\n",
       "      <td>2.13</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>PEKALONGAN</td>\n",
       "      <td>9121</td>\n",
       "      <td>16250.00</td>\n",
       "      <td>16500.00</td>\n",
       "      <td>268125000</td>\n",
       "      <td>1.78</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DAY_DATE        UNIT  TAILS       KG  SALES PER KG  TOTAL SALES  ABW  \\\n",
       "0  2017-01-01      LOMBOK   6237 11356.50      22000.00    249843000 1.82   \n",
       "1  2017-01-01       GARUT   2625  5446.80      17000.00     92595600 2.07   \n",
       "2  2017-01-01    SUMEDANG   7788 14176.80      16106.05    228332300 1.82   \n",
       "3  2017-01-01     CIREBON   7504 15958.00      17000.00    271286000 2.13   \n",
       "4  2017-01-01  PEKALONGAN   9121 16250.00      16500.00    268125000 1.78   \n",
       "\n",
       "  CHICKEN SIZE             PROVINCE  \n",
       "0       MEDIUM  NUSA TENGGARA BARAT  \n",
       "1        LARGE           JAWA BARAT  \n",
       "2       MEDIUM           JAWA BARAT  \n",
       "3        LARGE           JAWA BARAT  \n",
       "4       MEDIUM          JAWA TENGAH  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading file\n",
    "df = pd.read_csv('/workspaces/forecasting/data/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NUSA TENGGARA BARAT', 'JAWA BARAT', 'JAWA TENGAH', 'JAWA TIMUR',\n",
       "       'SUMATERA UTARA', 'SUMATERA BARAT', 'JAMBI', 'BENGKULU',\n",
       "       'SULAWESI SELATAN', 'KALIMANTAN SELATAN', 'DI YOGYAKARTA',\n",
       "       'KALIMANTAN TIMUR', 'LAMPUNG', 'RIAU', 'BANTEN', 'BALI',\n",
       "       'SULAWESI UTARA', 'SUMATERA SELATAN', 'SULAWESI BARAT',\n",
       "       'SULAWESI TENGAH', 'KALIMANTAN BARAT', 'SULAWESI TENGGARA',\n",
       "       'GORONTALO', 'ACEH', 'KALIMANTAN TENGAH'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the value name such that it matches the values in the supply and demand dataset\n",
    "# finding for any nan values\n",
    "df.isna().sum()\n",
    "# pring out the rows with nan values\n",
    "df[df.isna().any(axis=1)]\n",
    "\n",
    "# change value name of the province column\n",
    "df['PROVINCE'] = df['PROVINCE'].replace('DIY YOGYAKARTA', 'DI YOGYAKARTA')\n",
    "# print out the unique values of the province column\n",
    "df['PROVINCE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "     DAY_DATE        UNIT  TAILS       KG  SALES PER KG  ABW CHICKEN SIZE  \\\n",
      "0  2017-01-01      LOMBOK   6237 11356.50      22000.00 1.82       MEDIUM   \n",
      "1  2017-01-01       GARUT   2625  5446.80      17000.00 2.07        LARGE   \n",
      "2  2017-01-01    SUMEDANG   7788 14176.80      16106.05 1.82       MEDIUM   \n",
      "3  2017-01-01     CIREBON   7504 15958.00      17000.00 2.13        LARGE   \n",
      "4  2017-01-01  PEKALONGAN   9121 16250.00      16500.00 1.78       MEDIUM   \n",
      "\n",
      "              PROVINCE  price_bin  \n",
      "0  NUSA TENGGARA BARAT         13  \n",
      "1           JAWA BARAT         10  \n",
      "2           JAWA BARAT         10  \n",
      "3           JAWA BARAT         10  \n",
      "4          JAWA TENGAH         10  \n"
     ]
    }
   ],
   "source": [
    "# removing outlier\n",
    "df = df[df['SALES PER KG'] <= 35000]\n",
    "\n",
    "# removing 'total sales' column\n",
    "df = df.drop('TOTAL SALES', axis = 1)\n",
    "\n",
    "# creating bins for prediction\n",
    "\n",
    "# using sturges to print out the number of bins\n",
    "sturges = int(np.ceil(1 + np.log2(len(df['SALES PER KG']))))\n",
    "print(sturges)\n",
    "\n",
    "max_value = 35000\n",
    "bin_width = int((max_value - 0) // sturges)\n",
    "\n",
    "# Correctly calculate 'bin_edges'\n",
    "# Ensure 'bin_width' is added to 'max_value' to include the upper edge\n",
    "bin_edges = np.arange(0, max_value + bin_width, bin_width)\n",
    "\n",
    "# Use pd.cut to bin the data\n",
    "df['price_bin'] = pd.cut(df['SALES PER KG'], bins=bin_edges, labels=False, right=False)\n",
    "\n",
    "# Add 1 to change bins from 0-19 to 1-20\n",
    "df['price_bin'] += 1\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df.head())\n",
    "\n",
    "# dropping sales per kg column as we already have price_bin\n",
    "df = df.drop('SALES PER KG', axis = 1)\n",
    "\n",
    "# dropping ABW \n",
    "df = df.drop('ABW', axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre processing\n",
    "- extracting date column\n",
    "- splitting, scaling\n",
    "- creating function to evaluate the model [call `results(y_test, predictions)`]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting year and month from date column for seasonality trends\n",
    "df['DAY_DATE'] = pd.to_datetime(df['DAY_DATE'], errors='coerce').dt.normalize()\n",
    "df['YEAR'] = df['DAY_DATE'].dt.year\n",
    "df['MONTH'] = df['DAY_DATE'].dt.month\n",
    "df['DAY'] = df['DAY_DATE'].dt.day\n",
    "df = df.drop('DAY_DATE', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>price_bin</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOMBOK</td>\n",
       "      <td>6237</td>\n",
       "      <td>11356.50</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>NUSA TENGGARA BARAT</td>\n",
       "      <td>13</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GARUT</td>\n",
       "      <td>2625</td>\n",
       "      <td>5446.80</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUMEDANG</td>\n",
       "      <td>7788</td>\n",
       "      <td>14176.80</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CIREBON</td>\n",
       "      <td>7504</td>\n",
       "      <td>15958.00</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PEKALONGAN</td>\n",
       "      <td>9121</td>\n",
       "      <td>16250.00</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382897</th>\n",
       "      <td>SRAGEN</td>\n",
       "      <td>510</td>\n",
       "      <td>618.40</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382898</th>\n",
       "      <td>SLEMAN</td>\n",
       "      <td>48</td>\n",
       "      <td>63.20</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>DI YOGYAKARTA</td>\n",
       "      <td>7</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382899</th>\n",
       "      <td>SRAGEN</td>\n",
       "      <td>315</td>\n",
       "      <td>415.60</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382900</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>785</td>\n",
       "      <td>974.80</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382901</th>\n",
       "      <td>SRAGEN</td>\n",
       "      <td>750</td>\n",
       "      <td>1073.60</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382901 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              UNIT  TAILS       KG CHICKEN SIZE             PROVINCE  \\\n",
       "0           LOMBOK   6237 11356.50       MEDIUM  NUSA TENGGARA BARAT   \n",
       "1            GARUT   2625  5446.80        LARGE           JAWA BARAT   \n",
       "2         SUMEDANG   7788 14176.80       MEDIUM           JAWA BARAT   \n",
       "3          CIREBON   7504 15958.00        LARGE           JAWA BARAT   \n",
       "4       PEKALONGAN   9121 16250.00       MEDIUM          JAWA TENGAH   \n",
       "...            ...    ...      ...          ...                  ...   \n",
       "382897      SRAGEN    510   618.40        SMALL          JAWA TENGAH   \n",
       "382898      SLEMAN     48    63.20        SMALL        DI YOGYAKARTA   \n",
       "382899      SRAGEN    315   415.60        SMALL          JAWA TENGAH   \n",
       "382900    BOYOLALI    785   974.80        SMALL          JAWA TENGAH   \n",
       "382901      SRAGEN    750  1073.60        SMALL          JAWA TENGAH   \n",
       "\n",
       "        price_bin  YEAR  MONTH  DAY  \n",
       "0              13  2017      1    1  \n",
       "1              10  2017      1    1  \n",
       "2              10  2017      1    1  \n",
       "3              10  2017      1    1  \n",
       "4              10  2017      1    1  \n",
       "...           ...   ...    ...  ...  \n",
       "382897         10  2024      1   27  \n",
       "382898          7  2024      1   28  \n",
       "382899         10  2024      1   28  \n",
       "382900         10  2024      1   28  \n",
       "382901         10  2024      1   29  \n",
       "\n",
       "[382901 rows x 9 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demand and supply\n",
    "importing the demand and supply dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for rows for year 2019 to 2023\n",
    "df = df[(df['YEAR'] >= 2019) & (df['YEAR'] <= 2023)]\n",
    "\n",
    "# removine rows that are earlier than december 2019\n",
    "df = df[(df['YEAR'] >= 2019) & (df['MONTH'] >= 12)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>price_bin</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165114</th>\n",
       "      <td>PAYAKUMBUH</td>\n",
       "      <td>1267</td>\n",
       "      <td>2856.00</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165115</th>\n",
       "      <td>SINJAI</td>\n",
       "      <td>3310</td>\n",
       "      <td>7799.50</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>13</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165116</th>\n",
       "      <td>BANDAR JAYA</td>\n",
       "      <td>8236</td>\n",
       "      <td>22197.00</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165117</th>\n",
       "      <td>BANDAR LAMPUNG</td>\n",
       "      <td>2565</td>\n",
       "      <td>4971.00</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165118</th>\n",
       "      <td>BANYUASIN</td>\n",
       "      <td>696</td>\n",
       "      <td>1464.40</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382498</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>430</td>\n",
       "      <td>901.40</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382499</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>294</td>\n",
       "      <td>605.00</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382500</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>432</td>\n",
       "      <td>962.40</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382501</th>\n",
       "      <td>GUNUNGKIDUL</td>\n",
       "      <td>200</td>\n",
       "      <td>370.80</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>DI YOGYAKARTA</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382502</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>400</td>\n",
       "      <td>865.80</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17771 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  UNIT  TAILS       KG CHICKEN SIZE          PROVINCE  \\\n",
       "165114      PAYAKUMBUH   1267  2856.00        LARGE    SUMATERA BARAT   \n",
       "165115          SINJAI   3310  7799.50        LARGE  SULAWESI SELATAN   \n",
       "165116     BANDAR JAYA   8236 22197.00        LARGE           LAMPUNG   \n",
       "165117  BANDAR LAMPUNG   2565  4971.00       MEDIUM           LAMPUNG   \n",
       "165118       BANYUASIN    696  1464.40        LARGE  SUMATERA SELATAN   \n",
       "...                ...    ...      ...          ...               ...   \n",
       "382498        BOYOLALI    430   901.40          BIG       JAWA TENGAH   \n",
       "382499        BOYOLALI    294   605.00          BIG       JAWA TENGAH   \n",
       "382500        BOYOLALI    432   962.40          BIG       JAWA TENGAH   \n",
       "382501     GUNUNGKIDUL    200   370.80       MEDIUM     DI YOGYAKARTA   \n",
       "382502        BOYOLALI    400   865.80          BIG       JAWA TENGAH   \n",
       "\n",
       "        price_bin  YEAR  MONTH  DAY  \n",
       "165114         11  2019     12    1  \n",
       "165115         13  2019     12    1  \n",
       "165116         10  2019     12    1  \n",
       "165117         11  2019     12    1  \n",
       "165118         10  2019     12    1  \n",
       "...           ...   ...    ...  ...  \n",
       "382498         10  2023     12   31  \n",
       "382499         10  2023     12   31  \n",
       "382500         10  2023     12   31  \n",
       "382501         10  2023     12   31  \n",
       "382502         10  2023     12   31  \n",
       "\n",
       "[17771 rows x 9 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACEH</td>\n",
       "      <td>2687246</td>\n",
       "      <td>3930723</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BALI</td>\n",
       "      <td>5120529</td>\n",
       "      <td>5141045</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANTEN</td>\n",
       "      <td>16349469</td>\n",
       "      <td>13433846</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BENGKULU</td>\n",
       "      <td>554903</td>\n",
       "      <td>1339242</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DI YOGYAKARTA</td>\n",
       "      <td>4206148</td>\n",
       "      <td>6313628</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>SULAWESI TENGGARA</td>\n",
       "      <td>104238</td>\n",
       "      <td>705272</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>SULAWESI UTARA</td>\n",
       "      <td>396941</td>\n",
       "      <td>1307670</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>3689089</td>\n",
       "      <td>4922821</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>5467836</td>\n",
       "      <td>5767260</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>SUMATERA UTARA</td>\n",
       "      <td>9840988</td>\n",
       "      <td>9231167</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               PROVINCE  SupplyProvince  DemandProvince  MONTH  YEAR\n",
       "0                  ACEH         2687246         3930723     12  2019\n",
       "1                  BALI         5120529         5141045     12  2019\n",
       "2                BANTEN        16349469        13433846     12  2019\n",
       "3              BENGKULU          554903         1339242     12  2019\n",
       "4         DI YOGYAKARTA         4206148         6313628     12  2019\n",
       "...                 ...             ...             ...    ...   ...\n",
       "1723  SULAWESI TENGGARA          104238          705272     12  2023\n",
       "1724     SULAWESI UTARA          396941         1307670     12  2023\n",
       "1725     SUMATERA BARAT         3689089         4922821     12  2023\n",
       "1726   SUMATERA SELATAN         5467836         5767260     12  2023\n",
       "1727     SUMATERA UTARA         9840988         9231167     12  2023\n",
       "\n",
       "[1728 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing demand and supply dataset\n",
    "df_demand_supply = pd.read_csv('/workspaces/forecasting/data/provinceDD&SS.csv')\n",
    "df_demand_supply\n",
    "\n",
    "# splitting the month_year column into separate month and year columns\n",
    "df_demand_supply[['MONTH', 'YEAR']] = df_demand_supply['Month_Year'].str.split(' ', expand = True)\n",
    "\n",
    "# mapping month to numerical values\n",
    "month_num = {\n",
    "    'Jan' : 1, 'Feb' : 2, 'Mar' : 3, 'Apr' : 4, 'May' : 5, 'Jun' : 6, 'Jul' : 7, \n",
    "    'Aug' : 8, 'Sep' : 9, 'Oct' : 10, 'Nov' : 11, 'Dec' : 12\n",
    "}\n",
    "\n",
    "# replacing month with numerical values\n",
    "df_demand_supply['MONTH'] = df_demand_supply['MONTH'].replace(month_num)\n",
    "df_demand_supply['YEAR'] = df_demand_supply['YEAR'].astype(int)\n",
    "\n",
    "# dropping original month_year column\n",
    "df_demand_supply.drop('Month_Year', axis = 1, inplace = True)\n",
    "df_demand_supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>price_bin</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYAKUMBUH</td>\n",
       "      <td>1267</td>\n",
       "      <td>2856.00</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3885216</td>\n",
       "      <td>5993194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINJAI</td>\n",
       "      <td>3310</td>\n",
       "      <td>7799.50</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>13</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5447863</td>\n",
       "      <td>5931514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANDAR JAYA</td>\n",
       "      <td>8236</td>\n",
       "      <td>22197.00</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANDAR LAMPUNG</td>\n",
       "      <td>2565</td>\n",
       "      <td>4971.00</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANYUASIN</td>\n",
       "      <td>696</td>\n",
       "      <td>1464.40</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5758528</td>\n",
       "      <td>7021239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15050</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>430</td>\n",
       "      <td>901.40</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15051</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>294</td>\n",
       "      <td>605.00</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15052</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>432</td>\n",
       "      <td>962.40</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15053</th>\n",
       "      <td>GUNUNGKIDUL</td>\n",
       "      <td>200</td>\n",
       "      <td>370.80</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>DI YOGYAKARTA</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3993820</td>\n",
       "      <td>5186026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15054</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>400</td>\n",
       "      <td>865.80</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15055 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 UNIT  TAILS       KG CHICKEN SIZE          PROVINCE  \\\n",
       "0          PAYAKUMBUH   1267  2856.00        LARGE    SUMATERA BARAT   \n",
       "1              SINJAI   3310  7799.50        LARGE  SULAWESI SELATAN   \n",
       "2         BANDAR JAYA   8236 22197.00        LARGE           LAMPUNG   \n",
       "3      BANDAR LAMPUNG   2565  4971.00       MEDIUM           LAMPUNG   \n",
       "4           BANYUASIN    696  1464.40        LARGE  SUMATERA SELATAN   \n",
       "...               ...    ...      ...          ...               ...   \n",
       "15050        BOYOLALI    430   901.40          BIG       JAWA TENGAH   \n",
       "15051        BOYOLALI    294   605.00          BIG       JAWA TENGAH   \n",
       "15052        BOYOLALI    432   962.40          BIG       JAWA TENGAH   \n",
       "15053     GUNUNGKIDUL    200   370.80       MEDIUM     DI YOGYAKARTA   \n",
       "15054        BOYOLALI    400   865.80          BIG       JAWA TENGAH   \n",
       "\n",
       "       price_bin  YEAR  MONTH  DAY  SupplyProvince  DemandProvince  \n",
       "0             11  2019     12    1         3885216         5993194  \n",
       "1             13  2019     12    1         5447863         5931514  \n",
       "2             10  2019     12    1         5404511         5618463  \n",
       "3             11  2019     12    1         5404511         5618463  \n",
       "4             10  2019     12    1         5758528         7021239  \n",
       "...          ...   ...    ...  ...             ...             ...  \n",
       "15050         10  2023     12   31        54958385        26285612  \n",
       "15051         10  2023     12   31        54958385        26285612  \n",
       "15052         10  2023     12   31        54958385        26285612  \n",
       "15053         10  2023     12   31         3993820         5186026  \n",
       "15054         10  2023     12   31        54958385        26285612  \n",
       "\n",
       "[15055 rows x 11 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging the demand and supply dataset with the main dataset\n",
    "df = pd.merge(df, df_demand_supply, how = 'inner', on = ['YEAR', 'MONTH', 'PROVINCE'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIT              0\n",
      "TAILS             0\n",
      "KG                0\n",
      "CHICKEN SIZE      0\n",
      "PROVINCE          0\n",
      "YEAR              0\n",
      "MONTH             0\n",
      "DAY               0\n",
      "SupplyProvince    0\n",
      "DemandProvince    0\n",
      "dtype: int64\n",
      "UNIT              0\n",
      "TAILS             0\n",
      "KG                0\n",
      "CHICKEN SIZE      0\n",
      "PROVINCE          0\n",
      "YEAR              0\n",
      "MONTH             0\n",
      "DAY               0\n",
      "SupplyProvince    0\n",
      "DemandProvince    0\n",
      "dtype: int64\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# train test split before label encoding to prevent data leakage\n",
    "\n",
    "\n",
    "X = df.drop('price_bin', axis=1)\n",
    "y = df['price_bin']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# checking for any nan values after splitting\n",
    "print(X_train.isna().sum())\n",
    "print(X_test.isna().sum())\n",
    "print(y_train.isna().sum())\n",
    "print(y_test.isna().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UNIT, TAILS, KG, CHICKEN SIZE, PROVINCE, YEAR, MONTH, DAY, SupplyProvince, DemandProvince]\n",
       "Index: []"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out the nan rows in the x_train dataset\n",
    "X_train[X_train.isna().any(axis=1)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling numerical variable\n",
    "\n",
    "scaler = StandardScaler()\n",
    "columns_to_scale = ['KG', 'TAILS']\n",
    "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to evaluate the model\n",
    "def results(y_test, predictions):\n",
    "  mae = mean_absolute_error(y_test, predictions)\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "  rmse = np.sqrt(mse)\n",
    "  r2 = r2_score(y_test, predictions)\n",
    "\n",
    "  print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "  print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "  print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "  print(f\"R-squared (R²): {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding of columns\n",
    "# label encoding for province\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "X_train['SIZE ENCODE'] = label_encoder.fit_transform(X_train['CHICKEN SIZE'])\n",
    "X_test['SIZE ENCODE'] = label_encoder.transform(X_test['CHICKEN SIZE'])\n",
    "\n",
    "# dropping chicken size column\n",
    "X_train = X_train.drop(['CHICKEN SIZE'], axis = 1)\n",
    "X_test = X_test.drop(['CHICKEN SIZE'], axis = 1)\n",
    "\n",
    "\n",
    "# one hot encoding for province\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X_train[['PROVINCE']])\n",
    "X_train_encoded = encoder.transform(X_train[['PROVINCE']])\n",
    "X_test_encoded = encoder.transform(X_test[['PROVINCE']])\n",
    "\n",
    "# Convert the encoded matrices back to dataframes for easier manipulation\n",
    "columns = encoder.get_feature_names_out(['PROVINCE'])\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded.toarray(), columns=columns, index=X_train.index)\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded.toarray(), columns=columns, index=X_test.index)\n",
    "\n",
    "# merge back the dataframe\n",
    "X_train = pd.concat([X_train.drop('PROVINCE', axis=1), X_train_encoded_df], axis=1)\n",
    "X_test = pd.concat([X_test.drop('PROVINCE', axis=1), X_test_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# one hot encoding for unit\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X_train[['UNIT']])\n",
    "X_train_encoded_unit = encoder.transform(X_train[['UNIT']])\n",
    "X_test_encoded_unit = encoder.transform(X_test[['UNIT']])\n",
    "\n",
    "# Convert the encoded matrices back to dataframes for easier manipulation\n",
    "columns = encoder.get_feature_names_out(['UNIT'])\n",
    "X_train_encoded_df_unit = pd.DataFrame(X_train_encoded_unit.toarray(), columns=columns, index=X_train.index)\n",
    "X_test_encoded_df_unit = pd.DataFrame(X_test_encoded_unit.toarray(), columns=columns, index=X_test.index)\n",
    "\n",
    "# merge back the dataframe, dropping unit column\n",
    "X_train = pd.concat([X_train.drop('UNIT', axis=1), X_train_encoded_df_unit], axis=1)\n",
    "X_test = pd.concat([X_test.drop('UNIT', axis=1), X_test_encoded_df_unit], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "      <th>SIZE ENCODE</th>\n",
       "      <th>PROVINCE_ACEH</th>\n",
       "      <th>PROVINCE_BALI</th>\n",
       "      <th>...</th>\n",
       "      <th>UNIT_TANJUNG BINTANG</th>\n",
       "      <th>UNIT_TASIKMALAYA</th>\n",
       "      <th>UNIT_TEBING TINGGI</th>\n",
       "      <th>UNIT_TEGAL</th>\n",
       "      <th>UNIT_TULANG BAWANG</th>\n",
       "      <th>UNIT_TULUNGAGUNG</th>\n",
       "      <th>UNIT_UNGARAN</th>\n",
       "      <th>UNIT_WABIN</th>\n",
       "      <th>UNIT_WONOGIRI</th>\n",
       "      <th>UNIT_YOGYAKARTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12179</th>\n",
       "      <td>-0.87</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>2300037</td>\n",
       "      <td>4222539</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14448</th>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2985299</td>\n",
       "      <td>4704630</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13769</th>\n",
       "      <td>-0.94</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>28211360</td>\n",
       "      <td>34531309</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12070</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>426373</td>\n",
       "      <td>1051299</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11502</th>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1467591</td>\n",
       "      <td>2763960</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4759588</td>\n",
       "      <td>4868827</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13418</th>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>2985299</td>\n",
       "      <td>4704630</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>60416057</td>\n",
       "      <td>49183167</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1.92</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>64997688</td>\n",
       "      <td>51933021</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>5063848</td>\n",
       "      <td>5617440</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12044 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TAILS    KG  YEAR  MONTH  DAY  SupplyProvince  DemandProvince  \\\n",
       "12179  -0.87 -0.90  2021     12   17         2300037         4222539   \n",
       "14448  -0.28 -0.32  2021     12   31         2985299         4704630   \n",
       "13769  -0.94 -0.88  2021     12   27        28211360        34531309   \n",
       "12070   0.49  0.67  2021     12   16          426373         1051299   \n",
       "11502  -0.47 -0.30  2021     12   13         1467591         2763960   \n",
       "...      ...   ...   ...    ...  ...             ...             ...   \n",
       "5191   -0.11 -0.13  2020     12    1         4759588         4868827   \n",
       "13418   0.03 -0.05  2021     12   24         2985299         4704630   \n",
       "5390    0.01  0.02  2020     12    2        60416057        49183167   \n",
       "860     1.92  1.18  2019     12    5        64997688        51933021   \n",
       "7270    0.13  0.17  2020     12   16         5063848         5617440   \n",
       "\n",
       "       SIZE ENCODE  PROVINCE_ACEH  PROVINCE_BALI  ...  UNIT_TANJUNG BINTANG  \\\n",
       "12179            3           0.00           0.00  ...                  0.00   \n",
       "14448            2           0.00           0.00  ...                  0.00   \n",
       "13769            1           0.00           0.00  ...                  0.00   \n",
       "12070            1           0.00           0.00  ...                  0.00   \n",
       "11502            1           0.00           0.00  ...                  0.00   \n",
       "...            ...            ...            ...  ...                   ...   \n",
       "5191             2           0.00           1.00  ...                  0.00   \n",
       "13418            2           0.00           0.00  ...                  0.00   \n",
       "5390             2           0.00           0.00  ...                  0.00   \n",
       "860              3           0.00           0.00  ...                  0.00   \n",
       "7270             2           0.00           0.00  ...                  0.00   \n",
       "\n",
       "       UNIT_TASIKMALAYA  UNIT_TEBING TINGGI  UNIT_TEGAL  UNIT_TULANG BAWANG  \\\n",
       "12179              0.00                0.00        0.00                0.00   \n",
       "14448              0.00                0.00        0.00                0.00   \n",
       "13769              0.00                0.00        0.00                0.00   \n",
       "12070              0.00                0.00        0.00                0.00   \n",
       "11502              0.00                0.00        0.00                0.00   \n",
       "...                 ...                 ...         ...                 ...   \n",
       "5191               0.00                0.00        0.00                0.00   \n",
       "13418              0.00                0.00        0.00                0.00   \n",
       "5390               0.00                0.00        0.00                0.00   \n",
       "860                0.00                0.00        0.00                0.00   \n",
       "7270               0.00                0.00        0.00                0.00   \n",
       "\n",
       "       UNIT_TULUNGAGUNG  UNIT_UNGARAN  UNIT_WABIN  UNIT_WONOGIRI  \\\n",
       "12179              0.00          0.00        0.00           0.00   \n",
       "14448              0.00          0.00        0.00           0.00   \n",
       "13769              0.00          0.00        0.00           0.00   \n",
       "12070              0.00          0.00        0.00           0.00   \n",
       "11502              0.00          0.00        0.00           0.00   \n",
       "...                 ...           ...         ...            ...   \n",
       "5191               0.00          0.00        0.00           0.00   \n",
       "13418              0.00          0.00        0.00           0.00   \n",
       "5390               0.00          0.00        0.00           0.00   \n",
       "860                0.00          0.00        0.00           0.00   \n",
       "7270               0.00          0.00        0.00           0.00   \n",
       "\n",
       "       UNIT_YOGYAKARTA  \n",
       "12179             0.00  \n",
       "14448             0.00  \n",
       "13769             0.00  \n",
       "12070             0.00  \n",
       "11502             0.00  \n",
       "...                ...  \n",
       "5191              0.00  \n",
       "13418             0.00  \n",
       "5390              0.00  \n",
       "860               0.00  \n",
       "7270              0.00  \n",
       "\n",
       "[12044 rows x 157 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying lazy predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lazypredict in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.2.12)\n",
      "Requirement already satisfied: click in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (8.1.7)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (1.4.1.post1)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from lazypredict) (2.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (4.66.2)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from lazypredict) (1.3.2)\n",
      "Requirement already satisfied: lightgbm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (4.3.0)\n",
      "Requirement already satisfied: xgboost in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (2.0.3)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from lightgbm->lazypredict) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from lightgbm->lazypredict) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->lazypredict) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.utils import all_estimators\n",
    "from sklearn.base import RegressorMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AdaBoostRegressor', <class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'>), ('BaggingRegressor', <class 'sklearn.ensemble._bagging.BaggingRegressor'>), ('BayesianRidge', <class 'sklearn.linear_model._bayes.BayesianRidge'>), ('DecisionTreeRegressor', <class 'sklearn.tree._classes.DecisionTreeRegressor'>), ('DummyRegressor', <class 'sklearn.dummy.DummyRegressor'>), ('ElasticNet', <class 'sklearn.linear_model._coordinate_descent.ElasticNet'>), ('ElasticNetCV', <class 'sklearn.linear_model._coordinate_descent.ElasticNetCV'>), ('ExtraTreeRegressor', <class 'sklearn.tree._classes.ExtraTreeRegressor'>), ('ExtraTreesRegressor', <class 'sklearn.ensemble._forest.ExtraTreesRegressor'>), ('GammaRegressor', <class 'sklearn.linear_model._glm.glm.GammaRegressor'>), ('GaussianProcessRegressor', <class 'sklearn.gaussian_process._gpr.GaussianProcessRegressor'>), ('GradientBoostingRegressor', <class 'sklearn.ensemble._gb.GradientBoostingRegressor'>), ('HistGradientBoostingRegressor', <class 'sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor'>), ('HuberRegressor', <class 'sklearn.linear_model._huber.HuberRegressor'>), ('KNeighborsRegressor', <class 'sklearn.neighbors._regression.KNeighborsRegressor'>), ('KernelRidge', <class 'sklearn.kernel_ridge.KernelRidge'>), ('Lars', <class 'sklearn.linear_model._least_angle.Lars'>), ('LarsCV', <class 'sklearn.linear_model._least_angle.LarsCV'>), ('Lasso', <class 'sklearn.linear_model._coordinate_descent.Lasso'>), ('LassoCV', <class 'sklearn.linear_model._coordinate_descent.LassoCV'>), ('LassoLars', <class 'sklearn.linear_model._least_angle.LassoLars'>), ('LassoLarsCV', <class 'sklearn.linear_model._least_angle.LassoLarsCV'>), ('LassoLarsIC', <class 'sklearn.linear_model._least_angle.LassoLarsIC'>), ('LinearRegression', <class 'sklearn.linear_model._base.LinearRegression'>), ('LinearSVR', <class 'sklearn.svm._classes.LinearSVR'>), ('MLPRegressor', <class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'>), ('NuSVR', <class 'sklearn.svm._classes.NuSVR'>), ('OrthogonalMatchingPursuit', <class 'sklearn.linear_model._omp.OrthogonalMatchingPursuit'>), ('OrthogonalMatchingPursuitCV', <class 'sklearn.linear_model._omp.OrthogonalMatchingPursuitCV'>), ('PassiveAggressiveRegressor', <class 'sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor'>), ('PoissonRegressor', <class 'sklearn.linear_model._glm.glm.PoissonRegressor'>), ('QuantileRegressor', <class 'sklearn.linear_model._quantile.QuantileRegressor'>), ('RANSACRegressor', <class 'sklearn.linear_model._ransac.RANSACRegressor'>), ('RandomForestRegressor', <class 'sklearn.ensemble._forest.RandomForestRegressor'>), ('Ridge', <class 'sklearn.linear_model._ridge.Ridge'>), ('RidgeCV', <class 'sklearn.linear_model._ridge.RidgeCV'>), ('SGDRegressor', <class 'sklearn.linear_model._stochastic_gradient.SGDRegressor'>), ('SVR', <class 'sklearn.svm._classes.SVR'>), ('TransformedTargetRegressor', <class 'sklearn.compose._target.TransformedTargetRegressor'>), ('TweedieRegressor', <class 'sklearn.linear_model._glm.glm.TweedieRegressor'>), ('XGBRegressor', <class 'xgboost.sklearn.XGBRegressor'>), ('LGBMRegressor', <class 'lightgbm.sklearn.LGBMRegressor'>)]\n"
     ]
    }
   ],
   "source": [
    "print(lazypredict.Supervised.REGRESSORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    chosen_regressors = [\n",
    "    'SVR', \n",
    "    'BaggingRegressor',\n",
    "    'ExtraTreesRegressor',\n",
    "    'RandomForestRegressor',\n",
    "    'GradientBoostingRegressor',\n",
    "    'LGBMRegressor',\n",
    "    'XGBRegressor',\n",
    "    'CatBoostRegressor',\n",
    "    'HistGradientBoostingRegressor',\n",
    "    'AdaBoostRegressor',\n",
    "    'KNeighborsRegressor',\n",
    "    'DecisionTreeRegressor'\n",
    "]\n",
    "\n",
    "REGRESSORS = [\n",
    "    est\n",
    "    for est in all_estimators()\n",
    "    if (issubclass(est[1], RegressorMixin) and est[0] in chosen_regressors)\n",
    "\n",
    "]'''\n",
    "\n",
    "# initialising the regressor with chosen regressors\n",
    "reg = LazyRegressor(verbose=1, ignore_warnings=False, custom_metric=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/42 [00:01<00:52,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostRegressor', 'R-Squared': 0.38822110122196596, 'Adjusted R-Squared': 0.3545550349380012, 'RMSE': 1.0140434750373453, 'Time taken': 1.2924137115478516}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/42 [00:02<00:23,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BaggingRegressor', 'R-Squared': 0.8060589504376698, 'Adjusted R-Squared': 0.7953864145872367, 'RMSE': 0.570944901345103, 'Time taken': 0.7051398754119873}\n",
      "{'Model': 'BayesianRidge', 'R-Squared': 0.5196540383942234, 'Adjusted R-Squared': 0.493220699462535, 'RMSE': 0.8985378997525741, 'Time taken': 0.1851484775543213}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4/42 [00:02<00:16,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DecisionTreeRegressor', 'R-Squared': 0.6862230146049186, 'Adjusted R-Squared': 0.6689559319876639, 'RMSE': 0.7262227860912884, 'Time taken': 0.1832883358001709}\n",
      "{'Model': 'DummyRegressor', 'R-Squared': -0.00021885869723559104, 'Adjusted R-Squared': -0.05526069564622471, 'RMSE': 1.2966024788204467, 'Time taken': 0.03820300102233887}\n",
      "{'Model': 'ElasticNet', 'R-Squared': 0.015067937186860836, 'Adjusted R-Squared': -0.039132670545933834, 'RMSE': 1.2866560483416285, 'Time taken': 0.04514026641845703}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 8/42 [00:05<00:21,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ElasticNetCV', 'R-Squared': 0.5205660437014976, 'Adjusted R-Squared': 0.49418289223326595, 'RMSE': 0.8976844933128549, 'Time taken': 2.781524419784546}\n",
      "{'Model': 'ExtraTreeRegressor', 'R-Squared': 0.69274356908731, 'Adjusted R-Squared': 0.6758353112347715, 'RMSE': 0.7186374058055397, 'Time taken': 0.14821720123291016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 10/42 [00:09<00:37,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreesRegressor', 'R-Squared': 0.8252041875644915, 'Adjusted R-Squared': 0.815585210153915, 'RMSE': 0.5420318919611855, 'Time taken': 4.272757053375244}\n",
      "{'Model': 'GammaRegressor', 'R-Squared': 0.40231882532803775, 'Adjusted R-Squared': 0.36942855388622275, 'RMSE': 1.0022916600492124, 'Time taken': 0.11937570571899414}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 11/42 [00:47<05:39, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GaussianProcessRegressor', 'R-Squared': -32.8261753173401, 'Adjusted R-Squared': -34.687622749805016, 'RMSE': 7.540250531022452, 'Time taken': 37.230304479599}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 12/42 [00:49<04:17,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GradientBoostingRegressor', 'R-Squared': 0.6386300094212155, 'Adjusted R-Squared': 0.6187438935709284, 'RMSE': 0.7793550796529983, 'Time taken': 2.4228901863098145}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 13/42 [00:50<03:06,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'HistGradientBoostingRegressor', 'R-Squared': 0.7674408029020242, 'Adjusted R-Squared': 0.7546431183789319, 'RMSE': 0.6252102477414963, 'Time taken': 1.0709302425384521}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 14/42 [00:50<02:10,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'HuberRegressor', 'R-Squared': 0.5186660157226404, 'Adjusted R-Squared': 0.49217830610765767, 'RMSE': 0.899461525472337, 'Time taken': 0.32716822624206543}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 15/42 [00:51<01:31,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'KNeighborsRegressor', 'R-Squared': 0.7053578781223365, 'Adjusted R-Squared': 0.6891437830873581, 'RMSE': 0.7037311010869121, 'Time taken': 0.2735013961791992}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 17/42 [01:00<01:30,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'KernelRidge', 'R-Squared': -78.08270976010431, 'Adjusted R-Squared': -82.43461492390956, 'RMSE': 11.529224584844522, 'Time taken': 9.249894618988037}\n",
      "{'Model': 'Lars', 'R-Squared': -2.369247437640878e+28, 'Adjusted R-Squared': -2.4996266341742176e+28, 'RMSE': 199555884135842.0, 'Time taken': 0.10041308403015137}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 18/42 [01:00<01:04,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LarsCV', 'R-Squared': 0.42862551881537536, 'Adjusted R-Squared': 0.3971828992759481, 'RMSE': 0.9799857218103069, 'Time taken': 0.4555478096008301}\n",
      "{'Model': 'Lasso', 'R-Squared': -0.00021885869723559104, 'Adjusted R-Squared': -0.05526069564622471, 'RMSE': 1.2966024788204467, 'Time taken': 0.07434630393981934}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 20/42 [01:03<00:45,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LassoCV', 'R-Squared': 0.5211939093433848, 'Adjusted R-Squared': 0.49484530919158365, 'RMSE': 0.8970964979333852, 'Time taken': 2.641167640686035}\n",
      "{'Model': 'LassoLars', 'R-Squared': -0.00021885869723559104, 'Adjusted R-Squared': -0.05526069564622471, 'RMSE': 1.2966024788204467, 'Time taken': 0.0656743049621582}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 23/42 [01:04<00:20,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LassoLarsCV', 'R-Squared': 0.4922202242130769, 'Adjusted R-Squared': 0.46427720816030893, 'RMSE': 0.9238405652609801, 'Time taken': 0.20258307456970215}\n",
      "{'Model': 'LassoLarsIC', 'R-Squared': 0.5093491323167407, 'Adjusted R-Squared': 0.4823487165346616, 'RMSE': 0.908124962654713, 'Time taken': 0.1805894374847412}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 24/42 [01:04<00:15,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LinearRegression', 'R-Squared': 0.5200640124857963, 'Adjusted R-Squared': 0.49365323434358455, 'RMSE': 0.8981543679604107, 'Time taken': 0.1236884593963623}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 25/42 [01:07<00:25,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LinearSVR', 'R-Squared': 0.5098306641213479, 'Adjusted R-Squared': 0.48285674693489566, 'RMSE': 0.9076792298286904, 'Time taken': 3.5274364948272705}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 26/42 [01:21<01:17,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'MLPRegressor', 'R-Squared': 0.710783396285414, 'Adjusted R-Squared': 0.6948678663929534, 'RMSE': 0.6972217701405597, 'Time taken': 13.978176832199097}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 29/42 [01:32<00:47,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'NuSVR', 'R-Squared': 0.5707731281448487, 'Adjusted R-Squared': 0.5471528621507167, 'RMSE': 0.8493814652417179, 'Time taken': 10.828632354736328}\n",
      "{'Model': 'OrthogonalMatchingPursuit', 'R-Squared': 0.4510982683469339, 'Adjusted R-Squared': 0.4208923195668668, 'RMSE': 0.9605204786633305, 'Time taken': 0.04797720909118652}\n",
      "{'Model': 'OrthogonalMatchingPursuitCV', 'R-Squared': 0.4510982683469339, 'Adjusted R-Squared': 0.4208923195668668, 'RMSE': 0.9605204786633305, 'Time taken': 0.13541865348815918}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [01:33<00:23,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PassiveAggressiveRegressor', 'R-Squared': 0.03674208789343336, 'Adjusted R-Squared': -0.016265795808189765, 'RMSE': 1.2724203922867001, 'Time taken': 0.11642241477966309}\n",
      "{'Model': 'PoissonRegressor', 'R-Squared': 0.48653724716107305, 'Adjusted R-Squared': 0.4582814980563722, 'RMSE': 0.9289959071001787, 'Time taken': 0.16097307205200195}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 32/42 [01:37<00:28,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'QuantileRegressor', 'R-Squared': -0.12370888913213363, 'Adjusted R-Squared': -0.1855463569182343, 'RMSE': 1.3743148409175112, 'Time taken': 4.825397729873657}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 33/42 [01:38<00:21,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RANSACRegressor', 'R-Squared': -2.825203634044591e+26, 'Adjusted R-Squared': -2.9806740057743497e+26, 'RMSE': 21791353519779.926, 'Time taken': 1.1220436096191406}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 34/42 [01:45<00:27,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestRegressor', 'R-Squared': 0.8228092076623652, 'Adjusted R-Squared': 0.8130584350030562, 'RMSE': 0.545732607033221, 'Time taken': 6.25631856918335}\n",
      "{'Model': 'Ridge', 'R-Squared': 0.5216294377663593, 'Adjusted R-Squared': 0.49530480465360727, 'RMSE': 0.8966883996238066, 'Time taken': 0.06325888633728027}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 36/42 [01:45<00:11,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RidgeCV', 'R-Squared': 0.5216924325965349, 'Adjusted R-Squared': 0.49537126607626003, 'RMSE': 0.8966293569091536, 'Time taken': 0.21653246879577637}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 37/42 [01:45<00:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'SGDRegressor', 'R-Squared': 0.4947828805772676, 'Adjusted R-Squared': 0.4669808869742641, 'RMSE': 0.9215064032603248, 'Time taken': 0.20815372467041016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 39/42 [01:58<00:09,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'SVR', 'R-Squared': 0.5778900663253247, 'Adjusted R-Squared': 0.5546614439674824, 'RMSE': 0.8423103060754246, 'Time taken': 12.464138269424438}\n",
      "{'Model': 'TransformedTargetRegressor', 'R-Squared': 0.5200640124857963, 'Adjusted R-Squared': 0.49365323434358455, 'RMSE': 0.8981543679604107, 'Time taken': 0.12768173217773438}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 40/42 [01:58<00:04,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'TweedieRegressor', 'R-Squared': 0.4030448247517039, 'Adjusted R-Squared': 0.37019450490803674, 'RMSE': 1.0016827365088528, 'Time taken': 0.11376190185546875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 41/42 [01:58<00:01,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XGBRegressor', 'R-Squared': 0.7881130380918598, 'Adjusted R-Squared': 0.776452942396249, 'RMSE': 0.5967761318970698, 'Time taken': 0.37598299980163574}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 12044, number of used features: 153\n",
      "[LightGBM] [Info] Start training from score 11.475174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [01:59<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMRegressor', 'R-Squared': 0.7697210492224728, 'Adjusted R-Squared': 0.7570488461828402, 'RMSE': 0.6221375995476037, 'Time taken': 0.21047663688659668}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.54</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.55</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeRegressor</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.84</td>\n",
       "      <td>12.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.85</td>\n",
       "      <td>10.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoCV</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsIC</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsCV</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoissonRegressor</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LarsCV</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GammaRegressor</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileRegressor</th>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>1.37</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>-34.69</td>\n",
       "      <td>-32.83</td>\n",
       "      <td>7.54</td>\n",
       "      <td>37.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>-82.43</td>\n",
       "      <td>-78.08</td>\n",
       "      <td>11.53</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>-298067400577434970170064896.00</td>\n",
       "      <td>-282520363404459106451324928.00</td>\n",
       "      <td>21791353519779.93</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>-24996266341742175694129987584.00</td>\n",
       "      <td>-23692474376408780779026382848.00</td>\n",
       "      <td>199555884135842.00</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Adjusted R-Squared  \\\n",
       "Model                                                             \n",
       "ExtraTreesRegressor                                        0.82   \n",
       "RandomForestRegressor                                      0.81   \n",
       "BaggingRegressor                                           0.80   \n",
       "XGBRegressor                                               0.78   \n",
       "LGBMRegressor                                              0.76   \n",
       "HistGradientBoostingRegressor                              0.75   \n",
       "MLPRegressor                                               0.69   \n",
       "KNeighborsRegressor                                        0.69   \n",
       "ExtraTreeRegressor                                         0.68   \n",
       "DecisionTreeRegressor                                      0.67   \n",
       "GradientBoostingRegressor                                  0.62   \n",
       "SVR                                                        0.55   \n",
       "NuSVR                                                      0.55   \n",
       "RidgeCV                                                    0.50   \n",
       "Ridge                                                      0.50   \n",
       "LassoCV                                                    0.49   \n",
       "ElasticNetCV                                               0.49   \n",
       "TransformedTargetRegressor                                 0.49   \n",
       "LinearRegression                                           0.49   \n",
       "BayesianRidge                                              0.49   \n",
       "HuberRegressor                                             0.49   \n",
       "LinearSVR                                                  0.48   \n",
       "LassoLarsIC                                                0.48   \n",
       "SGDRegressor                                               0.47   \n",
       "LassoLarsCV                                                0.46   \n",
       "PoissonRegressor                                           0.46   \n",
       "OrthogonalMatchingPursuit                                  0.42   \n",
       "OrthogonalMatchingPursuitCV                                0.42   \n",
       "LarsCV                                                     0.40   \n",
       "TweedieRegressor                                           0.37   \n",
       "GammaRegressor                                             0.37   \n",
       "AdaBoostRegressor                                          0.35   \n",
       "PassiveAggressiveRegressor                                -0.02   \n",
       "ElasticNet                                                -0.04   \n",
       "Lasso                                                     -0.06   \n",
       "DummyRegressor                                            -0.06   \n",
       "LassoLars                                                 -0.06   \n",
       "QuantileRegressor                                         -0.19   \n",
       "GaussianProcessRegressor                                 -34.69   \n",
       "KernelRidge                                              -82.43   \n",
       "RANSACRegressor                 -298067400577434970170064896.00   \n",
       "Lars                          -24996266341742175694129987584.00   \n",
       "\n",
       "                                                      R-Squared  \\\n",
       "Model                                                             \n",
       "ExtraTreesRegressor                                        0.83   \n",
       "RandomForestRegressor                                      0.82   \n",
       "BaggingRegressor                                           0.81   \n",
       "XGBRegressor                                               0.79   \n",
       "LGBMRegressor                                              0.77   \n",
       "HistGradientBoostingRegressor                              0.77   \n",
       "MLPRegressor                                               0.71   \n",
       "KNeighborsRegressor                                        0.71   \n",
       "ExtraTreeRegressor                                         0.69   \n",
       "DecisionTreeRegressor                                      0.69   \n",
       "GradientBoostingRegressor                                  0.64   \n",
       "SVR                                                        0.58   \n",
       "NuSVR                                                      0.57   \n",
       "RidgeCV                                                    0.52   \n",
       "Ridge                                                      0.52   \n",
       "LassoCV                                                    0.52   \n",
       "ElasticNetCV                                               0.52   \n",
       "TransformedTargetRegressor                                 0.52   \n",
       "LinearRegression                                           0.52   \n",
       "BayesianRidge                                              0.52   \n",
       "HuberRegressor                                             0.52   \n",
       "LinearSVR                                                  0.51   \n",
       "LassoLarsIC                                                0.51   \n",
       "SGDRegressor                                               0.49   \n",
       "LassoLarsCV                                                0.49   \n",
       "PoissonRegressor                                           0.49   \n",
       "OrthogonalMatchingPursuit                                  0.45   \n",
       "OrthogonalMatchingPursuitCV                                0.45   \n",
       "LarsCV                                                     0.43   \n",
       "TweedieRegressor                                           0.40   \n",
       "GammaRegressor                                             0.40   \n",
       "AdaBoostRegressor                                          0.39   \n",
       "PassiveAggressiveRegressor                                 0.04   \n",
       "ElasticNet                                                 0.02   \n",
       "Lasso                                                     -0.00   \n",
       "DummyRegressor                                            -0.00   \n",
       "LassoLars                                                 -0.00   \n",
       "QuantileRegressor                                         -0.12   \n",
       "GaussianProcessRegressor                                 -32.83   \n",
       "KernelRidge                                              -78.08   \n",
       "RANSACRegressor                 -282520363404459106451324928.00   \n",
       "Lars                          -23692474376408780779026382848.00   \n",
       "\n",
       "                                            RMSE  Time Taken  \n",
       "Model                                                         \n",
       "ExtraTreesRegressor                         0.54        4.27  \n",
       "RandomForestRegressor                       0.55        6.26  \n",
       "BaggingRegressor                            0.57        0.71  \n",
       "XGBRegressor                                0.60        0.38  \n",
       "LGBMRegressor                               0.62        0.21  \n",
       "HistGradientBoostingRegressor               0.63        1.07  \n",
       "MLPRegressor                                0.70       13.98  \n",
       "KNeighborsRegressor                         0.70        0.27  \n",
       "ExtraTreeRegressor                          0.72        0.15  \n",
       "DecisionTreeRegressor                       0.73        0.18  \n",
       "GradientBoostingRegressor                   0.78        2.42  \n",
       "SVR                                         0.84       12.46  \n",
       "NuSVR                                       0.85       10.83  \n",
       "RidgeCV                                     0.90        0.22  \n",
       "Ridge                                       0.90        0.06  \n",
       "LassoCV                                     0.90        2.64  \n",
       "ElasticNetCV                                0.90        2.78  \n",
       "TransformedTargetRegressor                  0.90        0.13  \n",
       "LinearRegression                            0.90        0.12  \n",
       "BayesianRidge                               0.90        0.19  \n",
       "HuberRegressor                              0.90        0.33  \n",
       "LinearSVR                                   0.91        3.53  \n",
       "LassoLarsIC                                 0.91        0.18  \n",
       "SGDRegressor                                0.92        0.21  \n",
       "LassoLarsCV                                 0.92        0.20  \n",
       "PoissonRegressor                            0.93        0.16  \n",
       "OrthogonalMatchingPursuit                   0.96        0.05  \n",
       "OrthogonalMatchingPursuitCV                 0.96        0.14  \n",
       "LarsCV                                      0.98        0.46  \n",
       "TweedieRegressor                            1.00        0.11  \n",
       "GammaRegressor                              1.00        0.12  \n",
       "AdaBoostRegressor                           1.01        1.29  \n",
       "PassiveAggressiveRegressor                  1.27        0.12  \n",
       "ElasticNet                                  1.29        0.05  \n",
       "Lasso                                       1.30        0.07  \n",
       "DummyRegressor                              1.30        0.04  \n",
       "LassoLars                                   1.30        0.07  \n",
       "QuantileRegressor                           1.37        4.83  \n",
       "GaussianProcessRegressor                    7.54       37.23  \n",
       "KernelRidge                                11.53        9.25  \n",
       "RANSACRegressor                21791353519779.93        1.12  \n",
       "Lars                          199555884135842.00        0.10  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fitting and evaluate models\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.54</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.55</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Adjusted R-Squared  R-Squared  RMSE  Time Taken\n",
       "Model                                                                 \n",
       "ExtraTreesRegressor                  0.82       0.83  0.54        4.27\n",
       "RandomForestRegressor                0.81       0.82  0.55        6.26\n",
       "BaggingRegressor                     0.80       0.81  0.57        0.71\n",
       "XGBRegressor                         0.78       0.79  0.60        0.38\n",
       "LGBMRegressor                        0.76       0.77  0.62        0.21"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering out the top 5 models\n",
    "top_5_models = models.head(5)\n",
    "top_5_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.2274047\ttest: 1.2418868\tbest: 1.2418868 (0)\ttotal: 1.97ms\tremaining: 1.96s\n",
      "100:\tlearn: 0.6609947\ttest: 0.6988349\tbest: 0.6988349 (100)\ttotal: 176ms\tremaining: 1.57s\n",
      "200:\tlearn: 0.5868129\ttest: 0.6455161\tbest: 0.6455161 (200)\ttotal: 327ms\tremaining: 1.3s\n",
      "300:\tlearn: 0.5465392\ttest: 0.6210595\tbest: 0.6210595 (300)\ttotal: 475ms\tremaining: 1.1s\n",
      "400:\tlearn: 0.5168968\ttest: 0.6041516\tbest: 0.6041516 (400)\ttotal: 623ms\tremaining: 931ms\n",
      "500:\tlearn: 0.4950327\ttest: 0.5956385\tbest: 0.5955858 (499)\ttotal: 772ms\tremaining: 769ms\n",
      "600:\tlearn: 0.4768649\ttest: 0.5885465\tbest: 0.5885465 (600)\ttotal: 932ms\tremaining: 619ms\n",
      "700:\tlearn: 0.4603652\ttest: 0.5831260\tbest: 0.5830765 (696)\ttotal: 1.13s\tremaining: 482ms\n",
      "800:\tlearn: 0.4465353\ttest: 0.5789080\tbest: 0.5789080 (800)\ttotal: 1.28s\tremaining: 318ms\n",
      "900:\tlearn: 0.4338069\ttest: 0.5757830\tbest: 0.5757830 (900)\ttotal: 1.43s\tremaining: 157ms\n",
      "999:\tlearn: 0.4218770\ttest: 0.5732579\tbest: 0.5731948 (980)\ttotal: 1.58s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5731947735\n",
      "bestIteration = 980\n",
      "\n",
      "Shrink model to first 981 iterations.\n",
      "Mean Absolute Error (MAE): 0.4028182669099071\n",
      "Mean Squared Error (MSE): 0.3285522483302984\n",
      "Root Mean Squared Error (RMSE): 0.5731947734673603\n",
      "R-squared (R²): 0.8045274461260352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.results(y_test, predictions)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying CatBoostRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "cb = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, loss_function='RMSE', verbose=100)\n",
    "# fitting the model\n",
    "cb.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=100, verbose=100)\n",
    "\n",
    "# making predictions\n",
    "predictions = cb.predict(X_test)\n",
    "\n",
    "# results \n",
    "results(y_test, predictions)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "using entity embeddings to train the neural network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting up the model\n",
    "creating entity embeddings <br>\n",
    "`cat_col1` = `PROVINCE` <br>\n",
    "`cat_col2` = `CHICKEN SIZE` <br>\n",
    "`cat_col3` = `SIZE` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================\n",
      " cat_input1 (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " cat_input2 (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " cat_input3 (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_10 (Embedding)    (None, 1, 13)                325       ['cat_input1[0][0]']          \n",
      "                                                                                                  \n",
      " embedding_11 (Embedding)    (None, 1, 2)                 8         ['cat_input2[0][0]']          \n",
      "                                                                                                  \n",
      " embedding_12 (Embedding)    (None, 1, 50)                6200      ['cat_input3[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_9 (Flatten)         (None, 13)                   0         ['embedding_10[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_10 (Flatten)        (None, 2)                    0         ['embedding_11[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_11 (Flatten)        (None, 50)                   0         ['embedding_12[0][0]']        \n",
      "                                                                                                  \n",
      " num_input (InputLayer)      [(None, 8)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 73)                   0         ['flatten_9[0][0]',           \n",
      "                                                                     'flatten_10[0][0]',          \n",
      "                                                                     'flatten_11[0][0]',          \n",
      "                                                                     'num_input[0][0]']           \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 128)                  9472      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 64)                   8256      ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 1)                    65        ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24326 (95.02 KB)\n",
      "Trainable params: 24326 (95.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# original dataset `df`\n",
    "\n",
    "# importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Reshape, Concatenate, Dense, Flatten\n",
    "\n",
    "# getting the unique values of the categorical columns\n",
    "cat_columns = ['PROVINCE', 'CHICKEN SIZE', 'UNIT']\n",
    "unique_cat1 = df['PROVINCE'].nunique()\n",
    "unique_cat2 = df['CHICKEN SIZE'].nunique()\n",
    "unique_cat3 = df['UNIT'].nunique()\n",
    "\n",
    "# getting numerical columns\n",
    "num_columns = df.columns.difference(cat_columns)\n",
    "numerical_data = df[num_columns]\n",
    "\n",
    "# scaling the numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
    "\n",
    "# defining the input layer\n",
    "num_input = Input(shape=(numerical_data_scaled.shape[1],), name='num_input')\n",
    "\n",
    "# embedding the categorical columns\n",
    "cat_input1 = Input(shape = (1,), name='cat_input1')\n",
    "cat_embed1 = Embedding(input_dim=unique_cat1, output_dim = int(min(np.ceil(unique_cat1 /2), 50)))(cat_input1)\n",
    "cat_embed1 = Flatten()(cat_embed1)\n",
    "\n",
    "cat_input2 = Input(shape = (1,), name='cat_input2')\n",
    "cat_embed2 = Embedding(input_dim=unique_cat2, output_dim = int(min(np.ceil(unique_cat2 /2), 50)))(cat_input2)\n",
    "cat_embed2 = Flatten()(cat_embed2)\n",
    "\n",
    "\n",
    "cat_input3 = Input(shape = (1,), name='cat_input3')\n",
    "cat_embed3 = Embedding(input_dim=unique_cat3, output_dim = int(min(np.ceil(unique_cat3 /2), 50)))(cat_input3)\n",
    "cat_embed3 = Flatten()(cat_embed3)\n",
    "\n",
    "\n",
    "# concatenate the embeddings with numerical input\n",
    "concatenated = Concatenate()([cat_embed1, cat_embed2, cat_embed3, num_input])\n",
    "\n",
    "\n",
    "# adding the dense layer ontop of the embeddings\n",
    "dense_output = Dense(128, activation = 'relu')(concatenated)\n",
    "dense_output = Dense(64, activation = 'relu')(dense_output)\n",
    "output = Dense(1)(dense_output)\n",
    "\n",
    "# creating the model\n",
    "model = Model(inputs = [cat_input1, cat_input2, cat_input3, num_input], outputs = output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "X_train_cat1 = X_train['PROVINCE']\n",
    "X_train_cat2 = X_train['CHICKEN SIZE']\n",
    "X_train_cat3 = X_train['UNIT']\n",
    "X_train_num = X_train.drop(['PROVINCE', 'CHICKEN SIZE', 'UNIT'], axis = 1)\n",
    "\n",
    "# fitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>price_bin</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYAKUMBUH</td>\n",
       "      <td>1267</td>\n",
       "      <td>2856.00</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3885216</td>\n",
       "      <td>5993194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINJAI</td>\n",
       "      <td>3310</td>\n",
       "      <td>7799.50</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>13</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5447863</td>\n",
       "      <td>5931514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANDAR JAYA</td>\n",
       "      <td>8236</td>\n",
       "      <td>22197.00</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANDAR LAMPUNG</td>\n",
       "      <td>2565</td>\n",
       "      <td>4971.00</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANYUASIN</td>\n",
       "      <td>696</td>\n",
       "      <td>1464.40</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5758528</td>\n",
       "      <td>7021239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15050</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>430</td>\n",
       "      <td>901.40</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15051</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>294</td>\n",
       "      <td>605.00</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15052</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>432</td>\n",
       "      <td>962.40</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15053</th>\n",
       "      <td>GUNUNGKIDUL</td>\n",
       "      <td>200</td>\n",
       "      <td>370.80</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>DI YOGYAKARTA</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3993820</td>\n",
       "      <td>5186026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15054</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>400</td>\n",
       "      <td>865.80</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15055 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 UNIT  TAILS       KG CHICKEN SIZE          PROVINCE  \\\n",
       "0          PAYAKUMBUH   1267  2856.00        LARGE    SUMATERA BARAT   \n",
       "1              SINJAI   3310  7799.50        LARGE  SULAWESI SELATAN   \n",
       "2         BANDAR JAYA   8236 22197.00        LARGE           LAMPUNG   \n",
       "3      BANDAR LAMPUNG   2565  4971.00       MEDIUM           LAMPUNG   \n",
       "4           BANYUASIN    696  1464.40        LARGE  SUMATERA SELATAN   \n",
       "...               ...    ...      ...          ...               ...   \n",
       "15050        BOYOLALI    430   901.40          BIG       JAWA TENGAH   \n",
       "15051        BOYOLALI    294   605.00          BIG       JAWA TENGAH   \n",
       "15052        BOYOLALI    432   962.40          BIG       JAWA TENGAH   \n",
       "15053     GUNUNGKIDUL    200   370.80       MEDIUM     DI YOGYAKARTA   \n",
       "15054        BOYOLALI    400   865.80          BIG       JAWA TENGAH   \n",
       "\n",
       "       price_bin  YEAR  MONTH  DAY  SupplyProvince  DemandProvince  \n",
       "0             11  2019     12    1         3885216         5993194  \n",
       "1             13  2019     12    1         5447863         5931514  \n",
       "2             10  2019     12    1         5404511         5618463  \n",
       "3             11  2019     12    1         5404511         5618463  \n",
       "4             10  2019     12    1         5758528         7021239  \n",
       "...          ...   ...    ...  ...             ...             ...  \n",
       "15050         10  2023     12   31        54958385        26285612  \n",
       "15051         10  2023     12   31        54958385        26285612  \n",
       "15052         10  2023     12   31        54958385        26285612  \n",
       "15053         10  2023     12   31         3993820         5186026  \n",
       "15054         10  2023     12   31        54958385        26285612  \n",
       "\n",
       "[15055 rows x 11 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "339/339 [==============================] - 1s 1ms/step - loss: 321104838656.0000 - mae: 123220.4141 - val_loss: 52483396.0000 - val_mae: 5524.1006\n",
      "Epoch 2/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 41420740.0000 - mae: 4618.7798 - val_loss: 28234032.0000 - val_mae: 3835.6472\n",
      "Epoch 3/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 20185572.0000 - mae: 3167.2327 - val_loss: 9446453.0000 - val_mae: 2045.1842\n",
      "Epoch 4/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 6588207.0000 - mae: 1593.1550 - val_loss: 4124622.2500 - val_mae: 1210.5474\n",
      "Epoch 5/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 3645962.2500 - mae: 1008.6276 - val_loss: 2593703.5000 - val_mae: 858.6125\n",
      "Epoch 6/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 2381865.0000 - mae: 764.1129 - val_loss: 1900219.3750 - val_mae: 769.4922\n",
      "Epoch 7/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 1663770.1250 - mae: 666.0511 - val_loss: 1411462.7500 - val_mae: 692.6335\n",
      "Epoch 8/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 1136816.6250 - mae: 598.2757 - val_loss: 807617.6875 - val_mae: 506.7061\n",
      "Epoch 9/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 733652.6875 - mae: 515.5995 - val_loss: 726607.1875 - val_mae: 639.9957\n",
      "Epoch 10/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 467717.7812 - mae: 434.4715 - val_loss: 399809.5938 - val_mae: 431.8974\n",
      "Epoch 11/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 361304.5312 - mae: 411.9648 - val_loss: 157830.4062 - val_mae: 269.9457\n",
      "Epoch 12/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 164322.1562 - mae: 285.5919 - val_loss: 187197.2969 - val_mae: 321.6920\n",
      "Epoch 13/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 142460.3438 - mae: 269.9297 - val_loss: 302057.3125 - val_mae: 415.0816\n",
      "Epoch 14/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 79904.2031 - mae: 208.6195 - val_loss: 43095.4492 - val_mae: 165.9166\n",
      "Epoch 15/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 62378.7188 - mae: 188.3743 - val_loss: 83279.2422 - val_mae: 218.5399\n",
      "Epoch 16/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 516498.5000 - mae: 460.6822 - val_loss: 1119061.8750 - val_mae: 757.5232\n",
      "Epoch 17/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 320925504.0000 - mae: 7064.0264 - val_loss: 71594752.0000 - val_mae: 5556.6357\n",
      "Epoch 18/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 1440234240.0000 - mae: 14817.3438 - val_loss: 6362546.0000 - val_mae: 1739.1373\n",
      "Epoch 19/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 12086361.0000 - mae: 2257.5981 - val_loss: 4793827.5000 - val_mae: 1711.8400\n",
      "Epoch 20/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 48761872.0000 - mae: 4129.2861 - val_loss: 12144100.0000 - val_mae: 2572.4709\n",
      "Epoch 21/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 1114858496.0000 - mae: 13116.1152 - val_loss: 7888581.5000 - val_mae: 1812.5444\n",
      "Epoch 22/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 63603628.0000 - mae: 4045.0166 - val_loss: 39279076.0000 - val_mae: 4428.9736\n",
      "Epoch 23/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 92988704.0000 - mae: 4420.8696 - val_loss: 223031200.0000 - val_mae: 11371.9639\n",
      "Epoch 24/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 519788192.0000 - mae: 10577.2227 - val_loss: 82408656.0000 - val_mae: 6561.2456\n",
      "Epoch 25/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 320113312.0000 - mae: 7621.3091 - val_loss: 262134480.0000 - val_mae: 12822.3955\n",
      "Epoch 26/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 1540991744.0000 - mae: 16268.4219 - val_loss: 124073584.0000 - val_mae: 8005.9253\n",
      "Epoch 27/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 20430448.0000 - mae: 2915.7874 - val_loss: 16523337.0000 - val_mae: 2708.2393\n",
      "Epoch 28/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 18558834.0000 - mae: 2777.5430 - val_loss: 17404524.0000 - val_mae: 2824.0789\n",
      "Epoch 29/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 21372580.0000 - mae: 2727.7434 - val_loss: 2790459.0000 - val_mae: 1072.1046\n",
      "Epoch 30/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 58659676.0000 - mae: 4421.6753 - val_loss: 9883945.0000 - val_mae: 2204.5486\n",
      "Epoch 31/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 342100224.0000 - mae: 8583.6748 - val_loss: 121090880.0000 - val_mae: 8188.7412\n",
      "Epoch 32/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 77007776.0000 - mae: 5186.5386 - val_loss: 226898480.0000 - val_mae: 11618.1113\n",
      "Epoch 33/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 498617472.0000 - mae: 10707.6670 - val_loss: 2010009.0000 - val_mae: 984.9580\n",
      "Epoch 34/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 8162915.5000 - mae: 1760.3561 - val_loss: 34825676.0000 - val_mae: 4582.3066\n",
      "Epoch 35/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 63865664.0000 - mae: 4148.3135 - val_loss: 60997808.0000 - val_mae: 5993.1987\n",
      "Epoch 36/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 171742432.0000 - mae: 6114.2661 - val_loss: 1044016192.0000 - val_mae: 23634.1562\n",
      "Epoch 37/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 145474320.0000 - mae: 4572.7139 - val_loss: 1376288.0000 - val_mae: 876.5516\n",
      "Epoch 38/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 714866880.0000 - mae: 9259.0840 - val_loss: 728456704.0000 - val_mae: 20694.5020\n",
      "Epoch 39/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 25397066.0000 - mae: 2167.9116 - val_loss: 1987095.6250 - val_mae: 988.8322\n",
      "Epoch 40/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 1901379.1250 - mae: 913.5917 - val_loss: 4811042.5000 - val_mae: 1609.4609\n",
      "Epoch 41/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 1520239.8750 - mae: 781.6091 - val_loss: 1326114.8750 - val_mae: 811.5253\n",
      "Epoch 42/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 19030104.0000 - mae: 2076.6140 - val_loss: 12167067.0000 - val_mae: 2746.3064\n",
      "Epoch 43/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 162981536.0000 - mae: 6695.2661 - val_loss: 159923024.0000 - val_mae: 8910.2373\n",
      "Epoch 44/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 103331296.0000 - mae: 4207.7627 - val_loss: 1858599.5000 - val_mae: 907.5869\n",
      "Epoch 45/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 7254211.5000 - mae: 1655.9733 - val_loss: 99223320.0000 - val_mae: 7373.8105\n",
      "Epoch 46/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 301056384.0000 - mae: 7086.3311 - val_loss: 219116.2500 - val_mae: 272.5020\n",
      "Epoch 47/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 745708.1250 - mae: 533.5311 - val_loss: 525614.9375 - val_mae: 539.1840\n",
      "Epoch 48/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 7229822.0000 - mae: 1378.8865 - val_loss: 476160.3125 - val_mae: 500.4102\n",
      "Epoch 49/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 15694666.0000 - mae: 1461.5314 - val_loss: 104920392.0000 - val_mae: 7895.9229\n",
      "Epoch 50/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 57378184.0000 - mae: 3553.4360 - val_loss: 682775.6250 - val_mae: 656.6673\n",
      "Epoch 51/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 168390512.0000 - mae: 5958.7905 - val_loss: 314246176.0000 - val_mae: 13215.8477\n",
      "Epoch 52/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 16091930.0000 - mae: 1279.3322 - val_loss: 21406.3047 - val_mae: 119.9671\n",
      "Epoch 53/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 26211.4434 - mae: 125.8543 - val_loss: 30118.2168 - val_mae: 157.7316\n",
      "Epoch 54/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 508364224.0000 - mae: 7202.5278 - val_loss: 1582448000.0000 - val_mae: 29800.2188\n",
      "Epoch 55/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 51907280.0000 - mae: 1982.6132 - val_loss: 10175.5664 - val_mae: 87.0620\n",
      "Epoch 56/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 6155.2729 - mae: 63.7020 - val_loss: 4479.2451 - val_mae: 50.6240\n",
      "Epoch 57/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 4588.8335 - mae: 53.6297 - val_loss: 3861.0564 - val_mae: 47.4095\n",
      "Epoch 58/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 4017.8633 - mae: 49.4925 - val_loss: 3751.6489 - val_mae: 47.8912\n",
      "Epoch 59/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 5392.3525 - mae: 59.4266 - val_loss: 3446.7715 - val_mae: 42.8835\n",
      "Epoch 60/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 3918.7471 - mae: 49.8192 - val_loss: 3487.8718 - val_mae: 49.8637\n",
      "Epoch 61/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 17192.5371 - mae: 88.7994 - val_loss: 600294.6250 - val_mae: 562.8002\n",
      "Epoch 62/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 53507180.0000 - mae: 2579.7537 - val_loss: 236953.7344 - val_mae: 350.4988\n",
      "Epoch 63/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 5560410.5000 - mae: 847.6965 - val_loss: 187259.8906 - val_mae: 325.5642\n",
      "Epoch 64/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 27157108.0000 - mae: 2697.5425 - val_loss: 434299.5000 - val_mae: 496.2580\n",
      "Epoch 65/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 694113.5000 - mae: 491.7481 - val_loss: 347735.5000 - val_mae: 432.9265\n",
      "Epoch 66/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 79544992.0000 - mae: 3372.4199 - val_loss: 159981.0781 - val_mae: 289.7935\n",
      "Epoch 67/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 139779.0312 - mae: 212.2820 - val_loss: 113490.6328 - val_mae: 251.7280\n",
      "Epoch 68/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 131364.5781 - mae: 228.0747 - val_loss: 2028155.6250 - val_mae: 1092.0895\n",
      "Epoch 69/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 15758129.0000 - mae: 1856.5087 - val_loss: 2065679.7500 - val_mae: 1054.0946\n",
      "Epoch 70/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 44134516.0000 - mae: 2746.7886 - val_loss: 40636284.0000 - val_mae: 3877.9775\n",
      "Epoch 71/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 1785804.3750 - mae: 534.3793 - val_loss: 33097.7969 - val_mae: 142.8307\n",
      "Epoch 72/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 553394.7500 - mae: 382.7854 - val_loss: 226324.1094 - val_mae: 353.2190\n",
      "Epoch 73/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 20953964.0000 - mae: 1567.4603 - val_loss: 114301488.0000 - val_mae: 7926.4155\n",
      "Epoch 74/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 12201064.0000 - mae: 1409.3240 - val_loss: 21724.9004 - val_mae: 99.1760\n",
      "Epoch 75/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 726122.3750 - mae: 359.1617 - val_loss: 24294978.0000 - val_mae: 3807.7178\n",
      "Epoch 76/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 15478545.0000 - mae: 1968.3271 - val_loss: 185033.1562 - val_mae: 364.2556\n",
      "Epoch 77/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 12932670.0000 - mae: 1363.1853 - val_loss: 782809.4375 - val_mae: 692.9473\n",
      "Epoch 78/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 9269166.0000 - mae: 1626.1108 - val_loss: 2462755.0000 - val_mae: 1116.2064\n",
      "Epoch 79/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 4673351.0000 - mae: 1231.3896 - val_loss: 57080.7891 - val_mae: 176.0465\n",
      "Epoch 80/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 16295254.0000 - mae: 1668.3004 - val_loss: 65949.5938 - val_mae: 190.4398\n",
      "Epoch 81/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 1870831.8750 - mae: 589.2833 - val_loss: 1397987.8750 - val_mae: 839.0302\n",
      "Epoch 82/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 17370406.0000 - mae: 1699.8502 - val_loss: 433328.6875 - val_mae: 440.4149\n",
      "Epoch 83/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 1582731.8750 - mae: 780.4051 - val_loss: 560526.9375 - val_mae: 513.2466\n",
      "Epoch 84/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 1088489.5000 - mae: 568.2553 - val_loss: 203455.7812 - val_mae: 342.4058\n",
      "Epoch 85/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 68312480.0000 - mae: 3047.0298 - val_loss: 19483.6816 - val_mae: 114.3798\n",
      "Epoch 86/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 21712.0566 - mae: 113.9386 - val_loss: 18240.4316 - val_mae: 110.4415\n",
      "Epoch 87/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 26104.3184 - mae: 119.6948 - val_loss: 33307.2891 - val_mae: 134.0266\n",
      "Epoch 88/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 18877.4336 - mae: 102.6222 - val_loss: 11907.3936 - val_mae: 85.4526\n",
      "Epoch 89/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 21872.6074 - mae: 106.4936 - val_loss: 27987.3359 - val_mae: 117.9611\n",
      "Epoch 90/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 41608.0078 - mae: 136.9324 - val_loss: 27928.3145 - val_mae: 135.4041\n",
      "Epoch 91/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 90332.1797 - mae: 170.1037 - val_loss: 26685.1328 - val_mae: 116.4357\n",
      "Epoch 92/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 327505.4688 - mae: 319.0973 - val_loss: 743108.5000 - val_mae: 654.3956\n",
      "Epoch 93/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 5557705.0000 - mae: 1045.7231 - val_loss: 7417.0571 - val_mae: 56.7256\n",
      "Epoch 94/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 8894.1855 - mae: 59.2017 - val_loss: 22371.7988 - val_mae: 109.5786\n",
      "Epoch 95/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 169652.7812 - mae: 229.5764 - val_loss: 272142.5938 - val_mae: 389.6871\n",
      "Epoch 96/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 6353321.0000 - mae: 878.2083 - val_loss: 8311.1328 - val_mae: 68.2580\n",
      "Epoch 97/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 8925.9912 - mae: 72.9035 - val_loss: 4864.0713 - val_mae: 55.2277\n",
      "Epoch 98/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 35987.5039 - mae: 108.8729 - val_loss: 7906.5552 - val_mae: 69.5617\n",
      "Epoch 99/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 99928.6172 - mae: 169.7416 - val_loss: 11869.8730 - val_mae: 63.5040\n",
      "Epoch 100/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 1030631.1250 - mae: 496.8445 - val_loss: 11116693.0000 - val_mae: 2535.2422\n",
      "95/95 [==============================] - 0s 715us/step\n",
      "RMSE: 3287.589303794758\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Single output node for regression\n",
    "])\n",
    "\n",
    "# Compile the model, specifying the optimizer, loss function, and metric\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Fit the model on the training data\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, epochs=100, verbose=1)\n",
    "\n",
    "# Predict the target on the testing set\n",
    "predictions = model.predict(X_test).flatten()\n",
    "\n",
    "# Evaluate the model performance using RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# You can plot the training history to check how the loss and metric evolved over epochs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
