{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forecasting selling price of chicken with Bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing the relevant libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.6.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from category_encoders) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (1.12.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from category_encoders) (0.14.1)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from category_encoders) (0.5.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2023.4)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (3.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.10/site-packages (from statsmodels>=0.9.0->category_encoders) (23.2)\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "!pip install category_encoders\n",
    "import category_encoders as ce\n",
    "from category_encoders import TargetEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>SALES PER KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYAKUMBUH</td>\n",
       "      <td>1267</td>\n",
       "      <td>2856.0</td>\n",
       "      <td>18000.00000</td>\n",
       "      <td>2.254144</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3885216</td>\n",
       "      <td>5993194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINJAI</td>\n",
       "      <td>3310</td>\n",
       "      <td>7799.5</td>\n",
       "      <td>22637.89730</td>\n",
       "      <td>2.356344</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5447863</td>\n",
       "      <td>5931514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANDAR JAYA</td>\n",
       "      <td>8236</td>\n",
       "      <td>22197.0</td>\n",
       "      <td>15905.01419</td>\n",
       "      <td>2.695119</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANDAR LAMPUNG</td>\n",
       "      <td>2565</td>\n",
       "      <td>4971.0</td>\n",
       "      <td>18060.47073</td>\n",
       "      <td>1.938012</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANYUASIN</td>\n",
       "      <td>696</td>\n",
       "      <td>1464.4</td>\n",
       "      <td>16368.88828</td>\n",
       "      <td>2.104023</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5758528</td>\n",
       "      <td>7021239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             UNIT  TAILS       KG  SALES PER KG       ABW CHICKEN SIZE  \\\n",
       "0      PAYAKUMBUH   1267   2856.0   18000.00000  2.254144        LARGE   \n",
       "1          SINJAI   3310   7799.5   22637.89730  2.356344        LARGE   \n",
       "2     BANDAR JAYA   8236  22197.0   15905.01419  2.695119        LARGE   \n",
       "3  BANDAR LAMPUNG   2565   4971.0   18060.47073  1.938012       MEDIUM   \n",
       "4       BANYUASIN    696   1464.4   16368.88828  2.104023        LARGE   \n",
       "\n",
       "           PROVINCE  YEAR  MONTH  DAY  SupplyProvince  DemandProvince  \n",
       "0    SUMATERA BARAT    19     12    1         3885216         5993194  \n",
       "1  SULAWESI SELATAN    19     12    1         5447863         5931514  \n",
       "2           LAMPUNG    19     12    1         5404511         5618463  \n",
       "3           LAMPUNG    19     12    1         5404511         5618463  \n",
       "4  SUMATERA SELATAN    19     12    1         5758528         7021239  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading file\n",
    "df = pd.read_csv('/workspaces/forecasting/data/final.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>SALES PER KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>15055.0</td>\n",
       "      <td>15055.000000</td>\n",
       "      <td>1.505500e+04</td>\n",
       "      <td>1.505500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8241.127532</td>\n",
       "      <td>15260.051938</td>\n",
       "      <td>19204.083254</td>\n",
       "      <td>1.829462</td>\n",
       "      <td>20.098439</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.780671</td>\n",
       "      <td>2.617008e+07</td>\n",
       "      <td>2.040207e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7135.717864</td>\n",
       "      <td>13785.152507</td>\n",
       "      <td>2153.773552</td>\n",
       "      <td>0.336812</td>\n",
       "      <td>0.985753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.879310</td>\n",
       "      <td>2.328217e+07</td>\n",
       "      <td>1.675878e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>6892.778929</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.322200e+04</td>\n",
       "      <td>3.913950e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3235.500000</td>\n",
       "      <td>5698.000000</td>\n",
       "      <td>17414.197155</td>\n",
       "      <td>1.596241</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.424703e+06</td>\n",
       "      <td>5.141045e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6532.000000</td>\n",
       "      <td>11683.200000</td>\n",
       "      <td>19072.570490</td>\n",
       "      <td>1.821657</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.256251e+07</td>\n",
       "      <td>1.123831e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11104.000000</td>\n",
       "      <td>20707.450000</td>\n",
       "      <td>20576.154140</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.994253e+07</td>\n",
       "      <td>3.453131e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>103280.000000</td>\n",
       "      <td>215666.400000</td>\n",
       "      <td>28621.861390</td>\n",
       "      <td>3.481132</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.499769e+07</td>\n",
       "      <td>5.193302e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TAILS             KG  SALES PER KG           ABW          YEAR  \\\n",
       "count   15055.000000   15055.000000  15055.000000  15055.000000  15055.000000   \n",
       "mean     8241.127532   15260.051938  19204.083254      1.829462     20.098439   \n",
       "std      7135.717864   13785.152507   2153.773552      0.336812      0.985753   \n",
       "min        15.000000      24.800000   6892.778929      0.547500     19.000000   \n",
       "25%      3235.500000    5698.000000  17414.197155      1.596241     19.000000   \n",
       "50%      6532.000000   11683.200000  19072.570490      1.821657     20.000000   \n",
       "75%     11104.000000   20707.450000  20576.154140      2.060000     21.000000   \n",
       "max    103280.000000  215666.400000  28621.861390      3.481132     23.000000   \n",
       "\n",
       "         MONTH           DAY  SupplyProvince  DemandProvince  \n",
       "count  15055.0  15055.000000    1.505500e+04    1.505500e+04  \n",
       "mean      12.0     15.780671    2.617008e+07    2.040207e+07  \n",
       "std        0.0      8.879310    2.328217e+07    1.675878e+07  \n",
       "min       12.0      1.000000    8.322200e+04    3.913950e+05  \n",
       "25%       12.0      8.000000    4.424703e+06    5.141045e+06  \n",
       "50%       12.0     16.000000    1.256251e+07    1.123831e+07  \n",
       "75%       12.0     23.000000    4.994253e+07    3.453131e+07  \n",
       "max       12.0     31.000000    6.499769e+07    5.193302e+07  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding the best number of bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of bins: 5 with F1 Score: 0.7085\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming df is your DataFrame\n",
    "prices = df['SALES PER KG']\n",
    "\n",
    "# Define the scoring function and the range of bin numbers to evaluate\n",
    "scoring_function = make_scorer(f1_score, average='weighted')\n",
    "bin_range = range(5, 16)  # Example range\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for bins in bin_range:\n",
    "    # making a copy of the original dataframe such that the original dataframe is not affected\n",
    "    dfCopy = df.copy()\n",
    "    # Bin the data\n",
    "    dfCopy['price_bin'], bin_edges = pd.qcut(prices, q=bins, retbins=True, labels=False, duplicates='drop')\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = dfCopy.drop(['price_bin', 'SALES PER KG'], axis=1)  # Exclude target variable and original price column\n",
    "    y = dfCopy['price_bin']\n",
    "\n",
    "    # Define preprocessing for categorical variables (encode 'UNIT', 'CHICKEN SIZE', 'PROVINCE')\n",
    "    categorical_features = ['UNIT', 'CHICKEN SIZE', 'PROVINCE']\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features)],\n",
    "        remainder='passthrough'  # Passthrough numerical features as is\n",
    "    )\n",
    "\n",
    "    # Create the modeling pipeline\n",
    "    model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('classifier', xgb.XGBClassifier(objective='multi:softmax',\n",
    "                                                             num_class=bins,\n",
    "                                                             max_depth=5,\n",
    "                                                             eval_metric='mlogloss',\n",
    "                                                             use_label_encoder=False,\n",
    "                                                             seed=42))])\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X, y, cv=cv, scoring=scoring_function)\n",
    "    \n",
    "    # Store the average cross-validation score\n",
    "    cv_results[bins] = np.mean(cv_scores)\n",
    "\n",
    "# Find the number of bins with the best average F1 score\n",
    "best_bin_number = max(cv_results, key=cv_results.get)\n",
    "print(f\"Best number of bins: {best_bin_number} with F1 Score: {cv_results[best_bin_number]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best number of bins is 5, highest F1 score of 0.7085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>SALES PER KG</th>\n",
       "      <th>ABW</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "      <th>price_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYAKUMBUH</td>\n",
       "      <td>1267</td>\n",
       "      <td>2856.0</td>\n",
       "      <td>18000.00000</td>\n",
       "      <td>2.254144</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA BARAT</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3885216</td>\n",
       "      <td>5993194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINJAI</td>\n",
       "      <td>3310</td>\n",
       "      <td>7799.5</td>\n",
       "      <td>22637.89730</td>\n",
       "      <td>2.356344</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SULAWESI SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5447863</td>\n",
       "      <td>5931514</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANDAR JAYA</td>\n",
       "      <td>8236</td>\n",
       "      <td>22197.0</td>\n",
       "      <td>15905.01419</td>\n",
       "      <td>2.695119</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANDAR LAMPUNG</td>\n",
       "      <td>2565</td>\n",
       "      <td>4971.0</td>\n",
       "      <td>18060.47073</td>\n",
       "      <td>1.938012</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LAMPUNG</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5404511</td>\n",
       "      <td>5618463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANYUASIN</td>\n",
       "      <td>696</td>\n",
       "      <td>1464.4</td>\n",
       "      <td>16368.88828</td>\n",
       "      <td>2.104023</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>SUMATERA SELATAN</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5758528</td>\n",
       "      <td>7021239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15050</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>430</td>\n",
       "      <td>901.4</td>\n",
       "      <td>15800.00000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15051</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>294</td>\n",
       "      <td>605.0</td>\n",
       "      <td>15800.00000</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15052</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>432</td>\n",
       "      <td>962.4</td>\n",
       "      <td>15800.00000</td>\n",
       "      <td>2.230000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15053</th>\n",
       "      <td>GUNUNGKIDUL</td>\n",
       "      <td>200</td>\n",
       "      <td>370.8</td>\n",
       "      <td>16200.00000</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>DI YOGYAKARTA</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3993820</td>\n",
       "      <td>5186026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15054</th>\n",
       "      <td>BOYOLALI</td>\n",
       "      <td>400</td>\n",
       "      <td>865.8</td>\n",
       "      <td>15800.00000</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>BIG</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>54958385</td>\n",
       "      <td>26285612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15055 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 UNIT  TAILS       KG  SALES PER KG       ABW CHICKEN SIZE  \\\n",
       "0          PAYAKUMBUH   1267   2856.0   18000.00000  2.254144        LARGE   \n",
       "1              SINJAI   3310   7799.5   22637.89730  2.356344        LARGE   \n",
       "2         BANDAR JAYA   8236  22197.0   15905.01419  2.695119        LARGE   \n",
       "3      BANDAR LAMPUNG   2565   4971.0   18060.47073  1.938012       MEDIUM   \n",
       "4           BANYUASIN    696   1464.4   16368.88828  2.104023        LARGE   \n",
       "...               ...    ...      ...           ...       ...          ...   \n",
       "15050        BOYOLALI    430    901.4   15800.00000  2.100000          BIG   \n",
       "15051        BOYOLALI    294    605.0   15800.00000  2.060000          BIG   \n",
       "15052        BOYOLALI    432    962.4   15800.00000  2.230000          BIG   \n",
       "15053     GUNUNGKIDUL    200    370.8   16200.00000  1.850000       MEDIUM   \n",
       "15054        BOYOLALI    400    865.8   15800.00000  2.160000          BIG   \n",
       "\n",
       "               PROVINCE  YEAR  MONTH  DAY  SupplyProvince  DemandProvince  \\\n",
       "0        SUMATERA BARAT    19     12    1         3885216         5993194   \n",
       "1      SULAWESI SELATAN    19     12    1         5447863         5931514   \n",
       "2               LAMPUNG    19     12    1         5404511         5618463   \n",
       "3               LAMPUNG    19     12    1         5404511         5618463   \n",
       "4      SUMATERA SELATAN    19     12    1         5758528         7021239   \n",
       "...                 ...   ...    ...  ...             ...             ...   \n",
       "15050       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "15051       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "15052       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "15053     DI YOGYAKARTA    23     12   31         3993820         5186026   \n",
       "15054       JAWA TENGAH    23     12   31        54958385        26285612   \n",
       "\n",
       "       price_bin  \n",
       "0              1  \n",
       "1              4  \n",
       "2              0  \n",
       "3              1  \n",
       "4              0  \n",
       "...          ...  \n",
       "15050          0  \n",
       "15051          0  \n",
       "15052          0  \n",
       "15053          0  \n",
       "15054          0  \n",
       "\n",
       "[15055 rows x 13 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing quantile based binning\n",
    "df['price_bin'], bin_edges = pd.qcut(prices, q=best_bin_number, retbins=True, labels=False, duplicates='drop')\n",
    "df.drop(['SALES PER KG'], axis=1, inplace=True) # redundant \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin ranges: ['6892.78-17150.00', '17150.00-18496.56', '18496.56-19619.88', '19619.88-20973.08', '20973.08-28621.86']\n"
     ]
    }
   ],
   "source": [
    "# Creating bin labels and ranges for better understanding\n",
    "bin_labels = [f\"{bin_edges[i]:.2f}-{bin_edges[i+1]:.2f}\" for i in range(len(bin_edges)-1)]\n",
    "print(\"Bin ranges:\", bin_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIT              0\n",
      "TAILS             0\n",
      "KG                0\n",
      "SALES PER KG      0\n",
      "ABW               0\n",
      "CHICKEN SIZE      0\n",
      "PROVINCE          0\n",
      "YEAR              0\n",
      "MONTH             0\n",
      "DAY               0\n",
      "SupplyProvince    0\n",
      "DemandProvince    0\n",
      "dtype: int64\n",
      "UNIT              0\n",
      "TAILS             0\n",
      "KG                0\n",
      "SALES PER KG      0\n",
      "ABW               0\n",
      "CHICKEN SIZE      0\n",
      "PROVINCE          0\n",
      "YEAR              0\n",
      "MONTH             0\n",
      "DAY               0\n",
      "SupplyProvince    0\n",
      "DemandProvince    0\n",
      "dtype: int64\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# train test split before label encoding to prevent data leakage\n",
    "\n",
    "\n",
    "X = df.drop('price_bin', axis=1)\n",
    "y = df['price_bin']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# checking for any nan values after splitting\n",
    "print(X_train.isna().sum())\n",
    "print(X_test.isna().sum())\n",
    "print(y_train.isna().sum())\n",
    "print(y_test.isna().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling numerical variable\n",
    "\n",
    "scaler = StandardScaler()\n",
    "columns_to_scale = ['KG', 'TAILS', 'SupplyProvince', 'DemandProvince']\n",
    "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TAILS</th>\n",
       "      <th>KG</th>\n",
       "      <th>CHICKEN SIZE</th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>SupplyProvince</th>\n",
       "      <th>DemandProvince</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>KARANGASEM</td>\n",
       "      <td>-0.872846</td>\n",
       "      <td>-0.862323</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>BALI</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.916943</td>\n",
       "      <td>-0.924149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9726</th>\n",
       "      <td>BALIKPAPAN</td>\n",
       "      <td>0.059049</td>\n",
       "      <td>0.155902</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>KALIMANTAN TIMUR</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.022624</td>\n",
       "      <td>-0.962814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13769</th>\n",
       "      <td>BOJONEGORO</td>\n",
       "      <td>-0.933067</td>\n",
       "      <td>-0.870435</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>JAWA TIMUR</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>0.090720</td>\n",
       "      <td>0.850420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10131</th>\n",
       "      <td>BOJONEGORO</td>\n",
       "      <td>0.263272</td>\n",
       "      <td>-0.058983</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>JAWA TIMUR</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.090720</td>\n",
       "      <td>0.850420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10643</th>\n",
       "      <td>DEMAK</td>\n",
       "      <td>0.689839</td>\n",
       "      <td>0.455114</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>JAWA TENGAH</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.789468</td>\n",
       "      <td>0.287419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>KARANGASEM</td>\n",
       "      <td>0.852101</td>\n",
       "      <td>0.913293</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>BALI</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.916943</td>\n",
       "      <td>-0.924149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13419</th>\n",
       "      <td>BANGKINANG</td>\n",
       "      <td>0.396957</td>\n",
       "      <td>0.330484</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>RIAU</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.763180</td>\n",
       "      <td>-0.872158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>SERANG</td>\n",
       "      <td>-0.269240</td>\n",
       "      <td>-0.542749</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>BANTEN</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.468474</td>\n",
       "      <td>-0.454299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>SUBANG(P)</td>\n",
       "      <td>1.897051</td>\n",
       "      <td>1.165433</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>JAWA BARAT</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1.671334</td>\n",
       "      <td>1.891485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>SINGOSARI</td>\n",
       "      <td>-0.367378</td>\n",
       "      <td>-0.458573</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>JAWA TIMUR</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0.344926</td>\n",
       "      <td>1.276895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12043 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             UNIT     TAILS        KG CHICKEN SIZE          PROVINCE  YEAR  \\\n",
       "6463   KARANGASEM -0.872846 -0.862323       MEDIUM              BALI  2020   \n",
       "9726   BALIKPAPAN  0.059049  0.155902        LARGE  KALIMANTAN TIMUR  2021   \n",
       "13769  BOJONEGORO -0.933067 -0.870435        LARGE        JAWA TIMUR  2021   \n",
       "10131  BOJONEGORO  0.263272 -0.058983        SMALL        JAWA TIMUR  2021   \n",
       "10643       DEMAK  0.689839  0.455114       MEDIUM       JAWA TENGAH  2021   \n",
       "...           ...       ...       ...          ...               ...   ...   \n",
       "5192   KARANGASEM  0.852101  0.913293       MEDIUM              BALI  2020   \n",
       "13419  BANGKINANG  0.396957  0.330484       MEDIUM              RIAU  2021   \n",
       "5391       SERANG -0.269240 -0.542749        SMALL            BANTEN  2020   \n",
       "860     SUBANG(P)  1.897051  1.165433        SMALL        JAWA BARAT  2019   \n",
       "7271    SINGOSARI -0.367378 -0.458573       MEDIUM        JAWA TIMUR  2020   \n",
       "\n",
       "       MONTH  DAY  SupplyProvince  DemandProvince  \n",
       "6463      12   10       -0.916943       -0.924149  \n",
       "9726      12    2       -1.022624       -0.962814  \n",
       "13769     12   27        0.090720        0.850420  \n",
       "10131     12    4        0.090720        0.850420  \n",
       "10643     12    7        0.789468        0.287419  \n",
       "...      ...  ...             ...             ...  \n",
       "5192      12    1       -0.916943       -0.924149  \n",
       "13419     12   24       -0.763180       -0.872158  \n",
       "5391      12    2       -0.468474       -0.454299  \n",
       "860       12    5        1.671334        1.891485  \n",
       "7271      12   16        0.344926        1.276895  \n",
       "\n",
       "[12043 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to evaluate the model\n",
    "def results(y_test, predictions):\n",
    "  mae = mean_absolute_error(y_test, predictions)\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "  rmse = np.sqrt(mse)\n",
    "  r2 = r2_score(y_test, predictions)\n",
    "\n",
    "  print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "  print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "  print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "  print(f\"R-squared (R²): {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding of columns\n",
    "# label encoding for province\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "X_train['SIZE ENCODE'] = label_encoder.fit_transform(X_train['CHICKEN SIZE'])\n",
    "X_test['SIZE ENCODE'] = label_encoder.transform(X_test['CHICKEN SIZE'])\n",
    "\n",
    "# dropping chicken size column\n",
    "X_train = X_train.drop(['CHICKEN SIZE'], axis = 1)\n",
    "X_test = X_test.drop(['CHICKEN SIZE'], axis = 1)\n",
    "\n",
    "\n",
    "# one hot encoding for province\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X_train[['PROVINCE']])\n",
    "X_train_encoded = encoder.transform(X_train[['PROVINCE']])\n",
    "X_test_encoded = encoder.transform(X_test[['PROVINCE']])\n",
    "\n",
    "# Convert the encoded matrices back to dataframes for easier manipulation\n",
    "columns = encoder.get_feature_names_out(['PROVINCE'])\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded.toarray(), columns=columns, index=X_train.index)\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded.toarray(), columns=columns, index=X_test.index)\n",
    "\n",
    "# merge back the dataframe\n",
    "X_train = pd.concat([X_train.drop('PROVINCE', axis=1), X_train_encoded_df], axis=1)\n",
    "X_test = pd.concat([X_test.drop('PROVINCE', axis=1), X_test_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# one hot encoding for unit\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X_train[['UNIT']])\n",
    "X_train_encoded_unit = encoder.transform(X_train[['UNIT']])\n",
    "X_test_encoded_unit = encoder.transform(X_test[['UNIT']])\n",
    "\n",
    "# Convert the encoded matrices back to dataframes for easier manipulation\n",
    "columns = encoder.get_feature_names_out(['UNIT'])\n",
    "X_train_encoded_df_unit = pd.DataFrame(X_train_encoded_unit.toarray(), columns=columns, index=X_train.index)\n",
    "X_test_encoded_df_unit = pd.DataFrame(X_test_encoded_unit.toarray(), columns=columns, index=X_test.index)\n",
    "\n",
    "# merge back the dataframe, dropping unit column\n",
    "X_train = pd.concat([X_train.drop('UNIT', axis=1), X_train_encoded_df_unit], axis=1)\n",
    "X_test = pd.concat([X_test.drop('UNIT', axis=1), X_test_encoded_df_unit], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying lazy predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lazypredict in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.2.12)\n",
      "Requirement already satisfied: click in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (8.1.7)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (1.4.1.post1)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from lazypredict) (2.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (4.66.2)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from lazypredict) (1.3.2)\n",
      "Requirement already satisfied: lightgbm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (4.3.0)\n",
      "Requirement already satisfied: xgboost in /usr/local/python/3.10.13/lib/python3.10/site-packages (from lazypredict) (2.0.3)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from lightgbm->lazypredict) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from lightgbm->lazypredict) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->lazypredict) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->lazypredict) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.16.0)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.utils import all_estimators\\nfrom sklearn.base import RegressorMixin'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libraries\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "'''from sklearn.utils import all_estimators\n",
    "from sklearn.base import RegressorMixin'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AdaBoostClassifier', <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>), ('BaggingClassifier', <class 'sklearn.ensemble._bagging.BaggingClassifier'>), ('BernoulliNB', <class 'sklearn.naive_bayes.BernoulliNB'>), ('CalibratedClassifierCV', <class 'sklearn.calibration.CalibratedClassifierCV'>), ('CategoricalNB', <class 'sklearn.naive_bayes.CategoricalNB'>), ('DecisionTreeClassifier', <class 'sklearn.tree._classes.DecisionTreeClassifier'>), ('DummyClassifier', <class 'sklearn.dummy.DummyClassifier'>), ('ExtraTreeClassifier', <class 'sklearn.tree._classes.ExtraTreeClassifier'>), ('ExtraTreesClassifier', <class 'sklearn.ensemble._forest.ExtraTreesClassifier'>), ('GaussianNB', <class 'sklearn.naive_bayes.GaussianNB'>), ('KNeighborsClassifier', <class 'sklearn.neighbors._classification.KNeighborsClassifier'>), ('LabelPropagation', <class 'sklearn.semi_supervised._label_propagation.LabelPropagation'>), ('LabelSpreading', <class 'sklearn.semi_supervised._label_propagation.LabelSpreading'>), ('LinearDiscriminantAnalysis', <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>), ('LinearSVC', <class 'sklearn.svm._classes.LinearSVC'>), ('LogisticRegression', <class 'sklearn.linear_model._logistic.LogisticRegression'>), ('NearestCentroid', <class 'sklearn.neighbors._nearest_centroid.NearestCentroid'>), ('NuSVC', <class 'sklearn.svm._classes.NuSVC'>), ('PassiveAggressiveClassifier', <class 'sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier'>), ('Perceptron', <class 'sklearn.linear_model._perceptron.Perceptron'>), ('QuadraticDiscriminantAnalysis', <class 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'>), ('RandomForestClassifier', <class 'sklearn.ensemble._forest.RandomForestClassifier'>), ('RidgeClassifier', <class 'sklearn.linear_model._ridge.RidgeClassifier'>), ('RidgeClassifierCV', <class 'sklearn.linear_model._ridge.RidgeClassifierCV'>), ('SGDClassifier', <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>), ('SVC', <class 'sklearn.svm._classes.SVC'>), ('StackingClassifier', <class 'sklearn.ensemble._stacking.StackingClassifier'>), ('XGBClassifier', <class 'xgboost.sklearn.XGBClassifier'>), ('LGBMClassifier', <class 'lightgbm.sklearn.LGBMClassifier'>)]\n"
     ]
    }
   ],
   "source": [
    "print(lazypredict.Supervised.CLASSIFIERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    chosen_regressors = [\n",
    "    'SVR', \n",
    "    'BaggingRegressor',\n",
    "    'ExtraTreesRegressor',\n",
    "    'RandomForestRegressor',\n",
    "    'GradientBoostingRegressor',\n",
    "    'LGBMRegressor',\n",
    "    'XGBRegressor',\n",
    "    'CatBoostRegressor',\n",
    "    'HistGradientBoostingRegressor',\n",
    "    'AdaBoostRegressor',\n",
    "    'KNeighborsRegressor',\n",
    "    'DecisionTreeRegressor'\n",
    "]\n",
    "\n",
    "REGRESSORS = [\n",
    "    est\n",
    "    for est in all_estimators()\n",
    "    if (issubclass(est[1], RegressorMixin) and est[0] in chosen_regressors)\n",
    "\n",
    "]'''\n",
    "\n",
    "# initialising the regressor with chosen regressors\n",
    "reg = LazyClassifier(verbose=1, ignore_warnings=False, custom_metric=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/29 [00:00<00:24,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for AdaBoostClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n",
      "{'Model': 'AdaBoostClassifier', 'Accuracy': 0.41149119893723013, 'Balanced Accuracy': 0.1354976736437217, 'ROC AUC': None, 'F1 Score': 0.32996162485507313, 'Time taken': 0.8639228343963623}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/29 [00:01<00:20,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC couldn't be calculated for BaggingClassifier\n",
      "multi_class must be in ('ovo', 'ovr')\n",
      "{'Model': 'BaggingClassifier', 'Accuracy': 0.7499169711059449, 'Balanced Accuracy': 0.429473765876953, 'ROC AUC': None, 'F1 Score': 0.746572114415542, 'Time taken': 0.6885628700256348}\n",
      "ROC AUC couldn't be calculated for BernoulliNB\n",
      "multi_class must be in ('ovo', 'ovr')\n",
      "{'Model': 'BernoulliNB', 'Accuracy': 0.40983062105612755, 'Balanced Accuracy': 0.24126230101466106, 'ROC AUC': None, 'F1 Score': 0.4031425749212721, 'Time taken': 0.08809232711791992}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fitting and evaluate models\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out the top 5 models\n",
    "top_5_models = models.head(5)\n",
    "top_5_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.91%\n",
      "Confusion Matrix:\n",
      "[[  0   0   0   0   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   2   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0   0   0   0   0]\n",
      " [  0   1   1  25  15   4   1   0   0   0   0   0]\n",
      " [  0   1   0  50 507  99  24  11   4   5   0   0]\n",
      " [  1   1   2  25 148 470 111  34  25   4   1   0]\n",
      " [  0   0   0   5  30  95 513 141  58   5   2   0]\n",
      " [  0   0   0   1   4   8  63 237  79  10   0   0]\n",
      " [  0   0   0   1   4   4   4  29  79   8   0   0]\n",
      " [  0   0   0   0   0   0   0   5  12  32   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.23      0.53      0.32        47\n",
      "           5       0.71      0.72      0.72       701\n",
      "           6       0.69      0.57      0.62       822\n",
      "           7       0.72      0.60      0.66       849\n",
      "           8       0.52      0.59      0.55       402\n",
      "           9       0.30      0.61      0.41       129\n",
      "          10       0.50      0.65      0.57        49\n",
      "          11       0.25      0.33      0.29         3\n",
      "          12       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      3011\n",
      "   macro avg       0.33      0.38      0.34      3011\n",
      "weighted avg       0.65      0.62      0.63      3011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# trying XGBM model\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label encoding the target variable\n",
    "label_encoder = LabelEncoder().fit(y_train_resampled)  # Fit on y_train to learn all classes\n",
    "y_train_encoded = label_encoder.transform(y_train_resampled)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Dynamically set the number of classes\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "\n",
    "\n",
    "# Specify the parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # Specify multi-class classification\n",
    "    'num_class': num_classes,  # Dynamically set the number of classes\n",
    "    'max_depth': 4,  # Depth of the trees\n",
    "    'learning_rate': 0.1,  # Learning rate\n",
    "    'n_estimators': 100,  # Number of trees\n",
    "    'seed': 42  # Random seed for reproducibility\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "# Train the model with encoded targets\n",
    "clf.fit(X_train_resampled, y_train_encoded)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# getting unique classes for predicted labels\n",
    "unique_y_test = np.unique(y_test_encoded)\n",
    "unique_y_pred = np.unique(y_pred)\n",
    "\n",
    "# get unique classes \n",
    "all_unique_classes = np.unique(np.concatenate((y_test_encoded, y_pred)))\n",
    "\n",
    "# map the unique encoded classes back to original names\n",
    "target_names_adjusted = label_encoder.inverse_transform(all_unique_classes)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_encoded, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "using entity embeddings to train the neural network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting up the model\n",
    "creating entity embeddings <br>\n",
    "`cat_col1` = `PROVINCE` <br>\n",
    "`cat_col2` = `CHICKEN SIZE` <br>\n",
    "`cat_col3` = `SIZE` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset `df`\n",
    "\n",
    "# importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Reshape, Concatenate, Dense, Flatten\n",
    "\n",
    "# getting the unique values of the categorical columns\n",
    "cat_columns = ['PROVINCE', 'CHICKEN SIZE', 'UNIT']\n",
    "unique_cat1 = df['PROVINCE'].nunique()\n",
    "unique_cat2 = df['CHICKEN SIZE'].nunique()\n",
    "unique_cat3 = df['UNIT'].nunique()\n",
    "\n",
    "# getting numerical columns\n",
    "num_columns = df.columns.difference(cat_columns)\n",
    "numerical_data = df[num_columns]\n",
    "\n",
    "# scaling the numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
    "\n",
    "# defining the input layer\n",
    "num_input = Input(shape=(numerical_data_scaled.shape[1],), name='num_input')\n",
    "\n",
    "# embedding the categorical columns\n",
    "cat_input1 = Input(shape = (1,), name='cat_input1')\n",
    "cat_embed1 = Embedding(input_dim=unique_cat1, output_dim = int(min(np.ceil(unique_cat1 /2), 50)))(cat_input1)\n",
    "cat_embed1 = Flatten()(cat_embed1)\n",
    "\n",
    "cat_input2 = Input(shape = (1,), name='cat_input2')\n",
    "cat_embed2 = Embedding(input_dim=unique_cat2, output_dim = int(min(np.ceil(unique_cat2 /2), 50)))(cat_input2)\n",
    "cat_embed2 = Flatten()(cat_embed2)\n",
    "\n",
    "\n",
    "cat_input3 = Input(shape = (1,), name='cat_input3')\n",
    "cat_embed3 = Embedding(input_dim=unique_cat3, output_dim = int(min(np.ceil(unique_cat3 /2), 50)))(cat_input3)\n",
    "cat_embed3 = Flatten()(cat_embed3)\n",
    "\n",
    "\n",
    "# concatenate the embeddings with numerical input\n",
    "concatenated = Concatenate()([cat_embed1, cat_embed2, cat_embed3, num_input])\n",
    "\n",
    "\n",
    "# adding the dense layer ontop of the embeddings\n",
    "dense_output = Dense(128, activation = 'relu')(concatenated)\n",
    "dense_output = Dense(64, activation = 'relu')(dense_output)\n",
    "output = Dense(1)(dense_output)\n",
    "\n",
    "# creating the model\n",
    "model = Model(inputs = [cat_input1, cat_input2, cat_input3, num_input], outputs = output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "X_train_cat1 = X_train['PROVINCE']\n",
    "X_train_cat2 = X_train['CHICKEN SIZE']\n",
    "X_train_cat3 = X_train['UNIT']\n",
    "X_train_num = X_train.drop(['PROVINCE', 'CHICKEN SIZE', 'UNIT'], axis = 1)\n",
    "\n",
    "# fitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Single output node for regression\n",
    "])\n",
    "\n",
    "# Compile the model, specifying the optimizer, loss function, and metric\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Fit the model on the training data\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, epochs=100, verbose=1)\n",
    "\n",
    "# Predict the target on the testing set\n",
    "predictions = model.predict(X_test).flatten()\n",
    "\n",
    "# Evaluate the model performance using RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# You can plot the training history to check how the loss and metric evolved over epochs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
